[Rank 0] 2026-01-23 12:31:51,353 - podcast_processing.distributed_orchestrator - INFO - Rank 0/8 starting
[Rank 0] 2026-01-23 12:31:51,354 - podcast_processing.distributed_orchestrator - INFO - Dataset root: data/PodcastFillers
[Rank 0] 2026-01-23 12:31:51,354 - podcast_processing.distributed_orchestrator - INFO - Output root: outputs/features_masked
[Rank 0] 2026-01-23 12:31:51,354 - podcast_processing.distributed_orchestrator - INFO - Enumerating episodes...
[Rank 0] 2026-01-23 12:31:51,368 - podcast_processing.dataset_enumerator - INFO - Found 199 episodes across all splits
[Rank 0] 2026-01-23 12:31:51,369 - podcast_processing.distributed_orchestrator - INFO - Total episodes: 199
[Rank 0] 2026-01-23 12:31:51,369 - podcast_processing.distributed_orchestrator - INFO - Rank 0 processing episodes 0-23 (24 total)
[Rank 0] 2026-01-23 12:31:51,369 - podcast_processing.distributed_orchestrator - INFO - Loading models...
[Rank 0] 2026-01-23 12:31:51,381 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
[Rank 0] 2026-01-23 12:31:51,683 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /kyutai/moshiko-pytorch-bf16/resolve/main/tokenizer_spm_32k_3.model HTTP/1.1" 302 0
[Rank 0] 2026-01-23 12:31:58,405 - podcast_processing.distributed_orchestrator - INFO - Loading tokenizer...
[Rank 0] 2026-01-23 12:31:58,452 - podcast_processing.distributed_orchestrator - INFO - Models loaded on cuda:0
[Rank 0] 2026-01-23 12:31:58,458 - podcast_processing.episode_processor - INFO - Processing episode: All The Fly Kids_Chaos & Culture Episode 10 Rethinking the Urban Marketing Aesthetic feat. Karim Lateef
[Rank 0] 2026-01-23 12:31:58,462 - podcast_processing.label_generator - DEBUG - Loaded 2 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/All The Fly Kids_Chaos & Culture Episode 10 Rethinking the Urban Marketing Aesthetic feat. Karim Lateef.json
[Rank 0] 2026-01-23 12:31:58,463 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_00 (longer), SPEAKER_01 (shorter)
[Rank 0] 2026-01-23 12:31:58,553 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [169.06, 169.24], using fallback
[Rank 0] 2026-01-23 12:31:58,553 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [169.33, 169.60], using fallback
[Rank 0] 2026-01-23 12:31:58,761 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [615.71, 615.71], using fallback
[Rank 0] 2026-01-23 12:31:59,057 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1229.50, 1229.50], using fallback
[Rank 0] 2026-01-23 12:31:59,319 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1787.19, 1787.28], using fallback
[Rank 0] 2026-01-23 12:31:59,617 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2404.47, 2404.47], using fallback
[Rank 0] 2026-01-23 12:32:00,160 - podcast_processing.alignment_merger - INFO - Created 9911 word alignments
[Rank 0] 2026-01-23 12:32:00,936 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_00: torch.Size([1, 81931704]), SPEAKER_01: torch.Size([1, 81931704])
[Rank 0] 2026-01-23 12:32:00,936 - podcast_processing.episode_processor - INFO - Episode duration: 3413.82s
[Rank 0] 2026-01-23 12:32:00,936 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:32:00,937 - podcast_processing.audio_masking - DEBUG - No laughter events found for SPEAKER_01
[Rank 0] 2026-01-23 12:32:00,937 - podcast_processing.episode_processor - INFO - Audio is 3413.8s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:32:00,937 - podcast_processing.episode_processor - INFO - Processing 3413.8s audio in 17 chunks of 210s each
[Rank 0] 2026-01-23 12:32:00,937 - podcast_processing.episode_processor - INFO -   Processing chunk 1/17 (210.0s)
[Rank 0] 2026-01-23 12:32:03,059 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:03,059 - podcast_processing.episode_processor - DEBUG - System speaker has 335 words
[Rank 0] 2026-01-23 12:32:03,101 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:03,101 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:03,101 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:03,103 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:03,963 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:04,008 - podcast_processing.episode_processor - INFO -   Processing chunk 2/17 (210.0s)
[Rank 0] 2026-01-23 12:32:04,101 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:04,101 - podcast_processing.episode_processor - DEBUG - System speaker has 123 words
[Rank 0] 2026-01-23 12:32:04,148 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:04,148 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:04,148 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:04,149 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:04,176 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:04,271 - podcast_processing.episode_processor - INFO -   Processing chunk 3/17 (210.0s)
[Rank 0] 2026-01-23 12:32:04,353 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:04,353 - podcast_processing.episode_processor - DEBUG - System speaker has 373 words
[Rank 0] 2026-01-23 12:32:04,400 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:04,400 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:04,400 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:04,401 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:04,427 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:04,527 - podcast_processing.episode_processor - INFO -   Processing chunk 4/17 (210.0s)
[Rank 0] 2026-01-23 12:32:04,609 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:04,609 - podcast_processing.episode_processor - DEBUG - System speaker has 379 words
[Rank 0] 2026-01-23 12:32:04,656 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:04,656 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:04,656 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:04,657 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:04,686 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:04,803 - podcast_processing.episode_processor - INFO -   Processing chunk 5/17 (210.0s)
[Rank 0] 2026-01-23 12:32:04,896 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:04,896 - podcast_processing.episode_processor - DEBUG - System speaker has 254 words
[Rank 0] 2026-01-23 12:32:04,943 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:04,943 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:04,943 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:04,944 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:04,970 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:05,073 - podcast_processing.episode_processor - INFO -   Processing chunk 6/17 (210.0s)
[Rank 0] 2026-01-23 12:32:05,158 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:05,158 - podcast_processing.episode_processor - DEBUG - System speaker has 52 words
[Rank 0] 2026-01-23 12:32:05,205 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:05,205 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:05,205 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:05,206 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:05,232 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:05,336 - podcast_processing.episode_processor - INFO -   Processing chunk 7/17 (210.0s)
[Rank 0] 2026-01-23 12:32:05,422 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:05,423 - podcast_processing.episode_processor - DEBUG - System speaker has 216 words
[Rank 0] 2026-01-23 12:32:05,470 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:05,470 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:05,470 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:05,471 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:05,497 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:05,671 - podcast_processing.episode_processor - INFO -   Processing chunk 8/17 (210.0s)
[Rank 0] 2026-01-23 12:32:05,970 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:05,970 - podcast_processing.episode_processor - DEBUG - System speaker has 128 words
[Rank 0] 2026-01-23 12:32:06,012 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:06,012 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:06,013 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:06,014 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:06,040 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:06,144 - podcast_processing.episode_processor - INFO -   Processing chunk 9/17 (210.0s)
[Rank 0] 2026-01-23 12:32:06,239 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:06,239 - podcast_processing.episode_processor - DEBUG - System speaker has 557 words
[Rank 0] 2026-01-23 12:32:06,286 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:06,286 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:06,287 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:06,287 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:06,314 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:06,778 - podcast_processing.episode_processor - INFO -   Processing chunk 10/17 (210.0s)
[Rank 0] 2026-01-23 12:32:07,122 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:07,122 - podcast_processing.episode_processor - DEBUG - System speaker has 99 words
[Rank 0] 2026-01-23 12:32:07,169 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:07,169 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:07,169 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:07,170 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:07,197 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:07,466 - podcast_processing.episode_processor - INFO -   Processing chunk 11/17 (210.0s)
[Rank 0] 2026-01-23 12:32:07,621 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:07,621 - podcast_processing.episode_processor - DEBUG - System speaker has 144 words
[Rank 0] 2026-01-23 12:32:07,667 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:07,668 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:07,668 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:07,669 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:07,695 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:07,792 - podcast_processing.episode_processor - INFO -   Processing chunk 12/17 (210.0s)
[Rank 0] 2026-01-23 12:32:07,887 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:07,887 - podcast_processing.episode_processor - DEBUG - System speaker has 328 words
[Rank 0] 2026-01-23 12:32:07,935 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:07,935 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:07,935 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:07,936 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:07,962 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:08,074 - podcast_processing.episode_processor - INFO -   Processing chunk 13/17 (210.0s)
[Rank 0] 2026-01-23 12:32:08,166 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:08,166 - podcast_processing.episode_processor - DEBUG - System speaker has 160 words
[Rank 0] 2026-01-23 12:32:08,212 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:08,213 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:08,213 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:08,213 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:08,240 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:08,344 - podcast_processing.episode_processor - INFO -   Processing chunk 14/17 (210.0s)
[Rank 0] 2026-01-23 12:32:08,448 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:08,448 - podcast_processing.episode_processor - DEBUG - System speaker has 39 words
[Rank 0] 2026-01-23 12:32:08,495 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:08,495 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:08,496 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:08,497 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:08,523 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:08,618 - podcast_processing.episode_processor - INFO -   Processing chunk 15/17 (210.0s)
[Rank 0] 2026-01-23 12:32:08,720 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:08,720 - podcast_processing.episode_processor - DEBUG - System speaker has 224 words
[Rank 0] 2026-01-23 12:32:08,767 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:08,767 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:08,768 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:08,768 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:08,794 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:08,893 - podcast_processing.episode_processor - INFO -   Processing chunk 16/17 (210.0s)
[Rank 0] 2026-01-23 12:32:08,987 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:08,987 - podcast_processing.episode_processor - DEBUG - System speaker has 238 words
[Rank 0] 2026-01-23 12:32:09,035 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:09,035 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:09,035 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:09,035 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:09,061 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:09,160 - podcast_processing.episode_processor - INFO -   Processing chunk 17/17 (53.8s)
[Rank 0] 2026-01-23 12:32:09,541 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 673]), System codes shape: torch.Size([1, 8, 673])
[Rank 0] 2026-01-23 12:32:09,541 - podcast_processing.episode_processor - DEBUG - System speaker has 126 words
[Rank 0] 2026-01-23 12:32:09,544 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 673])
[Rank 0] 2026-01-23 12:32:09,544 - podcast_processing.episode_processor - DEBUG - Padded to max_t=673
[Rank 0] 2026-01-23 12:32:09,544 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 673]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:09,544 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 674])
[Rank 0] 2026-01-23 12:32:10,004 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 673, 4096])
[Rank 0] 2026-01-23 12:32:10,262 - podcast_processing.episode_processor - INFO - Combined 17 chunks into final output shape: torch.Size([42673, 4096])
[Rank 0] 2026-01-23 12:32:12,486 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/All The Fly Kids_Chaos & Culture Episode 10 Rethinking the Urban Marketing Aesthetic feat. Karim Lateef/features_assignment_0.npy
[Rank 0] 2026-01-23 12:32:12,486 - podcast_processing.episode_processor - INFO -   Saved features: 42673 frames
[Rank 0] 2026-01-23 12:32:12,487 - podcast_processing.label_generator - DEBUG - Processing 2 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:32:12,501 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/All The Fly Kids_Chaos & Culture Episode 10 Rethinking the Urban Marketing Aesthetic feat. Karim Lateef/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:32:12,501 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 5/42673 positive
[Rank 0] 2026-01-23 12:32:12,501 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:32:12,501 - podcast_processing.audio_masking - DEBUG - Creating mask from 2 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:32:12,572 - podcast_processing.audio_masking - DEBUG - Mask covers 9840/81931704 samples (0.01%)
[Rank 0] 2026-01-23 12:32:12,610 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 9840/81931704 samples masked
[Rank 0] 2026-01-23 12:32:13,554 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 9840/81931704 samples zeroed
[Rank 0] 2026-01-23 12:32:13,554 - podcast_processing.episode_processor - INFO - Audio is 3413.8s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:32:13,554 - podcast_processing.episode_processor - INFO - Processing 3413.8s audio in 17 chunks of 210s each
[Rank 0] 2026-01-23 12:32:13,554 - podcast_processing.episode_processor - INFO -   Processing chunk 1/17 (210.0s)
[Rank 0] 2026-01-23 12:32:13,609 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:13,697 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:13,697 - podcast_processing.episode_processor - DEBUG - System speaker has 252 words
[Rank 0] 2026-01-23 12:32:13,743 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:13,743 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:13,743 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:13,744 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:13,772 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:13,870 - podcast_processing.episode_processor - INFO -   Processing chunk 2/17 (210.0s)
[Rank 0] 2026-01-23 12:32:13,926 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:14,015 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:14,015 - podcast_processing.episode_processor - DEBUG - System speaker has 456 words
[Rank 0] 2026-01-23 12:32:14,061 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:14,061 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:14,061 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:14,062 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:14,090 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:14,184 - podcast_processing.episode_processor - INFO -   Processing chunk 3/17 (210.0s)
[Rank 0] 2026-01-23 12:32:14,240 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:14,329 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:14,329 - podcast_processing.episode_processor - DEBUG - System speaker has 178 words
[Rank 0] 2026-01-23 12:32:14,375 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:14,376 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:14,376 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:14,376 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:14,405 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:14,498 - podcast_processing.episode_processor - INFO -   Processing chunk 4/17 (210.0s)
[Rank 0] 2026-01-23 12:32:14,557 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:14,650 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:14,650 - podcast_processing.episode_processor - DEBUG - System speaker has 199 words
[Rank 0] 2026-01-23 12:32:14,696 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:14,696 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:14,696 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:14,697 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:14,724 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:14,819 - podcast_processing.episode_processor - INFO -   Processing chunk 5/17 (210.0s)
[Rank 0] 2026-01-23 12:32:14,874 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:14,966 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:14,966 - podcast_processing.episode_processor - DEBUG - System speaker has 324 words
[Rank 0] 2026-01-23 12:32:15,013 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:15,013 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:15,013 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:15,013 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:15,041 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:15,135 - podcast_processing.episode_processor - INFO -   Processing chunk 6/17 (210.0s)
[Rank 0] 2026-01-23 12:32:15,192 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:15,282 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:15,282 - podcast_processing.episode_processor - DEBUG - System speaker has 568 words
[Rank 0] 2026-01-23 12:32:15,328 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:15,328 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:15,328 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:15,329 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:15,358 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:15,451 - podcast_processing.episode_processor - INFO -   Processing chunk 7/17 (210.0s)
[Rank 0] 2026-01-23 12:32:15,506 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:15,595 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:15,595 - podcast_processing.episode_processor - DEBUG - System speaker has 324 words
[Rank 0] 2026-01-23 12:32:15,642 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:15,642 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:15,642 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:15,643 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:15,671 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:15,763 - podcast_processing.episode_processor - INFO -   Processing chunk 8/17 (210.0s)
[Rank 0] 2026-01-23 12:32:15,819 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:15,913 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:15,914 - podcast_processing.episode_processor - DEBUG - System speaker has 491 words
[Rank 0] 2026-01-23 12:32:15,960 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:15,960 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:15,960 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:15,961 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:15,989 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:16,082 - podcast_processing.episode_processor - INFO -   Processing chunk 9/17 (210.0s)
[Rank 0] 2026-01-23 12:32:16,141 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:16,236 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:16,236 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:32:16,283 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:16,283 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:16,283 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:16,283 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:16,311 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:16,410 - podcast_processing.episode_processor - INFO -   Processing chunk 10/17 (210.0s)
[Rank 0] 2026-01-23 12:32:16,466 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:16,560 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:16,561 - podcast_processing.episode_processor - DEBUG - System speaker has 556 words
[Rank 0] 2026-01-23 12:32:16,607 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:16,607 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:16,607 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:16,608 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:16,635 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:16,735 - podcast_processing.episode_processor - INFO -   Processing chunk 11/17 (210.0s)
[Rank 0] 2026-01-23 12:32:16,794 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:16,885 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:16,886 - podcast_processing.episode_processor - DEBUG - System speaker has 429 words
[Rank 0] 2026-01-23 12:32:16,932 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:16,932 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:16,932 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:16,933 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:16,960 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:17,061 - podcast_processing.episode_processor - INFO -   Processing chunk 12/17 (210.0s)
[Rank 0] 2026-01-23 12:32:17,209 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:17,306 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:17,307 - podcast_processing.episode_processor - DEBUG - System speaker has 304 words
[Rank 0] 2026-01-23 12:32:17,353 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:17,353 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:17,353 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:17,354 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:17,384 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:17,489 - podcast_processing.episode_processor - INFO -   Processing chunk 13/17 (210.0s)
[Rank 0] 2026-01-23 12:32:17,549 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:17,647 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:17,647 - podcast_processing.episode_processor - DEBUG - System speaker has 515 words
[Rank 0] 2026-01-23 12:32:17,693 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:17,693 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:17,693 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:17,694 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:17,722 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:17,815 - podcast_processing.episode_processor - INFO -   Processing chunk 14/17 (210.0s)
[Rank 0] 2026-01-23 12:32:17,876 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:17,981 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:18,096 - podcast_processing.episode_processor - DEBUG - System speaker has 618 words
[Rank 0] 2026-01-23 12:32:18,102 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:18,102 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:18,102 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:18,102 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:18,131 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:18,228 - podcast_processing.episode_processor - INFO -   Processing chunk 15/17 (210.0s)
[Rank 0] 2026-01-23 12:32:18,289 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:18,387 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:18,387 - podcast_processing.episode_processor - DEBUG - System speaker has 475 words
[Rank 0] 2026-01-23 12:32:18,433 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:18,433 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:18,434 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:18,434 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:18,463 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:18,567 - podcast_processing.episode_processor - INFO -   Processing chunk 16/17 (210.0s)
[Rank 0] 2026-01-23 12:32:18,627 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:18,730 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:18,730 - podcast_processing.episode_processor - DEBUG - System speaker has 431 words
[Rank 0] 2026-01-23 12:32:18,777 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:18,777 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:18,777 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:18,777 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:18,805 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:18,915 - podcast_processing.episode_processor - INFO -   Processing chunk 17/17 (53.8s)
[Rank 0] 2026-01-23 12:32:18,931 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 9840/1291704 samples zeroed
[Rank 0] 2026-01-23 12:32:18,970 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 673]), System codes shape: torch.Size([1, 8, 673])
[Rank 0] 2026-01-23 12:32:18,970 - podcast_processing.episode_processor - DEBUG - System speaker has 10 words
[Rank 0] 2026-01-23 12:32:18,973 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 673])
[Rank 0] 2026-01-23 12:32:18,973 - podcast_processing.episode_processor - DEBUG - Padded to max_t=673
[Rank 0] 2026-01-23 12:32:18,973 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 673]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:18,973 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 674])
[Rank 0] 2026-01-23 12:32:19,000 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 673, 4096])
[Rank 0] 2026-01-23 12:32:19,286 - podcast_processing.episode_processor - INFO - Combined 17 chunks into final output shape: torch.Size([42673, 4096])
[Rank 0] 2026-01-23 12:32:22,194 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/All The Fly Kids_Chaos & Culture Episode 10 Rethinking the Urban Marketing Aesthetic feat. Karim Lateef/features_assignment_1.npy
[Rank 0] 2026-01-23 12:32:22,195 - podcast_processing.episode_processor - INFO -   Saved features: 42673 frames
[Rank 0] 2026-01-23 12:32:22,202 - podcast_processing.label_generator - DEBUG - Processing 0 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:32:22,265 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/All The Fly Kids_Chaos & Culture Episode 10 Rethinking the Urban Marketing Aesthetic feat. Karim Lateef/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:32:22,265 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 0/42673 positive
[Rank 0] 2026-01-23 12:32:22,295 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/All The Fly Kids_Chaos & Culture Episode 10 Rethinking the Urban Marketing Aesthetic feat. Karim Lateef/metadata_shift_1.json
[Rank 0] 2026-01-23 12:32:22,295 - podcast_processing.episode_processor - INFO - Completed episode: All The Fly Kids_Chaos & Culture Episode 10 Rethinking the Urban Marketing Aesthetic feat. Karim Lateef
[Rank 0] 2026-01-23 12:32:22,372 - podcast_processing.distributed_orchestrator - INFO - âœ“ All The Fly Kids_Chaos & Culture Episode 10 Rethinking the Urban Marketing Aesthetic feat. Karim Lateef
[Rank 0] 2026-01-23 12:32:22,375 - podcast_processing.episode_processor - INFO - Processing episode: All The Fly Kids_Episode 125 The "End is Near" Episode with Geronimo Knows and Chelle B.
[Rank 0] 2026-01-23 12:32:22,384 - podcast_processing.label_generator - DEBUG - Loaded 82 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/All The Fly Kids_Episode 125 The "End is Near" Episode with Geronimo Knows and Chelle B..json
[Rank 0] 2026-01-23 12:32:22,385 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_01 (longer), SPEAKER_02 (shorter)
[Rank 0] 2026-01-23 12:32:22,580 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [250.04, 250.22], using fallback
[Rank 0] 2026-01-23 12:32:22,636 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [329.72, 329.72], using fallback
[Rank 0] 2026-01-23 12:32:22,643 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [335.96, 335.96], using fallback
[Rank 0] 2026-01-23 12:32:22,918 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [764.02, 764.21], using fallback
[Rank 0] 2026-01-23 12:32:23,520 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1598.07, 1598.58], using fallback
[Rank 0] 2026-01-23 12:32:23,691 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1824.30, 1824.57], using fallback
[Rank 0] 2026-01-23 12:32:24,004 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2245.80, 2246.28], using fallback
[Rank 0] 2026-01-23 12:32:24,410 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2796.26, 2796.46], using fallback
[Rank 0] 2026-01-23 12:32:24,680 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3153.18, 3153.66], using fallback
[Rank 0] 2026-01-23 12:32:24,680 - podcast_processing.alignment_merger - INFO - Created 9029 word alignments
[Rank 0] 2026-01-23 12:32:25,407 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_01: torch.Size([1, 75733184]), SPEAKER_02: torch.Size([1, 75733184])
[Rank 0] 2026-01-23 12:32:25,407 - podcast_processing.episode_processor - INFO - Episode duration: 3155.55s
[Rank 0] 2026-01-23 12:32:25,407 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:32:25,408 - podcast_processing.audio_masking - DEBUG - Creating mask from 43 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:32:25,455 - podcast_processing.audio_masking - DEBUG - Mask covers 327601/75733184 samples (0.43%)
[Rank 0] 2026-01-23 12:32:25,491 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 327601/75733184 samples masked
[Rank 0] 2026-01-23 12:32:26,324 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 327601/75733184 samples zeroed
[Rank 0] 2026-01-23 12:32:26,324 - podcast_processing.episode_processor - INFO - Audio is 3155.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:32:26,324 - podcast_processing.episode_processor - INFO - Processing 3155.5s audio in 16 chunks of 210s each
[Rank 0] 2026-01-23 12:32:26,324 - podcast_processing.episode_processor - INFO -   Processing chunk 1/16 (210.0s)
[Rank 0] 2026-01-23 12:32:26,377 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 28080/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:26,465 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:26,466 - podcast_processing.episode_processor - DEBUG - System speaker has 255 words
[Rank 0] 2026-01-23 12:32:26,512 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:26,512 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:26,512 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:26,512 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:26,541 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:26,643 - podcast_processing.episode_processor - INFO -   Processing chunk 2/16 (210.0s)
[Rank 0] 2026-01-23 12:32:26,698 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 82561/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:26,796 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:26,796 - podcast_processing.episode_processor - DEBUG - System speaker has 480 words
[Rank 0] 2026-01-23 12:32:26,842 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:26,843 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:26,843 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:26,843 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:26,871 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:26,965 - podcast_processing.episode_processor - INFO -   Processing chunk 3/16 (210.0s)
[Rank 0] 2026-01-23 12:32:27,022 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:27,115 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:27,115 - podcast_processing.episode_processor - DEBUG - System speaker has 348 words
[Rank 0] 2026-01-23 12:32:27,162 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:27,162 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:27,162 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:27,187 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:27,214 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:27,307 - podcast_processing.episode_processor - INFO -   Processing chunk 4/16 (210.0s)
[Rank 0] 2026-01-23 12:32:27,367 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:27,457 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:27,457 - podcast_processing.episode_processor - DEBUG - System speaker has 121 words
[Rank 0] 2026-01-23 12:32:27,504 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:27,504 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:27,504 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:27,505 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:27,532 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:27,626 - podcast_processing.episode_processor - INFO -   Processing chunk 5/16 (210.0s)
[Rank 0] 2026-01-23 12:32:27,681 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:27,767 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:27,767 - podcast_processing.episode_processor - DEBUG - System speaker has 268 words
[Rank 0] 2026-01-23 12:32:27,814 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:27,814 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:27,814 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:27,815 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:27,842 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:27,947 - podcast_processing.episode_processor - INFO -   Processing chunk 6/16 (210.0s)
[Rank 0] 2026-01-23 12:32:28,003 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5520/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:28,085 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:28,744 - podcast_processing.episode_processor - DEBUG - System speaker has 380 words
[Rank 0] 2026-01-23 12:32:28,747 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:28,748 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:28,748 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:28,748 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:28,776 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:28,870 - podcast_processing.episode_processor - INFO -   Processing chunk 7/16 (210.0s)
[Rank 0] 2026-01-23 12:32:28,926 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 24238/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:29,008 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:29,008 - podcast_processing.episode_processor - DEBUG - System speaker has 247 words
[Rank 0] 2026-01-23 12:32:29,055 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:29,055 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:29,055 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:29,055 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:29,083 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:29,176 - podcast_processing.episode_processor - INFO -   Processing chunk 8/16 (210.0s)
[Rank 0] 2026-01-23 12:32:29,231 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 45122/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:29,320 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:29,320 - podcast_processing.episode_processor - DEBUG - System speaker has 447 words
[Rank 0] 2026-01-23 12:32:29,367 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:29,367 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:29,367 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:29,368 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:29,395 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:29,501 - podcast_processing.episode_processor - INFO -   Processing chunk 9/16 (210.0s)
[Rank 0] 2026-01-23 12:32:29,555 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 36722/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:29,637 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:29,638 - podcast_processing.episode_processor - DEBUG - System speaker has 451 words
[Rank 0] 2026-01-23 12:32:29,684 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:29,684 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:29,684 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:29,685 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:29,713 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:29,806 - podcast_processing.episode_processor - INFO -   Processing chunk 10/16 (210.0s)
[Rank 0] 2026-01-23 12:32:29,861 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 45115/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:29,943 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:29,943 - podcast_processing.episode_processor - DEBUG - System speaker has 355 words
[Rank 0] 2026-01-23 12:32:29,989 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:29,989 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:29,990 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:29,990 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:30,018 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:30,111 - podcast_processing.episode_processor - INFO -   Processing chunk 11/16 (210.0s)
[Rank 0] 2026-01-23 12:32:30,166 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 60243/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:30,255 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:30,255 - podcast_processing.episode_processor - DEBUG - System speaker has 241 words
[Rank 0] 2026-01-23 12:32:30,301 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:30,302 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:30,302 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:30,302 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:30,331 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:30,436 - podcast_processing.episode_processor - INFO -   Processing chunk 12/16 (210.0s)
[Rank 0] 2026-01-23 12:32:30,492 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:30,585 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:30,585 - podcast_processing.episode_processor - DEBUG - System speaker has 276 words
[Rank 0] 2026-01-23 12:32:30,632 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:30,632 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:30,632 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:30,632 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:30,660 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:30,766 - podcast_processing.episode_processor - INFO -   Processing chunk 13/16 (210.0s)
[Rank 0] 2026-01-23 12:32:30,821 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:30,907 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:30,907 - podcast_processing.episode_processor - DEBUG - System speaker has 148 words
[Rank 0] 2026-01-23 12:32:30,954 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:30,954 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:30,955 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:30,955 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:30,982 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:31,086 - podcast_processing.episode_processor - INFO -   Processing chunk 14/16 (210.0s)
[Rank 0] 2026-01-23 12:32:31,141 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:31,223 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:31,223 - podcast_processing.episode_processor - DEBUG - System speaker has 252 words
[Rank 0] 2026-01-23 12:32:31,270 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:31,270 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:31,270 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:31,271 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:31,298 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:31,397 - podcast_processing.episode_processor - INFO -   Processing chunk 15/16 (210.0s)
[Rank 0] 2026-01-23 12:32:31,455 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:31,538 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:31,538 - podcast_processing.episode_processor - DEBUG - System speaker has 117 words
[Rank 0] 2026-01-23 12:32:31,584 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:31,584 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:31,584 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:31,585 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:31,613 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:31,728 - podcast_processing.episode_processor - INFO -   Processing chunk 16/16 (5.5s)
[Rank 0] 2026-01-23 12:32:31,731 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/133184 samples zeroed
[Rank 0] 2026-01-23 12:32:31,780 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 70]), System codes shape: torch.Size([1, 8, 70])
[Rank 0] 2026-01-23 12:32:31,780 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:32:31,780 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 70])
[Rank 0] 2026-01-23 12:32:31,780 - podcast_processing.episode_processor - DEBUG - Padded to max_t=70
[Rank 0] 2026-01-23 12:32:31,780 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 70]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:31,781 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 71])
[Rank 0] 2026-01-23 12:32:31,823 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 70, 4096])
[Rank 0] 2026-01-23 12:32:32,068 - podcast_processing.episode_processor - INFO - Combined 16 chunks into final output shape: torch.Size([39445, 4096])
[Rank 0] 2026-01-23 12:32:33,653 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/All The Fly Kids_Episode 125 The "End is Near" Episode with Geronimo Knows and Chelle B./features_assignment_0.npy
[Rank 0] 2026-01-23 12:32:33,653 - podcast_processing.episode_processor - INFO -   Saved features: 39445 frames
[Rank 0] 2026-01-23 12:32:33,654 - podcast_processing.label_generator - DEBUG - Processing 39 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:32:33,667 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/All The Fly Kids_Episode 125 The "End is Near" Episode with Geronimo Knows and Chelle B./labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:32:33,667 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 144/39445 positive
[Rank 0] 2026-01-23 12:32:33,667 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:32:33,709 - podcast_processing.audio_masking - DEBUG - Creating mask from 39 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:32:33,748 - podcast_processing.audio_masking - DEBUG - Mask covers 272405/75733184 samples (0.36%)
[Rank 0] 2026-01-23 12:32:33,785 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 272405/75733184 samples masked
[Rank 0] 2026-01-23 12:32:34,536 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 272405/75733184 samples zeroed
[Rank 0] 2026-01-23 12:32:34,536 - podcast_processing.episode_processor - INFO - Audio is 3155.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:32:34,536 - podcast_processing.episode_processor - INFO - Processing 3155.5s audio in 16 chunks of 210s each
[Rank 0] 2026-01-23 12:32:34,536 - podcast_processing.episode_processor - INFO -   Processing chunk 1/16 (210.0s)
[Rank 0] 2026-01-23 12:32:34,579 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:34,669 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:34,669 - podcast_processing.episode_processor - DEBUG - System speaker has 318 words
[Rank 0] 2026-01-23 12:32:34,715 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:34,716 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:34,716 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:34,716 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:34,745 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:34,869 - podcast_processing.episode_processor - INFO -   Processing chunk 2/16 (210.0s)
[Rank 0] 2026-01-23 12:32:34,909 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 26400/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:35,007 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:35,007 - podcast_processing.episode_processor - DEBUG - System speaker has 106 words
[Rank 0] 2026-01-23 12:32:35,054 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:35,054 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:35,054 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:35,055 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:35,083 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:35,186 - podcast_processing.episode_processor - INFO -   Processing chunk 3/16 (210.0s)
[Rank 0] 2026-01-23 12:32:35,222 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 50160/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:35,309 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:35,309 - podcast_processing.episode_processor - DEBUG - System speaker has 174 words
[Rank 0] 2026-01-23 12:32:35,356 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:35,356 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:35,356 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:35,357 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:35,384 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:35,478 - podcast_processing.episode_processor - INFO -   Processing chunk 4/16 (210.0s)
[Rank 0] 2026-01-23 12:32:35,514 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:35,603 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:35,603 - podcast_processing.episode_processor - DEBUG - System speaker has 429 words
[Rank 0] 2026-01-23 12:32:35,649 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:35,650 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:35,650 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:35,650 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:35,678 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:35,761 - podcast_processing.episode_processor - INFO -   Processing chunk 5/16 (210.0s)
[Rank 0] 2026-01-23 12:32:35,813 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:35,922 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:35,922 - podcast_processing.episode_processor - DEBUG - System speaker has 296 words
[Rank 0] 2026-01-23 12:32:35,968 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:35,969 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:35,969 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:35,969 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:35,997 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:36,080 - podcast_processing.episode_processor - INFO -   Processing chunk 6/16 (210.0s)
[Rank 0] 2026-01-23 12:32:36,132 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:36,220 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:36,220 - podcast_processing.episode_processor - DEBUG - System speaker has 227 words
[Rank 0] 2026-01-23 12:32:36,266 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:36,266 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:36,266 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:36,267 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:36,295 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:36,402 - podcast_processing.episode_processor - INFO -   Processing chunk 7/16 (210.0s)
[Rank 0] 2026-01-23 12:32:36,461 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 43200/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:36,565 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:36,565 - podcast_processing.episode_processor - DEBUG - System speaker has 364 words
[Rank 0] 2026-01-23 12:32:36,611 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:36,718 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:36,718 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:36,719 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:36,746 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:36,840 - podcast_processing.episode_processor - INFO -   Processing chunk 8/16 (210.0s)
[Rank 0] 2026-01-23 12:32:36,899 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5519/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:36,996 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:36,996 - podcast_processing.episode_processor - DEBUG - System speaker has 194 words
[Rank 0] 2026-01-23 12:32:37,043 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:37,043 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:37,044 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:37,044 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:37,073 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:37,166 - podcast_processing.episode_processor - INFO -   Processing chunk 9/16 (210.0s)
[Rank 0] 2026-01-23 12:32:37,228 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12959/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:37,316 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:37,316 - podcast_processing.episode_processor - DEBUG - System speaker has 130 words
[Rank 0] 2026-01-23 12:32:37,363 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:37,363 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:37,363 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:37,364 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:37,391 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:37,485 - podcast_processing.episode_processor - INFO -   Processing chunk 10/16 (210.0s)
[Rank 0] 2026-01-23 12:32:37,546 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 49924/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:37,634 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:37,634 - podcast_processing.episode_processor - DEBUG - System speaker has 273 words
[Rank 0] 2026-01-23 12:32:37,681 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:37,681 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:37,681 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:37,682 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:37,709 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:37,809 - podcast_processing.episode_processor - INFO -   Processing chunk 11/16 (210.0s)
[Rank 0] 2026-01-23 12:32:37,868 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 56882/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:37,956 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:37,956 - podcast_processing.episode_processor - DEBUG - System speaker has 382 words
[Rank 0] 2026-01-23 12:32:38,002 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:38,003 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:38,003 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:38,003 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:38,030 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:38,128 - podcast_processing.episode_processor - INFO -   Processing chunk 12/16 (210.0s)
[Rank 0] 2026-01-23 12:32:38,187 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 14640/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:38,275 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:38,275 - podcast_processing.episode_processor - DEBUG - System speaker has 356 words
[Rank 0] 2026-01-23 12:32:38,321 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:38,321 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:38,321 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:38,322 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:38,350 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:38,464 - podcast_processing.episode_processor - INFO -   Processing chunk 13/16 (210.0s)
[Rank 0] 2026-01-23 12:32:38,522 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:38,632 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:38,632 - podcast_processing.episode_processor - DEBUG - System speaker has 409 words
[Rank 0] 2026-01-23 12:32:38,678 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:38,679 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:38,679 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:38,679 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:38,708 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:38,807 - podcast_processing.episode_processor - INFO -   Processing chunk 14/16 (210.0s)
[Rank 0] 2026-01-23 12:32:38,866 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7201/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:38,954 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:38,954 - podcast_processing.episode_processor - DEBUG - System speaker has 434 words
[Rank 0] 2026-01-23 12:32:39,001 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:39,001 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:39,001 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:39,002 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:39,029 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:39,122 - podcast_processing.episode_processor - INFO -   Processing chunk 15/16 (210.0s)
[Rank 0] 2026-01-23 12:32:39,181 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5520/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:39,269 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:39,269 - podcast_processing.episode_processor - DEBUG - System speaker has 459 words
[Rank 0] 2026-01-23 12:32:39,316 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:39,316 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:39,316 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:39,316 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:39,344 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:39,437 - podcast_processing.episode_processor - INFO -   Processing chunk 16/16 (5.5s)
[Rank 0] 2026-01-23 12:32:39,439 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/133184 samples zeroed
[Rank 0] 2026-01-23 12:32:39,461 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 70]), System codes shape: torch.Size([1, 8, 70])
[Rank 0] 2026-01-23 12:32:39,461 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:32:39,461 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 70])
[Rank 0] 2026-01-23 12:32:39,461 - podcast_processing.episode_processor - DEBUG - Padded to max_t=70
[Rank 0] 2026-01-23 12:32:39,461 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 70]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:39,462 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 71])
[Rank 0] 2026-01-23 12:32:39,489 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 70, 4096])
[Rank 0] 2026-01-23 12:32:39,705 - podcast_processing.episode_processor - INFO - Combined 16 chunks into final output shape: torch.Size([39445, 4096])
[Rank 0] 2026-01-23 12:32:42,366 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/All The Fly Kids_Episode 125 The "End is Near" Episode with Geronimo Knows and Chelle B./features_assignment_1.npy
[Rank 0] 2026-01-23 12:32:42,366 - podcast_processing.episode_processor - INFO -   Saved features: 39445 frames
[Rank 0] 2026-01-23 12:32:42,367 - podcast_processing.label_generator - DEBUG - Processing 43 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:32:42,403 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/All The Fly Kids_Episode 125 The "End is Near" Episode with Geronimo Knows and Chelle B./labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:32:42,403 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 172/39445 positive
[Rank 0] 2026-01-23 12:32:42,422 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/All The Fly Kids_Episode 125 The "End is Near" Episode with Geronimo Knows and Chelle B./metadata_shift_1.json
[Rank 0] 2026-01-23 12:32:42,422 - podcast_processing.episode_processor - INFO - Completed episode: All The Fly Kids_Episode 125 The "End is Near" Episode with Geronimo Knows and Chelle B.
[Rank 0] 2026-01-23 12:32:42,473 - podcast_processing.distributed_orchestrator - INFO - âœ“ All The Fly Kids_Episode 125 The "End is Near" Episode with Geronimo Knows and Chelle B.
[Rank 0] 2026-01-23 12:32:42,479 - podcast_processing.episode_processor - INFO - Processing episode: All The Fly Kids_Episode 64 "Places and Spaces I've Been" with Timothy Anne Burnside of the Smithsonian NMAAHC
[Rank 0] 2026-01-23 12:32:42,485 - podcast_processing.label_generator - DEBUG - Loaded 96 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/All The Fly Kids_Episode 64 "Places and Spaces I've Been" with Timothy Anne Burnside of the Smithsonian NMAAHC.json
[Rank 0] 2026-01-23 12:32:42,487 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_00 (longer), SPEAKER_03 (shorter)
[Rank 0] 2026-01-23 12:32:43,610 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1454.73, 1454.73], using fallback
[Rank 0] 2026-01-23 12:32:43,977 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1989.69, 1989.96], using fallback
[Rank 0] 2026-01-23 12:32:44,155 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2231.01, 2231.28], using fallback
[Rank 0] 2026-01-23 12:32:44,296 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2450.16, 2450.22], using fallback
[Rank 0] 2026-01-23 12:32:44,522 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2728.90, 2729.14], using fallback
[Rank 0] 2026-01-23 12:32:44,578 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2811.16, 2811.25], using fallback
[Rank 0] 2026-01-23 12:32:44,578 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2811.48, 2811.67], using fallback
[Rank 0] 2026-01-23 12:32:44,579 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2811.70, 2811.88], using fallback
[Rank 0] 2026-01-23 12:32:44,609 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2871.15, 2871.39], using fallback
[Rank 0] 2026-01-23 12:32:44,612 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2875.71, 2875.77], using fallback
[Rank 0] 2026-01-23 12:32:44,635 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2918.46, 2918.64], using fallback
[Rank 0] 2026-01-23 12:32:44,925 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3313.20, 3313.38], using fallback
[Rank 0] 2026-01-23 12:32:44,925 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3313.41, 3313.83], using fallback
[Rank 0] 2026-01-23 12:32:45,016 - podcast_processing.alignment_merger - INFO - Created 10249 word alignments
[Rank 0] 2026-01-23 12:32:45,810 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_00: torch.Size([1, 82916272]), SPEAKER_03: torch.Size([1, 82916272])
[Rank 0] 2026-01-23 12:32:45,811 - podcast_processing.episode_processor - INFO - Episode duration: 3454.84s
[Rank 0] 2026-01-23 12:32:45,811 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:32:45,811 - podcast_processing.audio_masking - DEBUG - Creating mask from 31 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:32:45,861 - podcast_processing.audio_masking - DEBUG - Mask covers 305518/82916272 samples (0.37%)
[Rank 0] 2026-01-23 12:32:45,897 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 305518/82916272 samples masked
[Rank 0] 2026-01-23 12:32:46,781 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 305518/82916272 samples zeroed
[Rank 0] 2026-01-23 12:32:46,781 - podcast_processing.episode_processor - INFO - Audio is 3454.8s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:32:46,781 - podcast_processing.episode_processor - INFO - Processing 3454.8s audio in 17 chunks of 210s each
[Rank 0] 2026-01-23 12:32:46,781 - podcast_processing.episode_processor - INFO -   Processing chunk 1/17 (210.0s)
[Rank 0] 2026-01-23 12:32:46,838 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:46,926 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:46,926 - podcast_processing.episode_processor - DEBUG - System speaker has 450 words
[Rank 0] 2026-01-23 12:32:46,972 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:46,972 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:46,973 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:46,973 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:47,002 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:47,109 - podcast_processing.episode_processor - INFO -   Processing chunk 2/17 (210.0s)
[Rank 0] 2026-01-23 12:32:47,165 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 40079/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:47,248 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:47,353 - podcast_processing.episode_processor - DEBUG - System speaker has 294 words
[Rank 0] 2026-01-23 12:32:47,356 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:47,356 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:47,356 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:47,356 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:47,385 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:47,478 - podcast_processing.episode_processor - INFO -   Processing chunk 3/17 (210.0s)
[Rank 0] 2026-01-23 12:32:47,533 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:47,617 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:47,857 - podcast_processing.episode_processor - DEBUG - System speaker has 125 words
[Rank 0] 2026-01-23 12:32:47,859 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:47,859 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:47,859 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:47,860 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:47,887 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:47,987 - podcast_processing.episode_processor - INFO -   Processing chunk 4/17 (210.0s)
[Rank 0] 2026-01-23 12:32:48,043 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 25919/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:48,125 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:48,126 - podcast_processing.episode_processor - DEBUG - System speaker has 253 words
[Rank 0] 2026-01-23 12:32:48,172 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:48,172 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:48,172 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:48,173 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:48,200 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:48,295 - podcast_processing.episode_processor - INFO -   Processing chunk 5/17 (210.0s)
[Rank 0] 2026-01-23 12:32:48,350 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:48,432 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:48,433 - podcast_processing.episode_processor - DEBUG - System speaker has 121 words
[Rank 0] 2026-01-23 12:32:48,479 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:48,479 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:48,479 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:48,480 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:48,507 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:48,612 - podcast_processing.episode_processor - INFO -   Processing chunk 6/17 (210.0s)
[Rank 0] 2026-01-23 12:32:48,675 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:48,757 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:48,757 - podcast_processing.episode_processor - DEBUG - System speaker has 142 words
[Rank 0] 2026-01-23 12:32:48,803 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:48,804 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:48,804 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:48,804 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:48,831 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:48,926 - podcast_processing.episode_processor - INFO -   Processing chunk 7/17 (210.0s)
[Rank 0] 2026-01-23 12:32:48,981 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:49,068 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:49,068 - podcast_processing.episode_processor - DEBUG - System speaker has 119 words
[Rank 0] 2026-01-23 12:32:49,115 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:49,115 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:49,115 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:49,116 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:49,143 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:49,240 - podcast_processing.episode_processor - INFO -   Processing chunk 8/17 (210.0s)
[Rank 0] 2026-01-23 12:32:49,296 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:49,378 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:49,378 - podcast_processing.episode_processor - DEBUG - System speaker has 77 words
[Rank 0] 2026-01-23 12:32:49,425 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:49,425 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:49,425 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:49,426 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:49,453 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:49,550 - podcast_processing.episode_processor - INFO -   Processing chunk 9/17 (210.0s)
[Rank 0] 2026-01-23 12:32:49,606 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:49,708 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:49,708 - podcast_processing.episode_processor - DEBUG - System speaker has 92 words
[Rank 0] 2026-01-23 12:32:49,754 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:49,755 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:49,755 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:49,755 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:49,783 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:49,880 - podcast_processing.episode_processor - INFO -   Processing chunk 10/17 (210.0s)
[Rank 0] 2026-01-23 12:32:49,934 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6478/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:50,058 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:50,058 - podcast_processing.episode_processor - DEBUG - System speaker has 22 words
[Rank 0] 2026-01-23 12:32:50,105 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:50,105 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:50,105 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:50,106 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:50,133 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:50,238 - podcast_processing.episode_processor - INFO -   Processing chunk 11/17 (210.0s)
[Rank 0] 2026-01-23 12:32:50,295 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 58563/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:50,395 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:50,396 - podcast_processing.episode_processor - DEBUG - System speaker has 194 words
[Rank 0] 2026-01-23 12:32:50,442 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:50,442 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:50,442 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:50,443 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:50,470 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:50,703 - podcast_processing.episode_processor - INFO -   Processing chunk 12/17 (210.0s)
[Rank 0] 2026-01-23 12:32:50,760 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 8880/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:50,842 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:50,842 - podcast_processing.episode_processor - DEBUG - System speaker has 55 words
[Rank 0] 2026-01-23 12:32:50,888 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:50,889 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:50,889 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:50,889 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:50,916 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:51,009 - podcast_processing.episode_processor - INFO -   Processing chunk 13/17 (210.0s)
[Rank 0] 2026-01-23 12:32:51,066 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 23517/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:51,148 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:51,148 - podcast_processing.episode_processor - DEBUG - System speaker has 142 words
[Rank 0] 2026-01-23 12:32:51,195 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:51,195 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:51,195 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:51,196 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:51,223 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:51,330 - podcast_processing.episode_processor - INFO -   Processing chunk 14/17 (210.0s)
[Rank 0] 2026-01-23 12:32:51,386 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 22561/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:51,468 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:51,468 - podcast_processing.episode_processor - DEBUG - System speaker has 114 words
[Rank 0] 2026-01-23 12:32:51,514 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:51,515 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:51,515 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:51,515 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:51,542 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:51,654 - podcast_processing.episode_processor - INFO -   Processing chunk 15/17 (210.0s)
[Rank 0] 2026-01-23 12:32:51,708 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 53521/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:51,821 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:52,173 - podcast_processing.episode_processor - DEBUG - System speaker has 228 words
[Rank 0] 2026-01-23 12:32:52,176 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:52,176 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:52,176 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:52,176 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:52,204 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:52,296 - podcast_processing.episode_processor - INFO -   Processing chunk 16/17 (210.0s)
[Rank 0] 2026-01-23 12:32:52,352 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 29280/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:52,451 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:52,452 - podcast_processing.episode_processor - DEBUG - System speaker has 91 words
[Rank 0] 2026-01-23 12:32:52,498 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:52,498 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:52,498 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:52,498 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:52,527 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:52,631 - podcast_processing.episode_processor - INFO -   Processing chunk 17/17 (94.8s)
[Rank 0] 2026-01-23 12:32:52,650 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 36720/2276272 samples zeroed
[Rank 0] 2026-01-23 12:32:52,727 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1186]), System codes shape: torch.Size([1, 8, 1186])
[Rank 0] 2026-01-23 12:32:52,727 - podcast_processing.episode_processor - DEBUG - System speaker has 39 words
[Rank 0] 2026-01-23 12:32:52,739 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1186])
[Rank 0] 2026-01-23 12:32:52,739 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1186
[Rank 0] 2026-01-23 12:32:52,739 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1186]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:52,740 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1187])
[Rank 0] 2026-01-23 12:32:52,776 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1186, 4096])
[Rank 0] 2026-01-23 12:32:53,003 - podcast_processing.episode_processor - INFO - Combined 17 chunks into final output shape: torch.Size([43186, 4096])
[Rank 0] 2026-01-23 12:32:55,259 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/All The Fly Kids_Episode 64 "Places and Spaces I've Been" with Timothy Anne Burnside of the Smithsonian NMAAHC/features_assignment_0.npy
[Rank 0] 2026-01-23 12:32:55,259 - podcast_processing.episode_processor - INFO -   Saved features: 43186 frames
[Rank 0] 2026-01-23 12:32:55,269 - podcast_processing.label_generator - DEBUG - Processing 65 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:32:55,310 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/All The Fly Kids_Episode 64 "Places and Spaces I've Been" with Timothy Anne Burnside of the Smithsonian NMAAHC/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:32:55,310 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 244/43186 positive
[Rank 0] 2026-01-23 12:32:55,315 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:32:55,327 - podcast_processing.audio_masking - DEBUG - Creating mask from 65 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:32:55,405 - podcast_processing.audio_masking - DEBUG - Mask covers 457194/82916272 samples (0.55%)
[Rank 0] 2026-01-23 12:32:55,445 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 457194/82916272 samples masked
[Rank 0] 2026-01-23 12:32:56,273 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 457194/82916272 samples zeroed
[Rank 0] 2026-01-23 12:32:56,274 - podcast_processing.episode_processor - INFO - Audio is 3454.8s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:32:56,274 - podcast_processing.episode_processor - INFO - Processing 3454.8s audio in 17 chunks of 210s each
[Rank 0] 2026-01-23 12:32:56,274 - podcast_processing.episode_processor - INFO -   Processing chunk 1/17 (210.0s)
[Rank 0] 2026-01-23 12:32:56,310 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:56,416 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:56,416 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:32:56,462 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:56,462 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:56,462 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:56,463 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:56,491 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:56,576 - podcast_processing.episode_processor - INFO -   Processing chunk 2/17 (210.0s)
[Rank 0] 2026-01-23 12:32:56,611 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:56,699 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:56,699 - podcast_processing.episode_processor - DEBUG - System speaker has 288 words
[Rank 0] 2026-01-23 12:32:56,746 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:56,746 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:56,746 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:56,747 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:56,775 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:56,866 - podcast_processing.episode_processor - INFO -   Processing chunk 3/17 (210.0s)
[Rank 0] 2026-01-23 12:32:56,901 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 10080/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:56,989 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:56,989 - podcast_processing.episode_processor - DEBUG - System speaker has 375 words
[Rank 0] 2026-01-23 12:32:57,035 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:57,035 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:57,035 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:57,036 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:57,063 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:57,154 - podcast_processing.episode_processor - INFO -   Processing chunk 4/17 (210.0s)
[Rank 0] 2026-01-23 12:32:57,188 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4319/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:57,292 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:57,292 - podcast_processing.episode_processor - DEBUG - System speaker has 363 words
[Rank 0] 2026-01-23 12:32:57,339 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:57,339 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:57,339 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:57,339 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:57,367 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:57,468 - podcast_processing.episode_processor - INFO -   Processing chunk 5/17 (210.0s)
[Rank 0] 2026-01-23 12:32:58,389 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 15360/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:58,517 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:58,517 - podcast_processing.episode_processor - DEBUG - System speaker has 346 words
[Rank 0] 2026-01-23 12:32:58,563 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:58,563 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:58,563 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:58,564 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:58,591 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:58,700 - podcast_processing.episode_processor - INFO -   Processing chunk 6/17 (210.0s)
[Rank 0] 2026-01-23 12:32:58,735 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:58,829 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:58,829 - podcast_processing.episode_processor - DEBUG - System speaker has 562 words
[Rank 0] 2026-01-23 12:32:58,875 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:58,875 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:58,876 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:58,876 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:58,904 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:59,008 - podcast_processing.episode_processor - INFO -   Processing chunk 7/17 (210.0s)
[Rank 0] 2026-01-23 12:32:59,043 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:59,146 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:59,146 - podcast_processing.episode_processor - DEBUG - System speaker has 471 words
[Rank 0] 2026-01-23 12:32:59,193 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:59,193 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:59,193 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:59,194 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:59,221 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:59,314 - podcast_processing.episode_processor - INFO -   Processing chunk 8/17 (210.0s)
[Rank 0] 2026-01-23 12:32:59,361 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11999/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:59,453 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:59,453 - podcast_processing.episode_processor - DEBUG - System speaker has 456 words
[Rank 0] 2026-01-23 12:32:59,500 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:59,500 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:59,500 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:59,500 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:59,528 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:59,631 - podcast_processing.episode_processor - INFO -   Processing chunk 9/17 (210.0s)
[Rank 0] 2026-01-23 12:32:59,678 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 82319/5040000 samples zeroed
[Rank 0] 2026-01-23 12:32:59,765 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:32:59,765 - podcast_processing.episode_processor - DEBUG - System speaker has 502 words
[Rank 0] 2026-01-23 12:32:59,812 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:32:59,812 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:32:59,812 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:32:59,812 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:32:59,839 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:32:59,932 - podcast_processing.episode_processor - INFO -   Processing chunk 10/17 (210.0s)
[Rank 0] 2026-01-23 12:32:59,979 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:00,066 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:00,066 - podcast_processing.episode_processor - DEBUG - System speaker has 495 words
[Rank 0] 2026-01-23 12:33:00,113 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:00,113 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:00,113 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:00,114 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:00,143 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:00,234 - podcast_processing.episode_processor - INFO -   Processing chunk 11/17 (210.0s)
[Rank 0] 2026-01-23 12:33:00,280 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 55683/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:00,367 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:00,367 - podcast_processing.episode_processor - DEBUG - System speaker has 384 words
[Rank 0] 2026-01-23 12:33:00,414 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:00,414 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:00,414 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:00,414 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:00,441 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:00,535 - podcast_processing.episode_processor - INFO -   Processing chunk 12/17 (210.0s)
[Rank 0] 2026-01-23 12:33:00,583 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 54956/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:00,670 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:00,670 - podcast_processing.episode_processor - DEBUG - System speaker has 421 words
[Rank 0] 2026-01-23 12:33:00,717 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:00,717 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:00,717 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:00,718 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:00,744 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:00,839 - podcast_processing.episode_processor - INFO -   Processing chunk 13/17 (210.0s)
[Rank 0] 2026-01-23 12:33:00,894 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 15117/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:00,981 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:00,981 - podcast_processing.episode_processor - DEBUG - System speaker has 481 words
[Rank 0] 2026-01-23 12:33:01,028 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:01,028 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:01,028 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:01,029 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:01,056 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:01,149 - podcast_processing.episode_processor - INFO -   Processing chunk 14/17 (210.0s)
[Rank 0] 2026-01-23 12:33:01,197 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 122645/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:01,311 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:01,311 - podcast_processing.episode_processor - DEBUG - System speaker has 357 words
[Rank 0] 2026-01-23 12:33:01,358 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:01,358 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:01,358 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:01,358 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:01,386 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:01,479 - podcast_processing.episode_processor - INFO -   Processing chunk 15/17 (210.0s)
[Rank 0] 2026-01-23 12:33:01,527 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 63836/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:01,619 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:01,619 - podcast_processing.episode_processor - DEBUG - System speaker has 304 words
[Rank 0] 2026-01-23 12:33:01,666 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:01,666 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:01,666 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:01,667 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:01,694 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:01,979 - podcast_processing.episode_processor - INFO -   Processing chunk 16/17 (210.0s)
[Rank 0] 2026-01-23 12:33:02,028 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4080/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:02,115 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:02,115 - podcast_processing.episode_processor - DEBUG - System speaker has 401 words
[Rank 0] 2026-01-23 12:33:02,162 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:02,162 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:02,162 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:02,163 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:02,191 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:02,287 - podcast_processing.episode_processor - INFO -   Processing chunk 17/17 (94.8s)
[Rank 0] 2026-01-23 12:33:02,355 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/2276272 samples zeroed
[Rank 0] 2026-01-23 12:33:02,396 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1186]), System codes shape: torch.Size([1, 8, 1186])
[Rank 0] 2026-01-23 12:33:02,396 - podcast_processing.episode_processor - DEBUG - System speaker has 77 words
[Rank 0] 2026-01-23 12:33:02,409 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1186])
[Rank 0] 2026-01-23 12:33:02,409 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1186
[Rank 0] 2026-01-23 12:33:02,409 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1186]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:02,409 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1187])
[Rank 0] 2026-01-23 12:33:02,436 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1186, 4096])
[Rank 0] 2026-01-23 12:33:02,663 - podcast_processing.episode_processor - INFO - Combined 17 chunks into final output shape: torch.Size([43186, 4096])
[Rank 0] 2026-01-23 12:33:04,766 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/All The Fly Kids_Episode 64 "Places and Spaces I've Been" with Timothy Anne Burnside of the Smithsonian NMAAHC/features_assignment_1.npy
[Rank 0] 2026-01-23 12:33:04,767 - podcast_processing.episode_processor - INFO -   Saved features: 43186 frames
[Rank 0] 2026-01-23 12:33:04,767 - podcast_processing.label_generator - DEBUG - Processing 31 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:33:04,791 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/All The Fly Kids_Episode 64 "Places and Spaces I've Been" with Timothy Anne Burnside of the Smithsonian NMAAHC/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:33:04,791 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 161/43186 positive
[Rank 0] 2026-01-23 12:33:04,802 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/All The Fly Kids_Episode 64 "Places and Spaces I've Been" with Timothy Anne Burnside of the Smithsonian NMAAHC/metadata_shift_1.json
[Rank 0] 2026-01-23 12:33:04,802 - podcast_processing.episode_processor - INFO - Completed episode: All The Fly Kids_Episode 64 "Places and Spaces I've Been" with Timothy Anne Burnside of the Smithsonian NMAAHC
[Rank 0] 2026-01-23 12:33:04,869 - podcast_processing.distributed_orchestrator - INFO - âœ“ All The Fly Kids_Episode 64 "Places and Spaces I've Been" with Timothy Anne Burnside of the Smithsonian NMAAHC
[Rank 0] 2026-01-23 12:33:04,908 - podcast_processing.episode_processor - INFO - Processing episode: Americhicks_10.4.18FBI Report On Kavanaugh-Homeless Urban Camping-Gov. Hickenlooper and Electric Cars
[Rank 0] 2026-01-23 12:33:04,944 - podcast_processing.label_generator - DEBUG - Loaded 18 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Americhicks_10.4.18FBI Report On Kavanaugh-Homeless Urban Camping-Gov. Hickenlooper and Electric Cars.json
[Rank 0] 2026-01-23 12:33:04,946 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_03 (longer), SPEAKER_01 (shorter)
[Rank 0] 2026-01-23 12:33:05,024 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [75.14, 75.26], using fallback
[Rank 0] 2026-01-23 12:33:05,197 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [762.62, 762.69], using fallback
[Rank 0] 2026-01-23 12:33:05,440 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1743.29, 1743.55], using fallback
[Rank 0] 2026-01-23 12:33:05,440 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1743.56, 1743.69], using fallback
[Rank 0] 2026-01-23 12:33:05,466 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1866.32, 1866.61], using fallback
[Rank 0] 2026-01-23 12:33:05,466 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1866.62, 1866.89], using fallback
[Rank 0] 2026-01-23 12:33:05,466 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1866.98, 1867.25], using fallback
[Rank 0] 2026-01-23 12:33:05,466 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1867.25, 1867.58], using fallback
[Rank 0] 2026-01-23 12:33:05,466 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1868.28, 1868.85], using fallback
[Rank 0] 2026-01-23 12:33:05,466 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1868.85, 1869.33], using fallback
[Rank 0] 2026-01-23 12:33:05,467 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1869.33, 1869.72], using fallback
[Rank 0] 2026-01-23 12:33:05,588 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2413.45, 2413.57], using fallback
[Rank 0] 2026-01-23 12:33:05,643 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2677.02, 2677.20], using fallback
[Rank 0] 2026-01-23 12:33:05,643 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2677.20, 2677.29], using fallback
[Rank 0] 2026-01-23 12:33:05,643 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2677.29, 2677.41], using fallback
[Rank 0] 2026-01-23 12:33:05,643 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2677.41, 2677.71], using fallback
[Rank 0] 2026-01-23 12:33:05,790 - podcast_processing.alignment_merger - INFO - Created 10521 word alignments
[Rank 0] 2026-01-23 12:33:06,395 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_03: torch.Size([1, 80086416]), SPEAKER_01: torch.Size([1, 80086416])
[Rank 0] 2026-01-23 12:33:06,395 - podcast_processing.episode_processor - INFO - Episode duration: 3336.93s
[Rank 0] 2026-01-23 12:33:06,395 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:33:06,402 - podcast_processing.audio_masking - DEBUG - Creating mask from 1 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:33:06,438 - podcast_processing.audio_masking - DEBUG - Mask covers 28559/80086416 samples (0.04%)
[Rank 0] 2026-01-23 12:33:06,474 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 28559/80086416 samples masked
[Rank 0] 2026-01-23 12:33:07,340 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 28559/80086416 samples zeroed
[Rank 0] 2026-01-23 12:33:07,340 - podcast_processing.episode_processor - INFO - Audio is 3336.9s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:33:07,341 - podcast_processing.episode_processor - INFO - Processing 3336.9s audio in 16 chunks of 210s each
[Rank 0] 2026-01-23 12:33:07,341 - podcast_processing.episode_processor - INFO -   Processing chunk 1/16 (210.0s)
[Rank 0] 2026-01-23 12:33:07,376 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:07,483 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:07,483 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:07,529 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:07,530 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:07,530 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:07,530 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:07,559 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:07,656 - podcast_processing.episode_processor - INFO -   Processing chunk 2/16 (210.0s)
[Rank 0] 2026-01-23 12:33:07,691 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 28559/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:07,774 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:07,774 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:07,821 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:07,821 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:07,821 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:07,822 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:07,849 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:07,932 - podcast_processing.episode_processor - INFO -   Processing chunk 3/16 (210.0s)
[Rank 0] 2026-01-23 12:33:07,967 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:08,049 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:08,049 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:08,095 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:08,095 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:08,096 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:08,096 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:08,124 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:08,207 - podcast_processing.episode_processor - INFO -   Processing chunk 4/16 (210.0s)
[Rank 0] 2026-01-23 12:33:08,243 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:08,325 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:08,325 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:08,372 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:08,372 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:08,372 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:08,372 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:08,400 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:08,483 - podcast_processing.episode_processor - INFO -   Processing chunk 5/16 (210.0s)
[Rank 0] 2026-01-23 12:33:08,642 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:08,724 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:08,724 - podcast_processing.episode_processor - DEBUG - System speaker has 139 words
[Rank 0] 2026-01-23 12:33:08,770 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:08,770 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:08,771 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:08,771 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:08,799 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:08,890 - podcast_processing.episode_processor - INFO -   Processing chunk 6/16 (210.0s)
[Rank 0] 2026-01-23 12:33:08,925 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:09,007 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:09,007 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:09,053 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:09,054 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:09,054 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:09,054 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:09,082 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:09,170 - podcast_processing.episode_processor - INFO -   Processing chunk 7/16 (210.0s)
[Rank 0] 2026-01-23 12:33:09,205 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:09,287 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:09,287 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:09,334 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:09,334 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:09,334 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:09,335 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:09,362 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:09,451 - podcast_processing.episode_processor - INFO -   Processing chunk 8/16 (210.0s)
[Rank 0] 2026-01-23 12:33:09,486 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:09,567 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:09,568 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:09,614 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:09,614 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:09,614 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:09,615 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:09,642 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:09,729 - podcast_processing.episode_processor - INFO -   Processing chunk 9/16 (210.0s)
[Rank 0] 2026-01-23 12:33:09,764 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:09,847 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:09,847 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:09,893 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:09,894 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:09,894 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:09,894 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:09,921 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:10,015 - podcast_processing.episode_processor - INFO -   Processing chunk 10/16 (210.0s)
[Rank 0] 2026-01-23 12:33:10,065 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:10,174 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:10,174 - podcast_processing.episode_processor - DEBUG - System speaker has 194 words
[Rank 0] 2026-01-23 12:33:10,221 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:10,221 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:10,221 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:10,222 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:10,249 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:10,343 - podcast_processing.episode_processor - INFO -   Processing chunk 11/16 (210.0s)
[Rank 0] 2026-01-23 12:33:10,390 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:10,492 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:10,492 - podcast_processing.episode_processor - DEBUG - System speaker has 426 words
[Rank 0] 2026-01-23 12:33:10,539 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:10,539 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:10,539 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:10,540 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:10,567 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:10,677 - podcast_processing.episode_processor - INFO -   Processing chunk 12/16 (210.0s)
[Rank 0] 2026-01-23 12:33:10,725 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:10,813 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:10,813 - podcast_processing.episode_processor - DEBUG - System speaker has 411 words
[Rank 0] 2026-01-23 12:33:10,860 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:10,860 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:10,860 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:10,860 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:10,888 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:10,989 - podcast_processing.episode_processor - INFO -   Processing chunk 13/16 (210.0s)
[Rank 0] 2026-01-23 12:33:11,037 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:11,131 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:11,131 - podcast_processing.episode_processor - DEBUG - System speaker has 13 words
[Rank 0] 2026-01-23 12:33:11,176 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:11,176 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:11,177 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:11,177 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:11,206 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:11,306 - podcast_processing.episode_processor - INFO -   Processing chunk 14/16 (210.0s)
[Rank 0] 2026-01-23 12:33:11,662 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:11,760 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:11,760 - podcast_processing.episode_processor - DEBUG - System speaker has 400 words
[Rank 0] 2026-01-23 12:33:11,807 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:11,807 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:11,807 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:11,807 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:11,835 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:11,945 - podcast_processing.episode_processor - INFO -   Processing chunk 15/16 (210.0s)
[Rank 0] 2026-01-23 12:33:11,992 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:12,084 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:12,084 - podcast_processing.episode_processor - DEBUG - System speaker has 470 words
[Rank 0] 2026-01-23 12:33:12,131 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:12,131 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:12,131 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:12,131 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:12,159 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:12,273 - podcast_processing.episode_processor - INFO -   Processing chunk 16/16 (186.9s)
[Rank 0] 2026-01-23 12:33:12,315 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/4486416 samples zeroed
[Rank 0] 2026-01-23 12:33:12,398 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2337]), System codes shape: torch.Size([1, 8, 2337])
[Rank 0] 2026-01-23 12:33:12,398 - podcast_processing.episode_processor - DEBUG - System speaker has 344 words
[Rank 0] 2026-01-23 12:33:12,437 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2337])
[Rank 0] 2026-01-23 12:33:12,437 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2337
[Rank 0] 2026-01-23 12:33:12,437 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2337]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:12,438 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2338])
[Rank 0] 2026-01-23 12:33:12,470 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2337, 4096])
[Rank 0] 2026-01-23 12:33:13,078 - podcast_processing.episode_processor - INFO - Combined 16 chunks into final output shape: torch.Size([41712, 4096])
[Rank 0] 2026-01-23 12:33:15,340 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Americhicks_10.4.18FBI Report On Kavanaugh-Homeless Urban Camping-Gov. Hickenlooper and Electric Cars/features_assignment_0.npy
[Rank 0] 2026-01-23 12:33:15,340 - podcast_processing.episode_processor - INFO -   Saved features: 41712 frames
[Rank 0] 2026-01-23 12:33:15,340 - podcast_processing.label_generator - DEBUG - Processing 17 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:33:15,373 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Americhicks_10.4.18FBI Report On Kavanaugh-Homeless Urban Camping-Gov. Hickenlooper and Electric Cars/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:33:15,373 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 60/41712 positive
[Rank 0] 2026-01-23 12:33:15,373 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:33:15,423 - podcast_processing.audio_masking - DEBUG - Creating mask from 17 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:33:15,470 - podcast_processing.audio_masking - DEBUG - Mask covers 115207/80086416 samples (0.14%)
[Rank 0] 2026-01-23 12:33:15,508 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 115207/80086416 samples masked
[Rank 0] 2026-01-23 12:33:16,409 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 115207/80086416 samples zeroed
[Rank 0] 2026-01-23 12:33:16,409 - podcast_processing.episode_processor - INFO - Audio is 3336.9s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:33:16,410 - podcast_processing.episode_processor - INFO - Processing 3336.9s audio in 16 chunks of 210s each
[Rank 0] 2026-01-23 12:33:16,410 - podcast_processing.episode_processor - INFO -   Processing chunk 1/16 (210.0s)
[Rank 0] 2026-01-23 12:33:16,445 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12960/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:16,530 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:16,530 - podcast_processing.episode_processor - DEBUG - System speaker has 538 words
[Rank 0] 2026-01-23 12:33:16,576 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:16,576 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:16,576 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:16,577 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:16,605 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:16,702 - podcast_processing.episode_processor - INFO -   Processing chunk 2/16 (210.0s)
[Rank 0] 2026-01-23 12:33:16,737 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:16,819 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:16,819 - podcast_processing.episode_processor - DEBUG - System speaker has 570 words
[Rank 0] 2026-01-23 12:33:16,865 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:16,865 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:16,866 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:16,866 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:16,893 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:16,989 - podcast_processing.episode_processor - INFO -   Processing chunk 3/16 (210.0s)
[Rank 0] 2026-01-23 12:33:17,024 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12960/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:17,131 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:17,131 - podcast_processing.episode_processor - DEBUG - System speaker has 665 words
[Rank 0] 2026-01-23 12:33:17,176 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:17,176 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:17,177 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:17,177 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:17,205 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:17,319 - podcast_processing.episode_processor - INFO -   Processing chunk 4/16 (210.0s)
[Rank 0] 2026-01-23 12:33:17,354 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4320/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:17,451 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:17,451 - podcast_processing.episode_processor - DEBUG - System speaker has 622 words
[Rank 0] 2026-01-23 12:33:17,497 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:17,497 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:17,498 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:17,498 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:17,526 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:17,609 - podcast_processing.episode_processor - INFO -   Processing chunk 5/16 (210.0s)
[Rank 0] 2026-01-23 12:33:17,644 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:17,755 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:17,755 - podcast_processing.episode_processor - DEBUG - System speaker has 490 words
[Rank 0] 2026-01-23 12:33:17,802 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:17,802 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:17,802 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:17,803 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:17,830 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:17,912 - podcast_processing.episode_processor - INFO -   Processing chunk 6/16 (210.0s)
[Rank 0] 2026-01-23 12:33:17,946 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:18,086 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:18,086 - podcast_processing.episode_processor - DEBUG - System speaker has 645 words
[Rank 0] 2026-01-23 12:33:18,133 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:18,133 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:18,133 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:18,133 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:18,160 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:18,247 - podcast_processing.episode_processor - INFO -   Processing chunk 7/16 (210.0s)
[Rank 0] 2026-01-23 12:33:18,281 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:18,382 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:18,382 - podcast_processing.episode_processor - DEBUG - System speaker has 740 words
[Rank 0] 2026-01-23 12:33:18,428 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:18,428 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:18,428 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:18,429 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:18,457 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:18,539 - podcast_processing.episode_processor - INFO -   Processing chunk 8/16 (210.0s)
[Rank 0] 2026-01-23 12:33:18,574 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:18,663 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:18,663 - podcast_processing.episode_processor - DEBUG - System speaker has 763 words
[Rank 0] 2026-01-23 12:33:18,710 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:18,710 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:18,710 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:18,711 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:18,738 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:18,836 - podcast_processing.episode_processor - INFO -   Processing chunk 9/16 (210.0s)
[Rank 0] 2026-01-23 12:33:18,870 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 23042/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:18,963 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:18,963 - podcast_processing.episode_processor - DEBUG - System speaker has 477 words
[Rank 0] 2026-01-23 12:33:19,009 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:19,010 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:19,010 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:19,010 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:19,038 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:19,159 - podcast_processing.episode_processor - INFO -   Processing chunk 10/16 (210.0s)
[Rank 0] 2026-01-23 12:33:19,194 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11522/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:19,275 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:19,275 - podcast_processing.episode_processor - DEBUG - System speaker has 475 words
[Rank 0] 2026-01-23 12:33:19,322 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:19,322 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:19,323 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:19,323 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:19,350 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:19,461 - podcast_processing.episode_processor - INFO -   Processing chunk 11/16 (210.0s)
[Rank 0] 2026-01-23 12:33:19,497 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:19,578 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:19,578 - podcast_processing.episode_processor - DEBUG - System speaker has 208 words
[Rank 0] 2026-01-23 12:33:19,625 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:19,625 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:19,626 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:19,626 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:19,654 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:19,737 - podcast_processing.episode_processor - INFO -   Processing chunk 12/16 (210.0s)
[Rank 0] 2026-01-23 12:33:19,772 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 13680/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:19,855 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:19,855 - podcast_processing.episode_processor - DEBUG - System speaker has 190 words
[Rank 0] 2026-01-23 12:33:19,901 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:19,901 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:19,901 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:19,902 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:19,929 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:20,012 - podcast_processing.episode_processor - INFO -   Processing chunk 13/16 (210.0s)
[Rank 0] 2026-01-23 12:33:20,046 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 36723/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:20,128 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:20,128 - podcast_processing.episode_processor - DEBUG - System speaker has 458 words
[Rank 0] 2026-01-23 12:33:20,175 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:20,175 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:20,175 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:20,176 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:20,203 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:20,298 - podcast_processing.episode_processor - INFO -   Processing chunk 14/16 (210.0s)
[Rank 0] 2026-01-23 12:33:20,345 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:20,428 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:20,428 - podcast_processing.episode_processor - DEBUG - System speaker has 255 words
[Rank 0] 2026-01-23 12:33:20,474 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:20,475 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:20,475 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:20,475 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:20,503 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:20,587 - podcast_processing.episode_processor - INFO -   Processing chunk 15/16 (210.0s)
[Rank 0] 2026-01-23 12:33:20,633 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:20,715 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:20,715 - podcast_processing.episode_processor - DEBUG - System speaker has 158 words
[Rank 0] 2026-01-23 12:33:20,762 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:20,762 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:20,762 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:20,763 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:20,790 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:20,884 - podcast_processing.episode_processor - INFO -   Processing chunk 16/16 (186.9s)
[Rank 0] 2026-01-23 12:33:20,925 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/4486416 samples zeroed
[Rank 0] 2026-01-23 12:33:20,997 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2337]), System codes shape: torch.Size([1, 8, 2337])
[Rank 0] 2026-01-23 12:33:20,997 - podcast_processing.episode_processor - DEBUG - System speaker has 228 words
[Rank 0] 2026-01-23 12:33:21,036 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2337])
[Rank 0] 2026-01-23 12:33:21,036 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2337
[Rank 0] 2026-01-23 12:33:21,036 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2337]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:21,036 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2338])
[Rank 0] 2026-01-23 12:33:21,064 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2337, 4096])
[Rank 0] 2026-01-23 12:33:21,330 - podcast_processing.episode_processor - INFO - Combined 16 chunks into final output shape: torch.Size([41712, 4096])
[Rank 0] 2026-01-23 12:33:24,355 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Americhicks_10.4.18FBI Report On Kavanaugh-Homeless Urban Camping-Gov. Hickenlooper and Electric Cars/features_assignment_1.npy
[Rank 0] 2026-01-23 12:33:24,355 - podcast_processing.episode_processor - INFO -   Saved features: 41712 frames
[Rank 0] 2026-01-23 12:33:24,356 - podcast_processing.label_generator - DEBUG - Processing 1 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:33:24,414 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Americhicks_10.4.18FBI Report On Kavanaugh-Homeless Urban Camping-Gov. Hickenlooper and Electric Cars/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:33:24,414 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 15/41712 positive
[Rank 0] 2026-01-23 12:33:24,451 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Americhicks_10.4.18FBI Report On Kavanaugh-Homeless Urban Camping-Gov. Hickenlooper and Electric Cars/metadata_shift_1.json
[Rank 0] 2026-01-23 12:33:24,452 - podcast_processing.episode_processor - INFO - Completed episode: Americhicks_10.4.18FBI Report On Kavanaugh-Homeless Urban Camping-Gov. Hickenlooper and Electric Cars
[Rank 0] 2026-01-23 12:33:24,521 - podcast_processing.distributed_orchestrator - INFO - âœ“ Americhicks_10.4.18FBI Report On Kavanaugh-Homeless Urban Camping-Gov. Hickenlooper and Electric Cars
[Rank 0] 2026-01-23 12:33:24,524 - podcast_processing.episode_processor - INFO - Processing episode: Americhicks_Heart of the Matter September 14th Hour 2
[Rank 0] 2026-01-23 12:33:24,535 - podcast_processing.label_generator - DEBUG - Loaded 27 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Americhicks_Heart of the Matter September 14th Hour 2.json
[Rank 0] 2026-01-23 12:33:24,536 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_03 (longer), SPEAKER_01 (shorter)
[Rank 0] 2026-01-23 12:33:24,547 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [0.79, 0.91], using fallback
[Rank 0] 2026-01-23 12:33:24,782 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1158.70, 1158.70], using fallback
[Rank 0] 2026-01-23 12:33:24,980 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2176.78, 2176.90], using fallback
[Rank 0] 2026-01-23 12:33:25,050 - podcast_processing.alignment_merger - INFO - Created 7858 word alignments
[Rank 0] 2026-01-23 12:33:25,570 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_03: torch.Size([1, 60538920]), SPEAKER_01: torch.Size([1, 60538920])
[Rank 0] 2026-01-23 12:33:25,570 - podcast_processing.episode_processor - INFO - Episode duration: 2522.45s
[Rank 0] 2026-01-23 12:33:25,570 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:33:25,576 - podcast_processing.audio_masking - DEBUG - Creating mask from 3 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:33:25,605 - podcast_processing.audio_masking - DEBUG - Mask covers 31680/60538920 samples (0.05%)
[Rank 0] 2026-01-23 12:33:25,634 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 31680/60538920 samples masked
[Rank 0] 2026-01-23 12:33:26,290 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 31680/60538920 samples zeroed
[Rank 0] 2026-01-23 12:33:26,290 - podcast_processing.episode_processor - INFO - Audio is 2522.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:33:26,290 - podcast_processing.episode_processor - INFO - Processing 2522.5s audio in 13 chunks of 210s each
[Rank 0] 2026-01-23 12:33:26,290 - podcast_processing.episode_processor - INFO -   Processing chunk 1/13 (210.0s)
[Rank 0] 2026-01-23 12:33:26,327 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 14161/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:26,467 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:26,467 - podcast_processing.episode_processor - DEBUG - System speaker has 315 words
[Rank 0] 2026-01-23 12:33:26,513 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:26,513 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:26,513 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:26,514 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:26,542 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:26,643 - podcast_processing.episode_processor - INFO -   Processing chunk 2/13 (210.0s)
[Rank 0] 2026-01-23 12:33:27,641 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:27,759 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:27,759 - podcast_processing.episode_processor - DEBUG - System speaker has 143 words
[Rank 0] 2026-01-23 12:33:27,805 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:27,806 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:27,806 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:27,806 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:27,834 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:27,945 - podcast_processing.episode_processor - INFO -   Processing chunk 3/13 (210.0s)
[Rank 0] 2026-01-23 12:33:27,983 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:28,065 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:28,065 - podcast_processing.episode_processor - DEBUG - System speaker has 243 words
[Rank 0] 2026-01-23 12:33:28,112 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:28,112 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:28,112 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:28,113 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:28,141 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:28,228 - podcast_processing.episode_processor - INFO -   Processing chunk 4/13 (210.0s)
[Rank 0] 2026-01-23 12:33:28,496 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:28,583 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:28,583 - podcast_processing.episode_processor - DEBUG - System speaker has 180 words
[Rank 0] 2026-01-23 12:33:28,630 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:28,630 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:28,630 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:28,630 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:28,658 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:28,742 - podcast_processing.episode_processor - INFO -   Processing chunk 5/13 (210.0s)
[Rank 0] 2026-01-23 12:33:28,777 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:28,874 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:28,874 - podcast_processing.episode_processor - DEBUG - System speaker has 102 words
[Rank 0] 2026-01-23 12:33:28,920 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:28,920 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:28,920 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:28,921 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:28,948 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:29,031 - podcast_processing.episode_processor - INFO -   Processing chunk 6/13 (210.0s)
[Rank 0] 2026-01-23 12:33:29,066 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:29,148 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:29,164 - podcast_processing.episode_processor - DEBUG - System speaker has 571 words
[Rank 0] 2026-01-23 12:33:29,194 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:29,194 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:29,195 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:29,195 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:29,223 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:29,306 - podcast_processing.episode_processor - INFO -   Processing chunk 7/13 (210.0s)
[Rank 0] 2026-01-23 12:33:29,340 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:29,422 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:29,422 - podcast_processing.episode_processor - DEBUG - System speaker has 52 words
[Rank 0] 2026-01-23 12:33:29,469 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:29,469 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:29,469 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:29,470 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:29,497 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:29,581 - podcast_processing.episode_processor - INFO -   Processing chunk 8/13 (210.0s)
[Rank 0] 2026-01-23 12:33:29,616 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:29,698 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:29,698 - podcast_processing.episode_processor - DEBUG - System speaker has 507 words
[Rank 0] 2026-01-23 12:33:29,744 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:29,744 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:29,744 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:29,745 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:29,772 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:29,856 - podcast_processing.episode_processor - INFO -   Processing chunk 9/13 (210.0s)
[Rank 0] 2026-01-23 12:33:29,903 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:29,985 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:29,985 - podcast_processing.episode_processor - DEBUG - System speaker has 276 words
[Rank 0] 2026-01-23 12:33:30,031 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:30,031 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:30,031 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:30,032 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:30,060 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:30,145 - podcast_processing.episode_processor - INFO -   Processing chunk 10/13 (210.0s)
[Rank 0] 2026-01-23 12:33:30,493 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:30,575 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:30,575 - podcast_processing.episode_processor - DEBUG - System speaker has 300 words
[Rank 0] 2026-01-23 12:33:30,621 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:30,622 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:30,623 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:30,624 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:30,653 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:30,756 - podcast_processing.episode_processor - INFO -   Processing chunk 11/13 (210.0s)
[Rank 0] 2026-01-23 12:33:30,797 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 17519/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:30,895 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:30,895 - podcast_processing.episode_processor - DEBUG - System speaker has 288 words
[Rank 0] 2026-01-23 12:33:30,942 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:30,942 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:30,942 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:30,943 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:30,970 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:31,073 - podcast_processing.episode_processor - INFO -   Processing chunk 12/13 (210.0s)
[Rank 0] 2026-01-23 12:33:31,113 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:31,194 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:31,195 - podcast_processing.episode_processor - DEBUG - System speaker has 356 words
[Rank 0] 2026-01-23 12:33:31,241 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:31,241 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:31,242 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:31,242 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:31,269 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:31,354 - podcast_processing.episode_processor - INFO -   Processing chunk 13/13 (2.5s)
[Rank 0] 2026-01-23 12:33:31,355 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/58920 samples zeroed
[Rank 0] 2026-01-23 12:33:31,400 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 31]), System codes shape: torch.Size([1, 8, 31])
[Rank 0] 2026-01-23 12:33:31,400 - podcast_processing.episode_processor - DEBUG - System speaker has 6 words
[Rank 0] 2026-01-23 12:33:31,401 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 31])
[Rank 0] 2026-01-23 12:33:31,401 - podcast_processing.episode_processor - DEBUG - Padded to max_t=31
[Rank 0] 2026-01-23 12:33:31,401 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 31]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:31,401 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 32])
[Rank 0] 2026-01-23 12:33:31,442 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 31, 4096])
[Rank 0] 2026-01-23 12:33:31,592 - podcast_processing.episode_processor - INFO - Combined 13 chunks into final output shape: torch.Size([31531, 4096])
[Rank 0] 2026-01-23 12:33:32,824 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Americhicks_Heart of the Matter September 14th Hour 2/features_assignment_0.npy
[Rank 0] 2026-01-23 12:33:32,825 - podcast_processing.episode_processor - INFO -   Saved features: 31531 frames
[Rank 0] 2026-01-23 12:33:32,830 - podcast_processing.label_generator - DEBUG - Processing 24 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:33:32,867 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Americhicks_Heart of the Matter September 14th Hour 2/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:33:32,868 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 78/31531 positive
[Rank 0] 2026-01-23 12:33:32,875 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:33:32,883 - podcast_processing.audio_masking - DEBUG - Creating mask from 24 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:33:32,957 - podcast_processing.audio_masking - DEBUG - Mask covers 147358/60538920 samples (0.24%)
[Rank 0] 2026-01-23 12:33:32,987 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 147358/60538920 samples masked
[Rank 0] 2026-01-23 12:33:33,642 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 147358/60538920 samples zeroed
[Rank 0] 2026-01-23 12:33:33,642 - podcast_processing.episode_processor - INFO - Audio is 2522.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:33:33,642 - podcast_processing.episode_processor - INFO - Processing 2522.5s audio in 13 chunks of 210s each
[Rank 0] 2026-01-23 12:33:33,642 - podcast_processing.episode_processor - INFO -   Processing chunk 1/13 (210.0s)
[Rank 0] 2026-01-23 12:33:33,677 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:33,759 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:33,759 - podcast_processing.episode_processor - DEBUG - System speaker has 170 words
[Rank 0] 2026-01-23 12:33:33,806 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:33,806 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:33,806 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:33,806 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:33,834 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:33,932 - podcast_processing.episode_processor - INFO -   Processing chunk 2/13 (210.0s)
[Rank 0] 2026-01-23 12:33:33,966 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:34,048 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:34,048 - podcast_processing.episode_processor - DEBUG - System speaker has 458 words
[Rank 0] 2026-01-23 12:33:34,095 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:34,095 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:34,095 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:34,095 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:34,123 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:34,207 - podcast_processing.episode_processor - INFO -   Processing chunk 3/13 (210.0s)
[Rank 0] 2026-01-23 12:33:34,241 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:34,341 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:34,341 - podcast_processing.episode_processor - DEBUG - System speaker has 321 words
[Rank 0] 2026-01-23 12:33:34,388 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:34,388 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:34,388 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:34,388 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:34,415 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:34,500 - podcast_processing.episode_processor - INFO -   Processing chunk 4/13 (210.0s)
[Rank 0] 2026-01-23 12:33:34,535 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 9120/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:34,644 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:34,644 - podcast_processing.episode_processor - DEBUG - System speaker has 192 words
[Rank 0] 2026-01-23 12:33:34,691 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:34,691 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:34,691 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:34,692 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:34,719 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:34,828 - podcast_processing.episode_processor - INFO -   Processing chunk 5/13 (210.0s)
[Rank 0] 2026-01-23 12:33:34,865 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:34,953 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:34,954 - podcast_processing.episode_processor - DEBUG - System speaker has 530 words
[Rank 0] 2026-01-23 12:33:35,000 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:35,000 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:35,000 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:35,001 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:35,028 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:35,121 - podcast_processing.episode_processor - INFO -   Processing chunk 6/13 (210.0s)
[Rank 0] 2026-01-23 12:33:35,158 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 14880/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:35,240 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:35,240 - podcast_processing.episode_processor - DEBUG - System speaker has 128 words
[Rank 0] 2026-01-23 12:33:35,286 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:35,286 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:35,287 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:35,287 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:35,314 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:35,404 - podcast_processing.episode_processor - INFO -   Processing chunk 7/13 (210.0s)
[Rank 0] 2026-01-23 12:33:35,439 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:35,520 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:35,520 - podcast_processing.episode_processor - DEBUG - System speaker has 526 words
[Rank 0] 2026-01-23 12:33:35,567 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:35,673 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:35,673 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:35,673 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:35,700 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:35,797 - podcast_processing.episode_processor - INFO -   Processing chunk 8/13 (210.0s)
[Rank 0] 2026-01-23 12:33:35,831 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:35,912 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:35,913 - podcast_processing.episode_processor - DEBUG - System speaker has 220 words
[Rank 0] 2026-01-23 12:33:35,959 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:35,959 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:35,960 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:35,960 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:35,987 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:36,104 - podcast_processing.episode_processor - INFO -   Processing chunk 9/13 (210.0s)
[Rank 0] 2026-01-23 12:33:36,144 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:36,245 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:36,245 - podcast_processing.episode_processor - DEBUG - System speaker has 392 words
[Rank 0] 2026-01-23 12:33:36,292 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:36,292 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:36,292 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:36,293 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:36,319 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:36,442 - podcast_processing.episode_processor - INFO -   Processing chunk 10/13 (210.0s)
[Rank 0] 2026-01-23 12:33:36,481 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 51595/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:36,589 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:36,589 - podcast_processing.episode_processor - DEBUG - System speaker has 400 words
[Rank 0] 2026-01-23 12:33:36,636 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:36,636 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:36,636 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:36,637 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:36,665 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:36,764 - podcast_processing.episode_processor - INFO -   Processing chunk 11/13 (210.0s)
[Rank 0] 2026-01-23 12:33:36,804 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 71763/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:36,900 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:36,900 - podcast_processing.episode_processor - DEBUG - System speaker has 335 words
[Rank 0] 2026-01-23 12:33:36,947 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:36,947 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:36,947 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:36,948 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:36,975 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:37,090 - podcast_processing.episode_processor - INFO -   Processing chunk 12/13 (210.0s)
[Rank 0] 2026-01-23 12:33:37,127 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:37,212 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:37,212 - podcast_processing.episode_processor - DEBUG - System speaker has 349 words
[Rank 0] 2026-01-23 12:33:37,259 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:37,259 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:37,259 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:37,260 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:37,287 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:37,381 - podcast_processing.episode_processor - INFO -   Processing chunk 13/13 (2.5s)
[Rank 0] 2026-01-23 12:33:37,382 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/58920 samples zeroed
[Rank 0] 2026-01-23 12:33:37,403 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 31]), System codes shape: torch.Size([1, 8, 31])
[Rank 0] 2026-01-23 12:33:37,404 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:37,404 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 31])
[Rank 0] 2026-01-23 12:33:37,404 - podcast_processing.episode_processor - DEBUG - Padded to max_t=31
[Rank 0] 2026-01-23 12:33:37,404 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 31]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:37,404 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 32])
[Rank 0] 2026-01-23 12:33:37,431 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 31, 4096])
[Rank 0] 2026-01-23 12:33:37,583 - podcast_processing.episode_processor - INFO - Combined 13 chunks into final output shape: torch.Size([31531, 4096])
[Rank 0] 2026-01-23 12:33:39,034 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Americhicks_Heart of the Matter September 14th Hour 2/features_assignment_1.npy
[Rank 0] 2026-01-23 12:33:39,034 - podcast_processing.episode_processor - INFO -   Saved features: 31531 frames
[Rank 0] 2026-01-23 12:33:39,034 - podcast_processing.label_generator - DEBUG - Processing 3 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:33:39,037 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Americhicks_Heart of the Matter September 14th Hour 2/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:33:39,037 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 16/31531 positive
[Rank 0] 2026-01-23 12:33:39,038 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Americhicks_Heart of the Matter September 14th Hour 2/metadata_shift_1.json
[Rank 0] 2026-01-23 12:33:39,038 - podcast_processing.episode_processor - INFO - Completed episode: Americhicks_Heart of the Matter September 14th Hour 2
[Rank 0] 2026-01-23 12:33:39,053 - podcast_processing.distributed_orchestrator - INFO - âœ“ Americhicks_Heart of the Matter September 14th Hour 2
[Rank 0] 2026-01-23 12:33:39,057 - podcast_processing.episode_processor - INFO - Processing episode: Animal Talk_Episode 67 Impossible Meat and Impossible Pets
[Rank 0] 2026-01-23 12:33:39,062 - podcast_processing.label_generator - DEBUG - Loaded 221 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Animal Talk_Episode 67 Impossible Meat and Impossible Pets.json
[Rank 0] 2026-01-23 12:33:39,063 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_03 (longer), SPEAKER_02 (shorter)
[Rank 0] 2026-01-23 12:33:39,077 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [11.41, 11.86], using fallback
[Rank 0] 2026-01-23 12:33:39,212 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [175.99, 175.99], using fallback
[Rank 0] 2026-01-23 12:33:39,367 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [330.68, 330.80], using fallback
[Rank 0] 2026-01-23 12:33:39,439 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [419.76, 419.96], using fallback
[Rank 0] 2026-01-23 12:33:39,938 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [986.44, 986.44], using fallback
[Rank 0] 2026-01-23 12:33:40,168 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1200.58, 1200.70], using fallback
[Rank 0] 2026-01-23 12:33:40,168 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1200.70, 1200.88], using fallback
[Rank 0] 2026-01-23 12:33:40,168 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1200.88, 1201.00], using fallback
[Rank 0] 2026-01-23 12:33:40,168 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1201.01, 1201.21], using fallback
[Rank 0] 2026-01-23 12:33:40,280 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1344.00, 1344.18], using fallback
[Rank 0] 2026-01-23 12:33:40,300 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1368.09, 1368.47], using fallback
[Rank 0] 2026-01-23 12:33:40,300 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1368.48, 1368.90], using fallback
[Rank 0] 2026-01-23 12:33:40,453 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1558.11, 1558.41], using fallback
[Rank 0] 2026-01-23 12:33:40,453 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1558.41, 1558.56], using fallback
[Rank 0] 2026-01-23 12:33:40,454 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1558.56, 1558.98], using fallback
[Rank 0] 2026-01-23 12:33:40,454 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1558.98, 1559.13], using fallback
[Rank 0] 2026-01-23 12:33:40,462 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1567.55, 1567.55], using fallback
[Rank 0] 2026-01-23 12:33:40,472 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1570.83, 1570.95], using fallback
[Rank 0] 2026-01-23 12:33:40,475 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1575.09, 1575.18], using fallback
[Rank 0] 2026-01-23 12:33:40,476 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1575.21, 1575.39], using fallback
[Rank 0] 2026-01-23 12:33:40,476 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1575.45, 1575.57], using fallback
[Rank 0] 2026-01-23 12:33:40,476 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1575.57, 1575.69], using fallback
[Rank 0] 2026-01-23 12:33:40,943 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2146.03, 2146.33], using fallback
[Rank 0] 2026-01-23 12:33:41,259 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2343.73, 2343.97], using fallback
[Rank 0] 2026-01-23 12:33:41,432 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2546.02, 2546.23], using fallback
[Rank 0] 2026-01-23 12:33:41,433 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2546.24, 2546.47], using fallback
[Rank 0] 2026-01-23 12:33:41,433 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2546.48, 2546.80], using fallback
[Rank 0] 2026-01-23 12:33:41,479 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2600.47, 2600.48], using fallback
[Rank 0] 2026-01-23 12:33:41,487 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2611.28, 2611.57], using fallback
[Rank 0] 2026-01-23 12:33:41,532 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2689.77, 2690.41], using fallback
[Rank 0] 2026-01-23 12:33:41,556 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2720.28, 2720.35], using fallback
[Rank 0] 2026-01-23 12:33:41,579 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2749.76, 2750.01], using fallback
[Rank 0] 2026-01-23 12:33:41,579 - podcast_processing.alignment_merger - INFO - Created 8403 word alignments
[Rank 0] 2026-01-23 12:33:42,199 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_03: torch.Size([1, 66022924]), SPEAKER_02: torch.Size([1, 66022924])
[Rank 0] 2026-01-23 12:33:42,199 - podcast_processing.episode_processor - INFO - Episode duration: 2750.96s
[Rank 0] 2026-01-23 12:33:42,199 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:33:42,204 - podcast_processing.audio_masking - DEBUG - Creating mask from 101 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:33:42,236 - podcast_processing.audio_masking - DEBUG - Mask covers 752399/66022924 samples (1.14%)
[Rank 0] 2026-01-23 12:33:42,268 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 752399/66022924 samples masked
[Rank 0] 2026-01-23 12:33:42,979 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 752399/66022924 samples zeroed
[Rank 0] 2026-01-23 12:33:42,979 - podcast_processing.episode_processor - INFO - Audio is 2751.0s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:33:42,979 - podcast_processing.episode_processor - INFO - Processing 2751.0s audio in 14 chunks of 210s each
[Rank 0] 2026-01-23 12:33:42,979 - podcast_processing.episode_processor - INFO -   Processing chunk 1/14 (210.0s)
[Rank 0] 2026-01-23 12:33:43,013 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 136321/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:43,125 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:43,133 - podcast_processing.episode_processor - DEBUG - System speaker has 82 words
[Rank 0] 2026-01-23 12:33:43,171 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:43,171 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:43,171 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:43,172 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:43,200 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:43,286 - podcast_processing.episode_processor - INFO -   Processing chunk 2/14 (210.0s)
[Rank 0] 2026-01-23 12:33:43,328 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 21840/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:43,410 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:43,410 - podcast_processing.episode_processor - DEBUG - System speaker has 180 words
[Rank 0] 2026-01-23 12:33:43,456 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:43,456 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:43,457 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:43,457 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:43,484 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:43,586 - podcast_processing.episode_processor - INFO -   Processing chunk 3/14 (210.0s)
[Rank 0] 2026-01-23 12:33:43,631 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 64322/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:43,712 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:43,712 - podcast_processing.episode_processor - DEBUG - System speaker has 86 words
[Rank 0] 2026-01-23 12:33:43,759 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:43,759 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:43,759 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:43,760 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:43,787 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:43,869 - podcast_processing.episode_processor - INFO -   Processing chunk 4/14 (210.0s)
[Rank 0] 2026-01-23 12:33:43,903 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 47761/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:43,985 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:43,985 - podcast_processing.episode_processor - DEBUG - System speaker has 128 words
[Rank 0] 2026-01-23 12:33:44,031 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:44,031 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:44,031 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:44,032 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:44,059 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:44,141 - podcast_processing.episode_processor - INFO -   Processing chunk 5/14 (210.0s)
[Rank 0] 2026-01-23 12:33:44,181 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 43680/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:44,263 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:44,263 - podcast_processing.episode_processor - DEBUG - System speaker has 261 words
[Rank 0] 2026-01-23 12:33:44,310 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:44,310 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:44,310 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:44,310 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:44,338 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:44,421 - podcast_processing.episode_processor - INFO -   Processing chunk 6/14 (210.0s)
[Rank 0] 2026-01-23 12:33:44,455 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 53519/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:44,536 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:44,536 - podcast_processing.episode_processor - DEBUG - System speaker has 411 words
[Rank 0] 2026-01-23 12:33:44,583 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:44,583 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:44,583 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:44,584 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:44,611 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:44,704 - podcast_processing.episode_processor - INFO -   Processing chunk 7/14 (210.0s)
[Rank 0] 2026-01-23 12:33:44,739 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 44879/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:44,830 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:44,830 - podcast_processing.episode_processor - DEBUG - System speaker has 48 words
[Rank 0] 2026-01-23 12:33:44,877 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:44,877 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:44,877 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:44,878 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:44,905 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:44,998 - podcast_processing.episode_processor - INFO -   Processing chunk 8/14 (210.0s)
[Rank 0] 2026-01-23 12:33:45,037 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 26640/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:45,119 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:45,120 - podcast_processing.episode_processor - DEBUG - System speaker has 39 words
[Rank 0] 2026-01-23 12:33:45,166 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:45,166 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:45,167 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:45,167 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:45,194 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:45,286 - podcast_processing.episode_processor - INFO -   Processing chunk 9/14 (210.0s)
[Rank 0] 2026-01-23 12:33:45,326 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 145202/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:45,407 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:45,407 - podcast_processing.episode_processor - DEBUG - System speaker has 140 words
[Rank 0] 2026-01-23 12:33:45,454 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:45,454 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:45,454 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:45,455 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:45,482 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:45,565 - podcast_processing.episode_processor - INFO -   Processing chunk 10/14 (210.0s)
[Rank 0] 2026-01-23 12:33:45,605 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 48478/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:45,708 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:45,708 - podcast_processing.episode_processor - DEBUG - System speaker has 353 words
[Rank 0] 2026-01-23 12:33:45,755 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:45,755 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:45,755 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:45,756 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:45,783 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:45,866 - podcast_processing.episode_processor - INFO -   Processing chunk 11/14 (210.0s)
[Rank 0] 2026-01-23 12:33:45,906 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 119757/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:45,998 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:45,998 - podcast_processing.episode_processor - DEBUG - System speaker has 351 words
[Rank 0] 2026-01-23 12:33:46,045 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:46,045 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:46,045 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:46,046 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:46,073 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:46,156 - podcast_processing.episode_processor - INFO -   Processing chunk 12/14 (210.0s)
[Rank 0] 2026-01-23 12:33:46,201 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:46,309 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:46,309 - podcast_processing.episode_processor - DEBUG - System speaker has 336 words
[Rank 0] 2026-01-23 12:33:46,356 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:46,356 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:46,356 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:46,357 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:46,384 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:46,486 - podcast_processing.episode_processor - INFO -   Processing chunk 13/14 (210.0s)
[Rank 0] 2026-01-23 12:33:46,528 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:46,618 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:46,618 - podcast_processing.episode_processor - DEBUG - System speaker has 6 words
[Rank 0] 2026-01-23 12:33:46,665 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:46,665 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:46,665 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:46,666 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:46,693 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:46,805 - podcast_processing.episode_processor - INFO -   Processing chunk 14/14 (21.0s)
[Rank 0] 2026-01-23 12:33:46,809 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/502924 samples zeroed
[Rank 0] 2026-01-23 12:33:46,860 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 262]), System codes shape: torch.Size([1, 8, 262])
[Rank 0] 2026-01-23 12:33:46,860 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:33:46,860 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 262])
[Rank 0] 2026-01-23 12:33:46,860 - podcast_processing.episode_processor - DEBUG - Padded to max_t=262
[Rank 0] 2026-01-23 12:33:46,860 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 262]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:46,861 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 263])
[Rank 0] 2026-01-23 12:33:46,900 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 262, 4096])
[Rank 0] 2026-01-23 12:33:47,063 - podcast_processing.episode_processor - INFO - Combined 14 chunks into final output shape: torch.Size([34387, 4096])
[Rank 0] 2026-01-23 12:33:49,341 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Animal Talk_Episode 67 Impossible Meat and Impossible Pets/features_assignment_0.npy
[Rank 0] 2026-01-23 12:33:49,341 - podcast_processing.episode_processor - INFO -   Saved features: 34387 frames
[Rank 0] 2026-01-23 12:33:49,341 - podcast_processing.label_generator - DEBUG - Processing 120 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:33:49,353 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Animal Talk_Episode 67 Impossible Meat and Impossible Pets/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:33:49,353 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 471/34387 positive
[Rank 0] 2026-01-23 12:33:49,353 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:33:49,358 - podcast_processing.audio_masking - DEBUG - Creating mask from 120 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:33:49,397 - podcast_processing.audio_masking - DEBUG - Mask covers 891626/66022924 samples (1.35%)
[Rank 0] 2026-01-23 12:33:49,429 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 891626/66022924 samples masked
[Rank 0] 2026-01-23 12:33:50,149 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 891626/66022924 samples zeroed
[Rank 0] 2026-01-23 12:33:50,149 - podcast_processing.episode_processor - INFO - Audio is 2751.0s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:33:50,250 - podcast_processing.episode_processor - INFO - Processing 2751.0s audio in 14 chunks of 210s each
[Rank 0] 2026-01-23 12:33:50,250 - podcast_processing.episode_processor - INFO -   Processing chunk 1/14 (210.0s)
[Rank 0] 2026-01-23 12:33:50,285 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 72720/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:50,408 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:50,408 - podcast_processing.episode_processor - DEBUG - System speaker has 474 words
[Rank 0] 2026-01-23 12:33:50,454 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:50,454 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:50,455 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:50,455 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:50,483 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:50,569 - podcast_processing.episode_processor - INFO -   Processing chunk 2/14 (210.0s)
[Rank 0] 2026-01-23 12:33:50,604 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 42720/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:50,725 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:50,725 - podcast_processing.episode_processor - DEBUG - System speaker has 314 words
[Rank 0] 2026-01-23 12:33:50,771 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:50,771 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:50,772 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:50,772 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:50,799 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:50,882 - podcast_processing.episode_processor - INFO -   Processing chunk 3/14 (210.0s)
[Rank 0] 2026-01-23 12:33:50,916 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 59281/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:51,004 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:51,004 - podcast_processing.episode_processor - DEBUG - System speaker has 172 words
[Rank 0] 2026-01-23 12:33:51,050 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:51,484 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:51,484 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:51,485 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:51,512 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:51,614 - podcast_processing.episode_processor - INFO -   Processing chunk 4/14 (210.0s)
[Rank 0] 2026-01-23 12:33:51,649 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 64082/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:51,817 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:51,817 - podcast_processing.episode_processor - DEBUG - System speaker has 398 words
[Rank 0] 2026-01-23 12:33:51,864 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:51,864 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:51,864 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:51,865 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:51,892 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:52,016 - podcast_processing.episode_processor - INFO -   Processing chunk 5/14 (210.0s)
[Rank 0] 2026-01-23 12:33:52,051 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 62881/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:52,144 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:52,144 - podcast_processing.episode_processor - DEBUG - System speaker has 277 words
[Rank 0] 2026-01-23 12:33:52,191 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:52,191 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:52,191 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:52,192 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:52,219 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:52,303 - podcast_processing.episode_processor - INFO -   Processing chunk 6/14 (210.0s)
[Rank 0] 2026-01-23 12:33:52,338 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 72001/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:52,456 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:52,456 - podcast_processing.episode_processor - DEBUG - System speaker has 129 words
[Rank 0] 2026-01-23 12:33:52,503 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:52,503 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:52,503 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:52,504 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:52,531 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:52,614 - podcast_processing.episode_processor - INFO -   Processing chunk 7/14 (210.0s)
[Rank 0] 2026-01-23 12:33:52,648 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 108720/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:52,774 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:52,774 - podcast_processing.episode_processor - DEBUG - System speaker has 366 words
[Rank 0] 2026-01-23 12:33:52,821 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:52,821 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:52,821 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:52,822 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:52,849 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:52,932 - podcast_processing.episode_processor - INFO -   Processing chunk 8/14 (210.0s)
[Rank 0] 2026-01-23 12:33:52,966 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 30721/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:53,064 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:53,064 - podcast_processing.episode_processor - DEBUG - System speaker has 258 words
[Rank 0] 2026-01-23 12:33:53,109 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:53,109 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:53,109 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:53,110 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:53,137 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:53,225 - podcast_processing.episode_processor - INFO -   Processing chunk 9/14 (210.0s)
[Rank 0] 2026-01-23 12:33:53,270 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 31918/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:53,353 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:53,353 - podcast_processing.episode_processor - DEBUG - System speaker has 147 words
[Rank 0] 2026-01-23 12:33:53,399 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:53,650 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:53,650 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:53,651 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:53,678 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:53,767 - podcast_processing.episode_processor - INFO -   Processing chunk 10/14 (210.0s)
[Rank 0] 2026-01-23 12:33:53,808 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:53,889 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:53,890 - podcast_processing.episode_processor - DEBUG - System speaker has 246 words
[Rank 0] 2026-01-23 12:33:53,936 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:53,936 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:53,936 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:53,937 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:53,964 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:54,053 - podcast_processing.episode_processor - INFO -   Processing chunk 11/14 (210.0s)
[Rank 0] 2026-01-23 12:33:54,094 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 149767/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:54,175 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:54,176 - podcast_processing.episode_processor - DEBUG - System speaker has 254 words
[Rank 0] 2026-01-23 12:33:54,222 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:54,222 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:54,223 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:54,223 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:54,250 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:54,336 - podcast_processing.episode_processor - INFO -   Processing chunk 12/14 (210.0s)
[Rank 0] 2026-01-23 12:33:54,376 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 92886/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:54,458 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:54,783 - podcast_processing.episode_processor - DEBUG - System speaker has 240 words
[Rank 0] 2026-01-23 12:33:54,786 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:54,787 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:54,787 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:54,787 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:54,814 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:54,914 - podcast_processing.episode_processor - INFO -   Processing chunk 13/14 (210.0s)
[Rank 0] 2026-01-23 12:33:54,955 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 103929/5040000 samples zeroed
[Rank 0] 2026-01-23 12:33:55,057 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:33:55,057 - podcast_processing.episode_processor - DEBUG - System speaker has 311 words
[Rank 0] 2026-01-23 12:33:55,104 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:33:55,104 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:33:55,104 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:55,104 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:33:55,131 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:33:55,214 - podcast_processing.episode_processor - INFO -   Processing chunk 14/14 (21.0s)
[Rank 0] 2026-01-23 12:33:55,218 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/502924 samples zeroed
[Rank 0] 2026-01-23 12:33:55,241 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 262]), System codes shape: torch.Size([1, 8, 262])
[Rank 0] 2026-01-23 12:33:55,241 - podcast_processing.episode_processor - DEBUG - System speaker has 30 words
[Rank 0] 2026-01-23 12:33:55,241 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 262])
[Rank 0] 2026-01-23 12:33:55,241 - podcast_processing.episode_processor - DEBUG - Padded to max_t=262
[Rank 0] 2026-01-23 12:33:55,242 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 262]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:33:55,242 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 263])
[Rank 0] 2026-01-23 12:33:55,268 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 262, 4096])
[Rank 0] 2026-01-23 12:33:55,453 - podcast_processing.episode_processor - INFO - Combined 14 chunks into final output shape: torch.Size([34387, 4096])
[Rank 0] 2026-01-23 12:33:57,305 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Animal Talk_Episode 67 Impossible Meat and Impossible Pets/features_assignment_1.npy
[Rank 0] 2026-01-23 12:33:57,305 - podcast_processing.episode_processor - INFO -   Saved features: 34387 frames
[Rank 0] 2026-01-23 12:33:57,322 - podcast_processing.label_generator - DEBUG - Processing 101 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:33:57,392 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Animal Talk_Episode 67 Impossible Meat and Impossible Pets/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:33:57,393 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 393/34387 positive
[Rank 0] 2026-01-23 12:33:57,566 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Animal Talk_Episode 67 Impossible Meat and Impossible Pets/metadata_shift_1.json
[Rank 0] 2026-01-23 12:33:57,574 - podcast_processing.episode_processor - INFO - Completed episode: Animal Talk_Episode 67 Impossible Meat and Impossible Pets
[Rank 0] 2026-01-23 12:33:57,628 - podcast_processing.distributed_orchestrator - INFO - âœ“ Animal Talk_Episode 67 Impossible Meat and Impossible Pets
[Rank 0] 2026-01-23 12:33:57,680 - podcast_processing.episode_processor - INFO - Processing episode: Animal Talk_Matt's New 9 Year Old Puppy - Episode 92
[Rank 0] 2026-01-23 12:33:57,729 - podcast_processing.label_generator - DEBUG - Loaded 143 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Animal Talk_Matt's New 9 Year Old Puppy - Episode 92.json
[Rank 0] 2026-01-23 12:33:57,732 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_01 (longer), SPEAKER_02 (shorter)
[Rank 0] 2026-01-23 12:33:57,850 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [79.74, 79.95], using fallback
[Rank 0] 2026-01-23 12:33:57,876 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [109.62, 109.86], using fallback
[Rank 0] 2026-01-23 12:33:58,014 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [257.15, 257.15], using fallback
[Rank 0] 2026-01-23 12:33:58,045 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [279.87, 280.08], using fallback
[Rank 0] 2026-01-23 12:33:58,046 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [281.32, 281.56], using fallback
[Rank 0] 2026-01-23 12:33:58,093 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [333.94, 334.03], using fallback
[Rank 0] 2026-01-23 12:33:58,202 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [463.23, 463.71], using fallback
[Rank 0] 2026-01-23 12:33:58,227 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [492.83, 492.99], using fallback
[Rank 0] 2026-01-23 12:33:58,328 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [605.77, 605.89], using fallback
[Rank 0] 2026-01-23 12:33:58,581 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [945.31, 945.31], using fallback
[Rank 0] 2026-01-23 12:33:58,753 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1172.07, 1172.07], using fallback
[Rank 0] 2026-01-23 12:33:59,716 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2507.61, 2508.12], using fallback
[Rank 0] 2026-01-23 12:33:59,717 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2508.12, 2508.57], using fallback
[Rank 0] 2026-01-23 12:33:59,717 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2508.57, 2508.95], using fallback
[Rank 0] 2026-01-23 12:33:59,719 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2511.33, 2511.75], using fallback
[Rank 0] 2026-01-23 12:33:59,719 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2511.75, 2512.20], using fallback
[Rank 0] 2026-01-23 12:33:59,719 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2512.20, 2512.68], using fallback
[Rank 0] 2026-01-23 12:33:59,796 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2637.42, 2638.44], using fallback
[Rank 0] 2026-01-23 12:33:59,810 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2659.63, 2659.82], using fallback
[Rank 0] 2026-01-23 12:33:59,825 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2680.75, 2680.84], using fallback
[Rank 0] 2026-01-23 12:33:59,825 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2680.86, 2681.19], using fallback
[Rank 0] 2026-01-23 12:33:59,967 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2914.77, 2915.02], using fallback
[Rank 0] 2026-01-23 12:33:59,988 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2949.21, 2949.22], using fallback
[Rank 0] 2026-01-23 12:34:00,000 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2971.08, 2971.41], using fallback
[Rank 0] 2026-01-23 12:34:00,010 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2987.99, 2988.26], using fallback
[Rank 0] 2026-01-23 12:34:00,014 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2996.84, 2996.98], using fallback
[Rank 0] 2026-01-23 12:34:00,057 - podcast_processing.alignment_merger - INFO - Created 8786 word alignments
[Rank 0] 2026-01-23 12:34:00,932 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_01: torch.Size([1, 73396352]), SPEAKER_02: torch.Size([1, 73396352])
[Rank 0] 2026-01-23 12:34:00,932 - podcast_processing.episode_processor - INFO - Episode duration: 3058.18s
[Rank 0] 2026-01-23 12:34:00,932 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:34:00,957 - podcast_processing.audio_masking - DEBUG - Creating mask from 53 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:34:00,992 - podcast_processing.audio_masking - DEBUG - Mask covers 346324/73396352 samples (0.47%)
[Rank 0] 2026-01-23 12:34:01,027 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 346324/73396352 samples masked
[Rank 0] 2026-01-23 12:34:01,815 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 346324/73396352 samples zeroed
[Rank 0] 2026-01-23 12:34:01,815 - podcast_processing.episode_processor - INFO - Audio is 3058.2s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:34:01,815 - podcast_processing.episode_processor - INFO - Processing 3058.2s audio in 15 chunks of 210s each
[Rank 0] 2026-01-23 12:34:01,815 - podcast_processing.episode_processor - INFO -   Processing chunk 1/15 (210.0s)
[Rank 0] 2026-01-23 12:34:01,851 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 27601/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:02,011 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:02,011 - podcast_processing.episode_processor - DEBUG - System speaker has 87 words
[Rank 0] 2026-01-23 12:34:02,058 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:02,058 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:02,058 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:02,059 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:02,087 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:02,202 - podcast_processing.episode_processor - INFO -   Processing chunk 2/15 (210.0s)
[Rank 0] 2026-01-23 12:34:02,237 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 37921/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:02,351 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:02,351 - podcast_processing.episode_processor - DEBUG - System speaker has 65 words
[Rank 0] 2026-01-23 12:34:02,398 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:02,398 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:02,398 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:02,399 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:02,426 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:02,507 - podcast_processing.episode_processor - INFO -   Processing chunk 3/15 (210.0s)
[Rank 0] 2026-01-23 12:34:02,553 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 13920/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:02,723 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:02,723 - podcast_processing.episode_processor - DEBUG - System speaker has 114 words
[Rank 0] 2026-01-23 12:34:02,770 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:02,770 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:02,770 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:02,771 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:02,798 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:02,899 - podcast_processing.episode_processor - INFO -   Processing chunk 4/15 (210.0s)
[Rank 0] 2026-01-23 12:34:02,939 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 31920/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:03,027 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:03,027 - podcast_processing.episode_processor - DEBUG - System speaker has 382 words
[Rank 0] 2026-01-23 12:34:03,073 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:03,443 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:03,443 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:03,444 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:03,471 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:03,556 - podcast_processing.episode_processor - INFO -   Processing chunk 5/15 (210.0s)
[Rank 0] 2026-01-23 12:34:03,595 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:03,686 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:03,686 - podcast_processing.episode_processor - DEBUG - System speaker has 25 words
[Rank 0] 2026-01-23 12:34:03,733 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:03,733 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:03,733 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:03,734 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:03,761 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:03,844 - podcast_processing.episode_processor - INFO -   Processing chunk 6/15 (210.0s)
[Rank 0] 2026-01-23 12:34:03,983 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 8160/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:04,075 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:04,075 - podcast_processing.episode_processor - DEBUG - System speaker has 328 words
[Rank 0] 2026-01-23 12:34:04,122 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:04,122 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:04,238 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:04,239 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:04,266 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:04,372 - podcast_processing.episode_processor - INFO -   Processing chunk 7/15 (210.0s)
[Rank 0] 2026-01-23 12:34:04,408 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3600/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:04,489 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:04,490 - podcast_processing.episode_processor - DEBUG - System speaker has 342 words
[Rank 0] 2026-01-23 12:34:04,536 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:04,536 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:04,537 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:04,537 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:04,564 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:04,673 - podcast_processing.episode_processor - INFO -   Processing chunk 8/15 (210.0s)
[Rank 0] 2026-01-23 12:34:04,712 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 113281/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:04,794 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:04,794 - podcast_processing.episode_processor - DEBUG - System speaker has 391 words
[Rank 0] 2026-01-23 12:34:04,841 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:04,841 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:04,841 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:04,842 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:04,870 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:04,970 - podcast_processing.episode_processor - INFO -   Processing chunk 9/15 (210.0s)
[Rank 0] 2026-01-23 12:34:05,005 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:05,088 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:05,088 - podcast_processing.episode_processor - DEBUG - System speaker has 396 words
[Rank 0] 2026-01-23 12:34:05,134 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:05,134 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:05,134 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:05,135 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:05,162 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:05,245 - podcast_processing.episode_processor - INFO -   Processing chunk 10/15 (210.0s)
[Rank 0] 2026-01-23 12:34:05,281 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 53520/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:05,363 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:05,363 - podcast_processing.episode_processor - DEBUG - System speaker has 392 words
[Rank 0] 2026-01-23 12:34:05,410 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:05,410 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:05,410 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:05,411 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:05,438 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:05,521 - podcast_processing.episode_processor - INFO -   Processing chunk 11/15 (210.0s)
[Rank 0] 2026-01-23 12:34:05,556 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 13200/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:05,651 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:05,651 - podcast_processing.episode_processor - DEBUG - System speaker has 152 words
[Rank 0] 2026-01-23 12:34:05,698 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:05,698 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:05,698 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:05,699 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:05,726 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:05,809 - podcast_processing.episode_processor - INFO -   Processing chunk 12/15 (210.0s)
[Rank 0] 2026-01-23 12:34:05,843 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:05,924 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:05,925 - podcast_processing.episode_processor - DEBUG - System speaker has 94 words
[Rank 0] 2026-01-23 12:34:05,971 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:05,971 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:05,971 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:05,972 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:05,999 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:06,082 - podcast_processing.episode_processor - INFO -   Processing chunk 13/15 (210.0s)
[Rank 0] 2026-01-23 12:34:06,116 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 31679/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:06,197 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:06,197 - podcast_processing.episode_processor - DEBUG - System speaker has 85 words
[Rank 0] 2026-01-23 12:34:06,244 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:06,244 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:06,244 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:06,244 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:06,271 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:06,354 - podcast_processing.episode_processor - INFO -   Processing chunk 14/15 (210.0s)
[Rank 0] 2026-01-23 12:34:06,389 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6962/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:06,471 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:06,471 - podcast_processing.episode_processor - DEBUG - System speaker has 5 words
[Rank 0] 2026-01-23 12:34:06,517 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:06,517 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:06,517 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:06,518 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:06,545 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:06,627 - podcast_processing.episode_processor - INFO -   Processing chunk 15/15 (118.2s)
[Rank 0] 2026-01-23 12:34:06,650 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/2836352 samples zeroed
[Rank 0] 2026-01-23 12:34:06,707 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1478]), System codes shape: torch.Size([1, 8, 1478])
[Rank 0] 2026-01-23 12:34:06,708 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:34:06,725 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1478])
[Rank 0] 2026-01-23 12:34:06,725 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1478
[Rank 0] 2026-01-23 12:34:06,725 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1478]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:06,726 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1479])
[Rank 0] 2026-01-23 12:34:06,759 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1478, 4096])
[Rank 0] 2026-01-23 12:34:06,977 - podcast_processing.episode_processor - INFO - Combined 15 chunks into final output shape: torch.Size([38228, 4096])
[Rank 0] 2026-01-23 12:34:08,717 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Animal Talk_Matt's New 9 Year Old Puppy - Episode 92/features_assignment_0.npy
[Rank 0] 2026-01-23 12:34:08,769 - podcast_processing.episode_processor - INFO -   Saved features: 38228 frames
[Rank 0] 2026-01-23 12:34:08,770 - podcast_processing.label_generator - DEBUG - Processing 90 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:34:08,780 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Animal Talk_Matt's New 9 Year Old Puppy - Episode 92/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:34:08,782 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 298/38228 positive
[Rank 0] 2026-01-23 12:34:08,783 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:34:08,789 - podcast_processing.audio_masking - DEBUG - Creating mask from 90 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:34:08,831 - podcast_processing.audio_masking - DEBUG - Mask covers 566883/73396352 samples (0.77%)
[Rank 0] 2026-01-23 12:34:08,866 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 566883/73396352 samples masked
[Rank 0] 2026-01-23 12:34:09,655 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 566883/73396352 samples zeroed
[Rank 0] 2026-01-23 12:34:09,655 - podcast_processing.episode_processor - INFO - Audio is 3058.2s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:34:09,655 - podcast_processing.episode_processor - INFO - Processing 3058.2s audio in 15 chunks of 210s each
[Rank 0] 2026-01-23 12:34:09,655 - podcast_processing.episode_processor - INFO -   Processing chunk 1/15 (210.0s)
[Rank 0] 2026-01-23 12:34:09,690 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 106560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:09,772 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:09,772 - podcast_processing.episode_processor - DEBUG - System speaker has 349 words
[Rank 0] 2026-01-23 12:34:09,818 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:09,818 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:09,818 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:09,818 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:09,846 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:09,945 - podcast_processing.episode_processor - INFO -   Processing chunk 2/15 (210.0s)
[Rank 0] 2026-01-23 12:34:09,981 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 72479/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:10,063 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:10,210 - podcast_processing.episode_processor - DEBUG - System speaker has 165 words
[Rank 0] 2026-01-23 12:34:10,212 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:10,212 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:10,212 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:10,213 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:10,240 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:10,322 - podcast_processing.episode_processor - INFO -   Processing chunk 3/15 (210.0s)
[Rank 0] 2026-01-23 12:34:10,357 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 48720/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:10,471 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:10,471 - podcast_processing.episode_processor - DEBUG - System speaker has 219 words
[Rank 0] 2026-01-23 12:34:10,518 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:10,518 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:10,518 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:10,519 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:10,546 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:10,628 - podcast_processing.episode_processor - INFO -   Processing chunk 4/15 (210.0s)
[Rank 0] 2026-01-23 12:34:10,662 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7680/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:10,770 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:10,770 - podcast_processing.episode_processor - DEBUG - System speaker has 164 words
[Rank 0] 2026-01-23 12:34:10,817 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:10,817 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:10,817 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:10,818 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:10,844 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:10,945 - podcast_processing.episode_processor - INFO -   Processing chunk 5/15 (210.0s)
[Rank 0] 2026-01-23 12:34:10,980 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 57838/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:11,074 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:11,074 - podcast_processing.episode_processor - DEBUG - System speaker has 524 words
[Rank 0] 2026-01-23 12:34:11,121 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:11,121 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:11,122 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:11,122 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:11,149 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:11,240 - podcast_processing.episode_processor - INFO -   Processing chunk 6/15 (210.0s)
[Rank 0] 2026-01-23 12:34:11,275 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 17040/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:11,356 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:11,357 - podcast_processing.episode_processor - DEBUG - System speaker has 72 words
[Rank 0] 2026-01-23 12:34:11,403 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:11,403 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:11,404 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:11,404 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:11,431 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:11,545 - podcast_processing.episode_processor - INFO -   Processing chunk 7/15 (210.0s)
[Rank 0] 2026-01-23 12:34:11,579 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6720/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:11,660 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:11,660 - podcast_processing.episode_processor - DEBUG - System speaker has 166 words
[Rank 0] 2026-01-23 12:34:11,707 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:11,707 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:11,707 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:11,708 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:11,735 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:11,862 - podcast_processing.episode_processor - INFO -   Processing chunk 8/15 (210.0s)
[Rank 0] 2026-01-23 12:34:11,896 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 64322/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:11,991 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:11,991 - podcast_processing.episode_processor - DEBUG - System speaker has 271 words
[Rank 0] 2026-01-23 12:34:12,037 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:12,037 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:12,038 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:12,038 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:12,065 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:12,217 - podcast_processing.episode_processor - INFO -   Processing chunk 9/15 (210.0s)
[Rank 0] 2026-01-23 12:34:12,257 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 36482/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:12,349 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:12,349 - podcast_processing.episode_processor - DEBUG - System speaker has 132 words
[Rank 0] 2026-01-23 12:34:12,395 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:12,395 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:12,396 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:12,396 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:12,423 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:12,602 - podcast_processing.episode_processor - INFO -   Processing chunk 10/15 (210.0s)
[Rank 0] 2026-01-23 12:34:12,654 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 33837/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:12,775 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:12,775 - podcast_processing.episode_processor - DEBUG - System speaker has 133 words
[Rank 0] 2026-01-23 12:34:12,822 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:12,822 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:12,822 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:12,822 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:12,849 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:12,977 - podcast_processing.episode_processor - INFO -   Processing chunk 11/15 (210.0s)
[Rank 0] 2026-01-23 12:34:13,017 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12240/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:13,120 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:13,120 - podcast_processing.episode_processor - DEBUG - System speaker has 233 words
[Rank 0] 2026-01-23 12:34:13,167 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:13,167 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:13,167 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:13,168 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:13,194 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:13,277 - podcast_processing.episode_processor - INFO -   Processing chunk 12/15 (210.0s)
[Rank 0] 2026-01-23 12:34:13,318 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4321/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:13,400 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:13,400 - podcast_processing.episode_processor - DEBUG - System speaker has 410 words
[Rank 0] 2026-01-23 12:34:13,446 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:13,446 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:13,446 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:13,447 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:13,474 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:13,557 - podcast_processing.episode_processor - INFO -   Processing chunk 13/15 (210.0s)
[Rank 0] 2026-01-23 12:34:13,604 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 17760/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:13,686 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:13,686 - podcast_processing.episode_processor - DEBUG - System speaker has 223 words
[Rank 0] 2026-01-23 12:34:13,733 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:13,733 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:13,733 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:13,733 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:13,760 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:13,844 - podcast_processing.episode_processor - INFO -   Processing chunk 14/15 (210.0s)
[Rank 0] 2026-01-23 12:34:13,890 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4320/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:13,977 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:13,977 - podcast_processing.episode_processor - DEBUG - System speaker has 431 words
[Rank 0] 2026-01-23 12:34:14,024 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:14,024 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:14,024 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:14,025 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:14,052 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:14,140 - podcast_processing.episode_processor - INFO -   Processing chunk 15/15 (118.2s)
[Rank 0] 2026-01-23 12:34:14,168 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 76564/2836352 samples zeroed
[Rank 0] 2026-01-23 12:34:14,216 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1478]), System codes shape: torch.Size([1, 8, 1478])
[Rank 0] 2026-01-23 12:34:14,216 - podcast_processing.episode_processor - DEBUG - System speaker has 137 words
[Rank 0] 2026-01-23 12:34:14,234 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1478])
[Rank 0] 2026-01-23 12:34:14,234 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1478
[Rank 0] 2026-01-23 12:34:14,234 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1478]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:14,235 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1479])
[Rank 0] 2026-01-23 12:34:14,261 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1478, 4096])
[Rank 0] 2026-01-23 12:34:14,522 - podcast_processing.episode_processor - INFO - Combined 15 chunks into final output shape: torch.Size([38228, 4096])
[Rank 0] 2026-01-23 12:34:16,960 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Animal Talk_Matt's New 9 Year Old Puppy - Episode 92/features_assignment_1.npy
[Rank 0] 2026-01-23 12:34:16,960 - podcast_processing.episode_processor - INFO -   Saved features: 38228 frames
[Rank 0] 2026-01-23 12:34:16,961 - podcast_processing.label_generator - DEBUG - Processing 53 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:34:17,405 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Animal Talk_Matt's New 9 Year Old Puppy - Episode 92/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:34:17,405 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 185/38228 positive
[Rank 0] 2026-01-23 12:34:17,425 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Animal Talk_Matt's New 9 Year Old Puppy - Episode 92/metadata_shift_1.json
[Rank 0] 2026-01-23 12:34:17,425 - podcast_processing.episode_processor - INFO - Completed episode: Animal Talk_Matt's New 9 Year Old Puppy - Episode 92
[Rank 0] 2026-01-23 12:34:17,500 - podcast_processing.distributed_orchestrator - INFO - âœ“ Animal Talk_Matt's New 9 Year Old Puppy - Episode 92
[Rank 0] 2026-01-23 12:34:17,539 - podcast_processing.episode_processor - INFO - Processing episode: Animal Talk_Take a photo of a bear from 15 angles - Episode 44
[Rank 0] 2026-01-23 12:34:17,581 - podcast_processing.label_generator - DEBUG - Loaded 298 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Animal Talk_Take a photo of a bear from 15 angles - Episode 44.json
[Rank 0] 2026-01-23 12:34:17,588 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_03 (longer), SPEAKER_02 (shorter)
[Rank 0] 2026-01-23 12:34:17,725 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [82.04, 82.09], using fallback
[Rank 0] 2026-01-23 12:34:17,945 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [264.84, 264.93], using fallback
[Rank 0] 2026-01-23 12:34:18,111 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [378.88, 379.17], using fallback
[Rank 0] 2026-01-23 12:34:18,648 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [834.66, 834.83], using fallback
[Rank 0] 2026-01-23 12:34:18,648 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [835.41, 835.51], using fallback
[Rank 0] 2026-01-23 12:34:18,673 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [857.68, 857.73], using fallback
[Rank 0] 2026-01-23 12:34:18,883 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1036.21, 1036.48], using fallback
[Rank 0] 2026-01-23 12:34:19,085 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1193.95, 1194.15], using fallback
[Rank 0] 2026-01-23 12:34:19,194 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1253.07, 1253.34], using fallback
[Rank 0] 2026-01-23 12:34:19,359 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1376.91, 1377.06], using fallback
[Rank 0] 2026-01-23 12:34:19,636 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1377.06, 1377.23], using fallback
[Rank 0] 2026-01-23 12:34:19,962 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1664.57, 1664.69], using fallback
[Rank 0] 2026-01-23 12:34:20,124 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1817.54, 1817.78], using fallback
[Rank 0] 2026-01-23 12:34:20,688 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2322.77, 2322.83], using fallback
[Rank 0] 2026-01-23 12:34:20,688 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2322.83, 2323.04], using fallback
[Rank 0] 2026-01-23 12:34:20,790 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2424.51, 2424.70], using fallback
[Rank 0] 2026-01-23 12:34:20,822 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2454.48, 2454.57], using fallback
[Rank 0] 2026-01-23 12:34:20,823 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2454.57, 2454.69], using fallback
[Rank 0] 2026-01-23 12:34:20,823 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2454.72, 2454.97], using fallback
[Rank 0] 2026-01-23 12:34:20,944 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2541.28, 2541.40], using fallback
[Rank 0] 2026-01-23 12:34:21,020 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2602.34, 2602.46], using fallback
[Rank 0] 2026-01-23 12:34:21,145 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2722.55, 2722.61], using fallback
[Rank 0] 2026-01-23 12:34:21,145 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2722.64, 2722.73], using fallback
[Rank 0] 2026-01-23 12:34:21,146 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2722.73, 2723.38], using fallback
[Rank 0] 2026-01-23 12:34:21,148 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2728.85, 2729.03], using fallback
[Rank 0] 2026-01-23 12:34:21,148 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2729.03, 2729.49], using fallback
[Rank 0] 2026-01-23 12:34:21,675 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3197.17, 3197.38], using fallback
[Rank 0] 2026-01-23 12:34:21,675 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3197.41, 3197.59], using fallback
[Rank 0] 2026-01-23 12:34:21,731 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3245.08, 3245.18], using fallback
[Rank 0] 2026-01-23 12:34:21,921 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3407.20, 3408.27], using fallback
[Rank 0] 2026-01-23 12:34:22,032 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3417.69, 3417.90], using fallback
[Rank 0] 2026-01-23 12:34:22,042 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3424.85, 3425.05], using fallback
[Rank 0] 2026-01-23 12:34:22,043 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3425.05, 3425.22], using fallback
[Rank 0] 2026-01-23 12:34:22,043 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3425.55, 3425.91], using fallback
[Rank 0] 2026-01-23 12:34:22,074 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3463.17, 3463.44], using fallback
[Rank 0] 2026-01-23 12:34:22,075 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3463.44, 3463.65], using fallback
[Rank 0] 2026-01-23 12:34:22,211 - podcast_processing.alignment_merger - INFO - Created 11102 word alignments
[Rank 0] 2026-01-23 12:34:23,012 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_03: torch.Size([1, 86508304]), SPEAKER_02: torch.Size([1, 86508304])
[Rank 0] 2026-01-23 12:34:23,012 - podcast_processing.episode_processor - INFO - Episode duration: 3604.51s
[Rank 0] 2026-01-23 12:34:23,012 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:34:23,020 - podcast_processing.audio_masking - DEBUG - Creating mask from 126 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:34:23,062 - podcast_processing.audio_masking - DEBUG - Mask covers 799683/86508304 samples (0.92%)
[Rank 0] 2026-01-23 12:34:23,103 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 799683/86508304 samples masked
[Rank 0] 2026-01-23 12:34:24,044 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 799683/86508304 samples zeroed
[Rank 0] 2026-01-23 12:34:24,045 - podcast_processing.episode_processor - INFO - Audio is 3604.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:34:24,045 - podcast_processing.episode_processor - INFO - Processing 3604.5s audio in 18 chunks of 210s each
[Rank 0] 2026-01-23 12:34:24,045 - podcast_processing.episode_processor - INFO -   Processing chunk 1/18 (210.0s)
[Rank 0] 2026-01-23 12:34:24,094 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 99361/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:24,210 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:24,210 - podcast_processing.episode_processor - DEBUG - System speaker has 142 words
[Rank 0] 2026-01-23 12:34:24,256 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:24,256 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:24,256 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:24,257 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:24,285 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:24,426 - podcast_processing.episode_processor - INFO -   Processing chunk 2/18 (210.0s)
[Rank 0] 2026-01-23 12:34:24,466 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 52560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:24,571 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:24,571 - podcast_processing.episode_processor - DEBUG - System speaker has 42 words
[Rank 0] 2026-01-23 12:34:24,618 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:24,618 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:24,618 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:24,619 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:24,646 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:24,758 - podcast_processing.episode_processor - INFO -   Processing chunk 3/18 (210.0s)
[Rank 0] 2026-01-23 12:34:24,803 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:24,907 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:24,907 - podcast_processing.episode_processor - DEBUG - System speaker has 183 words
[Rank 0] 2026-01-23 12:34:24,954 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:24,954 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:24,954 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:24,954 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:24,981 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:25,103 - podcast_processing.episode_processor - INFO -   Processing chunk 4/18 (210.0s)
[Rank 0] 2026-01-23 12:34:25,143 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 106799/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:25,253 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:26,064 - podcast_processing.episode_processor - DEBUG - System speaker has 193 words
[Rank 0] 2026-01-23 12:34:26,067 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:26,067 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:26,067 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:26,068 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:26,095 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:26,178 - podcast_processing.episode_processor - INFO -   Processing chunk 5/18 (210.0s)
[Rank 0] 2026-01-23 12:34:26,226 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 14879/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:26,308 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:26,309 - podcast_processing.episode_processor - DEBUG - System speaker has 304 words
[Rank 0] 2026-01-23 12:34:26,355 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:26,355 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:26,355 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:26,356 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:26,383 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:26,467 - podcast_processing.episode_processor - INFO -   Processing chunk 6/18 (210.0s)
[Rank 0] 2026-01-23 12:34:26,502 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20880/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:26,584 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:26,584 - podcast_processing.episode_processor - DEBUG - System speaker has 338 words
[Rank 0] 2026-01-23 12:34:26,630 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:26,630 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:26,631 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:26,631 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:26,658 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:26,741 - podcast_processing.episode_processor - INFO -   Processing chunk 7/18 (210.0s)
[Rank 0] 2026-01-23 12:34:26,780 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 112562/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:26,862 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:26,862 - podcast_processing.episode_processor - DEBUG - System speaker has 248 words
[Rank 0] 2026-01-23 12:34:26,908 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:26,909 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:26,909 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:26,909 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:26,936 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:27,019 - podcast_processing.episode_processor - INFO -   Processing chunk 8/18 (210.0s)
[Rank 0] 2026-01-23 12:34:27,066 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:27,148 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:27,148 - podcast_processing.episode_processor - DEBUG - System speaker has 402 words
[Rank 0] 2026-01-23 12:34:27,194 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:27,194 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:27,195 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:27,195 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:27,222 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:27,309 - podcast_processing.episode_processor - INFO -   Processing chunk 9/18 (210.0s)
[Rank 0] 2026-01-23 12:34:27,348 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 42960/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:27,430 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:27,430 - podcast_processing.episode_processor - DEBUG - System speaker has 233 words
[Rank 0] 2026-01-23 12:34:27,477 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:27,477 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:27,477 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:27,478 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:27,505 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:27,598 - podcast_processing.episode_processor - INFO -   Processing chunk 10/18 (210.0s)
[Rank 0] 2026-01-23 12:34:27,643 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:27,725 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:27,725 - podcast_processing.episode_processor - DEBUG - System speaker has 198 words
[Rank 0] 2026-01-23 12:34:27,771 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:27,772 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:27,772 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:27,772 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:27,799 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:27,890 - podcast_processing.episode_processor - INFO -   Processing chunk 11/18 (210.0s)
[Rank 0] 2026-01-23 12:34:27,931 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 30964/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:28,012 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:28,012 - podcast_processing.episode_processor - DEBUG - System speaker has 158 words
[Rank 0] 2026-01-23 12:34:28,059 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:28,059 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:28,059 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:28,060 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:28,087 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:28,177 - podcast_processing.episode_processor - INFO -   Processing chunk 12/18 (210.0s)
[Rank 0] 2026-01-23 12:34:28,224 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 139679/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:28,305 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:28,306 - podcast_processing.episode_processor - DEBUG - System speaker has 234 words
[Rank 0] 2026-01-23 12:34:28,352 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:28,352 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:28,352 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:28,353 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:28,380 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:28,472 - podcast_processing.episode_processor - INFO -   Processing chunk 13/18 (210.0s)
[Rank 0] 2026-01-23 12:34:28,998 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 21604/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:29,087 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:29,087 - podcast_processing.episode_processor - DEBUG - System speaker has 147 words
[Rank 0] 2026-01-23 12:34:29,133 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:29,133 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:29,135 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:29,136 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:29,165 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:29,258 - podcast_processing.episode_processor - INFO -   Processing chunk 14/18 (210.0s)
[Rank 0] 2026-01-23 12:34:29,304 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 22800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:29,386 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:29,386 - podcast_processing.episode_processor - DEBUG - System speaker has 107 words
[Rank 0] 2026-01-23 12:34:29,432 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:29,433 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:29,433 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:29,433 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:29,461 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:29,562 - podcast_processing.episode_processor - INFO -   Processing chunk 15/18 (210.0s)
[Rank 0] 2026-01-23 12:34:29,609 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 17760/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:29,715 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:29,715 - podcast_processing.episode_processor - DEBUG - System speaker has 168 words
[Rank 0] 2026-01-23 12:34:29,762 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:29,762 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:29,762 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:29,763 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:29,790 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:29,884 - podcast_processing.episode_processor - INFO -   Processing chunk 16/18 (210.0s)
[Rank 0] 2026-01-23 12:34:29,931 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 72957/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:30,018 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:30,018 - podcast_processing.episode_processor - DEBUG - System speaker has 181 words
[Rank 0] 2026-01-23 12:34:30,065 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:30,065 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:30,065 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:30,066 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:30,093 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:30,196 - podcast_processing.episode_processor - INFO -   Processing chunk 17/18 (210.0s)
[Rank 0] 2026-01-23 12:34:30,242 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 43918/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:30,324 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:30,324 - podcast_processing.episode_processor - DEBUG - System speaker has 185 words
[Rank 0] 2026-01-23 12:34:30,370 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:30,370 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:30,371 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:30,371 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:30,398 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:30,499 - podcast_processing.episode_processor - INFO -   Processing chunk 18/18 (34.5s)
[Rank 0] 2026-01-23 12:34:30,508 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/828304 samples zeroed
[Rank 0] 2026-01-23 12:34:30,557 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 432]), System codes shape: torch.Size([1, 8, 432])
[Rank 0] 2026-01-23 12:34:30,911 - podcast_processing.episode_processor - DEBUG - System speaker has 8 words
[Rank 0] 2026-01-23 12:34:30,912 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 432])
[Rank 0] 2026-01-23 12:34:30,912 - podcast_processing.episode_processor - DEBUG - Padded to max_t=432
[Rank 0] 2026-01-23 12:34:30,912 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 432]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:30,912 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 433])
[Rank 0] 2026-01-23 12:34:30,949 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 432, 4096])
[Rank 0] 2026-01-23 12:34:31,162 - podcast_processing.episode_processor - INFO - Combined 18 chunks into final output shape: torch.Size([45057, 4096])
[Rank 0] 2026-01-23 12:34:35,174 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Animal Talk_Take a photo of a bear from 15 angles - Episode 44/features_assignment_0.npy
[Rank 0] 2026-01-23 12:34:35,174 - podcast_processing.episode_processor - INFO -   Saved features: 45057 frames
[Rank 0] 2026-01-23 12:34:35,176 - podcast_processing.label_generator - DEBUG - Processing 172 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:34:35,221 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Animal Talk_Take a photo of a bear from 15 angles - Episode 44/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:34:35,221 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 582/45057 positive
[Rank 0] 2026-01-23 12:34:35,229 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:34:35,241 - podcast_processing.audio_masking - DEBUG - Creating mask from 172 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:34:35,320 - podcast_processing.audio_masking - DEBUG - Mask covers 1097525/86508304 samples (1.27%)
[Rank 0] 2026-01-23 12:34:35,362 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 1097525/86508304 samples masked
[Rank 0] 2026-01-23 12:34:36,509 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 1097525/86508304 samples zeroed
[Rank 0] 2026-01-23 12:34:36,509 - podcast_processing.episode_processor - INFO - Audio is 3604.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:34:36,509 - podcast_processing.episode_processor - INFO - Processing 3604.5s audio in 18 chunks of 210s each
[Rank 0] 2026-01-23 12:34:36,509 - podcast_processing.episode_processor - INFO -   Processing chunk 1/18 (210.0s)
[Rank 0] 2026-01-23 12:34:36,544 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 59044/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:36,643 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:36,643 - podcast_processing.episode_processor - DEBUG - System speaker has 323 words
[Rank 0] 2026-01-23 12:34:36,689 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:36,690 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:36,690 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:36,690 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:36,718 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:36,824 - podcast_processing.episode_processor - INFO -   Processing chunk 2/18 (210.0s)
[Rank 0] 2026-01-23 12:34:36,859 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 10320/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:36,981 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:36,981 - podcast_processing.episode_processor - DEBUG - System speaker has 361 words
[Rank 0] 2026-01-23 12:34:37,028 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:37,028 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:37,028 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:37,029 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:37,056 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:37,154 - podcast_processing.episode_processor - INFO -   Processing chunk 3/18 (210.0s)
[Rank 0] 2026-01-23 12:34:37,189 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 69121/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:37,326 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:37,326 - podcast_processing.episode_processor - DEBUG - System speaker has 384 words
[Rank 0] 2026-01-23 12:34:37,373 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:37,373 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:37,373 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:37,374 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:37,401 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:37,520 - podcast_processing.episode_processor - INFO -   Processing chunk 4/18 (210.0s)
[Rank 0] 2026-01-23 12:34:37,555 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 133439/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:37,637 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:37,637 - podcast_processing.episode_processor - DEBUG - System speaker has 426 words
[Rank 0] 2026-01-23 12:34:37,683 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:37,684 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:37,684 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:37,684 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:37,711 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:37,798 - podcast_processing.episode_processor - INFO -   Processing chunk 5/18 (210.0s)
[Rank 0] 2026-01-23 12:34:37,833 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 98403/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:37,939 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:37,939 - podcast_processing.episode_processor - DEBUG - System speaker has 324 words
[Rank 0] 2026-01-23 12:34:37,986 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:37,986 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:37,986 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:37,987 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:38,014 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:38,130 - podcast_processing.episode_processor - INFO -   Processing chunk 6/18 (210.0s)
[Rank 0] 2026-01-23 12:34:38,164 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 80638/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:38,276 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:38,537 - podcast_processing.episode_processor - DEBUG - System speaker has 174 words
[Rank 0] 2026-01-23 12:34:38,539 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:38,540 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:38,540 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:38,540 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:38,567 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:38,666 - podcast_processing.episode_processor - INFO -   Processing chunk 7/18 (210.0s)
[Rank 0] 2026-01-23 12:34:38,701 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 22079/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:38,794 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:38,795 - podcast_processing.episode_processor - DEBUG - System speaker has 275 words
[Rank 0] 2026-01-23 12:34:38,841 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:38,841 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:38,842 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:38,842 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:38,869 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:38,953 - podcast_processing.episode_processor - INFO -   Processing chunk 8/18 (210.0s)
[Rank 0] 2026-01-23 12:34:38,988 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 38158/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:39,069 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:39,069 - podcast_processing.episode_processor - DEBUG - System speaker has 273 words
[Rank 0] 2026-01-23 12:34:39,116 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:39,116 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:39,117 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:39,117 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:39,144 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:39,228 - podcast_processing.episode_processor - INFO -   Processing chunk 9/18 (210.0s)
[Rank 0] 2026-01-23 12:34:39,263 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 42719/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:39,344 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:39,344 - podcast_processing.episode_processor - DEBUG - System speaker has 368 words
[Rank 0] 2026-01-23 12:34:39,391 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:39,391 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:39,392 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:39,392 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:39,419 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:39,503 - podcast_processing.episode_processor - INFO -   Processing chunk 10/18 (210.0s)
[Rank 0] 2026-01-23 12:34:39,538 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:39,619 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:39,619 - podcast_processing.episode_processor - DEBUG - System speaker has 398 words
[Rank 0] 2026-01-23 12:34:39,666 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:39,666 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:39,666 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:39,667 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:39,694 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:39,779 - podcast_processing.episode_processor - INFO -   Processing chunk 11/18 (210.0s)
[Rank 0] 2026-01-23 12:34:39,815 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 89038/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:39,917 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:39,917 - podcast_processing.episode_processor - DEBUG - System speaker has 344 words
[Rank 0] 2026-01-23 12:34:39,963 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:39,963 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:39,963 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:39,964 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:39,991 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:40,088 - podcast_processing.episode_processor - INFO -   Processing chunk 12/18 (210.0s)
[Rank 0] 2026-01-23 12:34:40,122 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 118077/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:40,213 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:40,214 - podcast_processing.episode_processor - DEBUG - System speaker has 279 words
[Rank 0] 2026-01-23 12:34:40,260 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:40,260 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:40,260 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:40,261 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:40,288 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:40,372 - podcast_processing.episode_processor - INFO -   Processing chunk 13/18 (210.0s)
[Rank 0] 2026-01-23 12:34:40,418 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12724/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:40,514 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:40,514 - podcast_processing.episode_processor - DEBUG - System speaker has 338 words
[Rank 0] 2026-01-23 12:34:40,561 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:40,561 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:40,561 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:40,562 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:40,589 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:40,673 - podcast_processing.episode_processor - INFO -   Processing chunk 14/18 (210.0s)
[Rank 0] 2026-01-23 12:34:40,719 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 31680/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:40,831 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:40,832 - podcast_processing.episode_processor - DEBUG - System speaker has 465 words
[Rank 0] 2026-01-23 12:34:40,878 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:40,878 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:40,878 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:40,879 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:40,906 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:41,293 - podcast_processing.episode_processor - INFO -   Processing chunk 15/18 (210.0s)
[Rank 0] 2026-01-23 12:34:41,351 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 47517/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:41,448 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:41,448 - podcast_processing.episode_processor - DEBUG - System speaker has 411 words
[Rank 0] 2026-01-23 12:34:41,494 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:41,494 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:41,494 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:41,495 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:41,522 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:41,622 - podcast_processing.episode_processor - INFO -   Processing chunk 16/18 (210.0s)
[Rank 0] 2026-01-23 12:34:41,668 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 86162/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:41,750 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:41,750 - podcast_processing.episode_processor - DEBUG - System speaker has 353 words
[Rank 0] 2026-01-23 12:34:41,797 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:41,797 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:41,797 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:41,798 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:41,825 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:41,919 - podcast_processing.episode_processor - INFO -   Processing chunk 17/18 (210.0s)
[Rank 0] 2026-01-23 12:34:41,965 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 145926/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:42,061 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:42,061 - podcast_processing.episode_processor - DEBUG - System speaker has 226 words
[Rank 0] 2026-01-23 12:34:42,108 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:42,108 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:42,108 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:42,109 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:42,136 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:42,230 - podcast_processing.episode_processor - INFO -   Processing chunk 18/18 (34.5s)
[Rank 0] 2026-01-23 12:34:42,238 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12480/828304 samples zeroed
[Rank 0] 2026-01-23 12:34:42,261 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 432]), System codes shape: torch.Size([1, 8, 432])
[Rank 0] 2026-01-23 12:34:42,261 - podcast_processing.episode_processor - DEBUG - System speaker has 53 words
[Rank 0] 2026-01-23 12:34:42,261 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 432])
[Rank 0] 2026-01-23 12:34:42,261 - podcast_processing.episode_processor - DEBUG - Padded to max_t=432
[Rank 0] 2026-01-23 12:34:42,261 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 432]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:42,262 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 433])
[Rank 0] 2026-01-23 12:34:42,287 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 432, 4096])
[Rank 0] 2026-01-23 12:34:42,508 - podcast_processing.episode_processor - INFO - Combined 18 chunks into final output shape: torch.Size([45057, 4096])
[Rank 0] 2026-01-23 12:34:46,478 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Animal Talk_Take a photo of a bear from 15 angles - Episode 44/features_assignment_1.npy
[Rank 0] 2026-01-23 12:34:46,478 - podcast_processing.episode_processor - INFO -   Saved features: 45057 frames
[Rank 0] 2026-01-23 12:34:46,478 - podcast_processing.label_generator - DEBUG - Processing 126 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:34:46,501 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Animal Talk_Take a photo of a bear from 15 angles - Episode 44/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:34:46,501 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 427/45057 positive
[Rank 0] 2026-01-23 12:34:46,520 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Animal Talk_Take a photo of a bear from 15 angles - Episode 44/metadata_shift_1.json
[Rank 0] 2026-01-23 12:34:46,520 - podcast_processing.episode_processor - INFO - Completed episode: Animal Talk_Take a photo of a bear from 15 angles - Episode 44
[Rank 0] 2026-01-23 12:34:46,594 - podcast_processing.distributed_orchestrator - INFO - âœ“ Animal Talk_Take a photo of a bear from 15 angles - Episode 44
[Rank 0] 2026-01-23 12:34:46,598 - podcast_processing.episode_processor - INFO - Processing episode: Art & Company Podcast_Cat del Buono and Yeon Jin Kim Women Artists and the Allure of New Media  - #9
[Rank 0] 2026-01-23 12:34:46,601 - podcast_processing.label_generator - DEBUG - Loaded 74 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Art & Company Podcast_Cat del Buono and Yeon Jin Kim Women Artists and the Allure of New Media  - #9.json
[Rank 0] 2026-01-23 12:34:46,603 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_03 (longer), SPEAKER_00 (shorter)
[Rank 0] 2026-01-23 12:34:47,291 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [901.30, 901.45], using fallback
[Rank 0] 2026-01-23 12:34:47,631 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1327.65, 1327.65], using fallback
[Rank 0] 2026-01-23 12:34:47,730 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1442.41, 1442.41], using fallback
[Rank 0] 2026-01-23 12:34:47,823 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1546.10, 1546.14], using fallback
[Rank 0] 2026-01-23 12:34:47,823 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1546.19, 1546.25], using fallback
[Rank 0] 2026-01-23 12:34:47,823 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1546.25, 1546.49], using fallback
[Rank 0] 2026-01-23 12:34:48,151 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1956.55, 1956.55], using fallback
[Rank 0] 2026-01-23 12:34:48,895 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2778.39, 2778.57], using fallback
[Rank 0] 2026-01-23 12:34:49,043 - podcast_processing.alignment_merger - INFO - Created 9108 word alignments
[Rank 0] 2026-01-23 12:34:49,720 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_03: torch.Size([1, 71209584]), SPEAKER_00: torch.Size([1, 71209584])
[Rank 0] 2026-01-23 12:34:49,720 - podcast_processing.episode_processor - INFO - Episode duration: 2967.07s
[Rank 0] 2026-01-23 12:34:49,721 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:34:49,727 - podcast_processing.audio_masking - DEBUG - Creating mask from 45 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:34:49,761 - podcast_processing.audio_masking - DEBUG - Mask covers 532319/71209584 samples (0.75%)
[Rank 0] 2026-01-23 12:34:49,796 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 532319/71209584 samples masked
[Rank 0] 2026-01-23 12:34:50,567 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 532319/71209584 samples zeroed
[Rank 0] 2026-01-23 12:34:50,567 - podcast_processing.episode_processor - INFO - Audio is 2967.1s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:34:50,568 - podcast_processing.episode_processor - INFO - Processing 2967.1s audio in 15 chunks of 210s each
[Rank 0] 2026-01-23 12:34:50,568 - podcast_processing.episode_processor - INFO -   Processing chunk 1/15 (210.0s)
[Rank 0] 2026-01-23 12:34:50,616 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:50,699 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:50,699 - podcast_processing.episode_processor - DEBUG - System speaker has 22 words
[Rank 0] 2026-01-23 12:34:50,745 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:50,745 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:50,745 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:50,746 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:50,773 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:50,860 - podcast_processing.episode_processor - INFO -   Processing chunk 2/15 (210.0s)
[Rank 0] 2026-01-23 12:34:50,908 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 129840/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:50,990 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:50,990 - podcast_processing.episode_processor - DEBUG - System speaker has 179 words
[Rank 0] 2026-01-23 12:34:51,037 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:51,037 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:51,037 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:51,038 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:51,065 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:51,148 - podcast_processing.episode_processor - INFO -   Processing chunk 3/15 (210.0s)
[Rank 0] 2026-01-23 12:34:51,194 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 24960/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:51,275 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:51,276 - podcast_processing.episode_processor - DEBUG - System speaker has 2 words
[Rank 0] 2026-01-23 12:34:51,322 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:51,322 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:51,322 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:51,323 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:51,350 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:51,432 - podcast_processing.episode_processor - INFO -   Processing chunk 4/15 (210.0s)
[Rank 0] 2026-01-23 12:34:51,473 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16562/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:51,555 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:51,555 - podcast_processing.episode_processor - DEBUG - System speaker has 2 words
[Rank 0] 2026-01-23 12:34:51,602 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:51,602 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:51,602 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:51,602 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:51,629 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:51,712 - podcast_processing.episode_processor - INFO -   Processing chunk 5/15 (210.0s)
[Rank 0] 2026-01-23 12:34:51,757 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 83039/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:51,839 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:51,839 - podcast_processing.episode_processor - DEBUG - System speaker has 265 words
[Rank 0] 2026-01-23 12:34:51,886 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:51,886 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:51,886 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:51,886 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:51,913 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:51,996 - podcast_processing.episode_processor - INFO -   Processing chunk 6/15 (210.0s)
[Rank 0] 2026-01-23 12:34:52,048 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 40800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:52,130 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:52,130 - podcast_processing.episode_processor - DEBUG - System speaker has 352 words
[Rank 0] 2026-01-23 12:34:52,177 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:52,177 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:52,177 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:52,178 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:52,205 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:52,288 - podcast_processing.episode_processor - INFO -   Processing chunk 7/15 (210.0s)
[Rank 0] 2026-01-23 12:34:52,712 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 28319/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:52,804 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:52,804 - podcast_processing.episode_processor - DEBUG - System speaker has 46 words
[Rank 0] 2026-01-23 12:34:52,850 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:52,850 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:52,850 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:52,852 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:52,879 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:52,976 - podcast_processing.episode_processor - INFO -   Processing chunk 8/15 (210.0s)
[Rank 0] 2026-01-23 12:34:53,021 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 52801/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:53,114 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:53,114 - podcast_processing.episode_processor - DEBUG - System speaker has 61 words
[Rank 0] 2026-01-23 12:34:53,161 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:53,161 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:53,161 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:53,162 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:53,189 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:53,283 - podcast_processing.episode_processor - INFO -   Processing chunk 9/15 (210.0s)
[Rank 0] 2026-01-23 12:34:53,318 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:53,399 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:53,399 - podcast_processing.episode_processor - DEBUG - System speaker has 26 words
[Rank 0] 2026-01-23 12:34:53,446 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:53,446 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:53,446 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:53,447 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:53,474 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:53,557 - podcast_processing.episode_processor - INFO -   Processing chunk 10/15 (210.0s)
[Rank 0] 2026-01-23 12:34:53,591 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:53,677 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:53,677 - podcast_processing.episode_processor - DEBUG - System speaker has 614 words
[Rank 0] 2026-01-23 12:34:53,723 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:53,723 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:53,724 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:53,724 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:53,752 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:53,834 - podcast_processing.episode_processor - INFO -   Processing chunk 11/15 (210.0s)
[Rank 0] 2026-01-23 12:34:53,869 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7918/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:53,950 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:53,951 - podcast_processing.episode_processor - DEBUG - System speaker has 420 words
[Rank 0] 2026-01-23 12:34:53,997 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:53,997 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:53,998 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:53,998 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:54,025 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:54,108 - podcast_processing.episode_processor - INFO -   Processing chunk 12/15 (210.0s)
[Rank 0] 2026-01-23 12:34:54,142 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 113996/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:54,224 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:54,224 - podcast_processing.episode_processor - DEBUG - System speaker has 401 words
[Rank 0] 2026-01-23 12:34:54,271 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:54,271 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:54,271 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:54,272 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:54,298 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:54,391 - podcast_processing.episode_processor - INFO -   Processing chunk 13/15 (210.0s)
[Rank 0] 2026-01-23 12:34:54,436 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 34084/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:54,518 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:54,518 - podcast_processing.episode_processor - DEBUG - System speaker has 221 words
[Rank 0] 2026-01-23 12:34:54,565 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:54,565 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:54,565 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:54,565 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:54,592 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:54,677 - podcast_processing.episode_processor - INFO -   Processing chunk 14/15 (210.0s)
[Rank 0] 2026-01-23 12:34:55,125 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:55,235 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:55,235 - podcast_processing.episode_processor - DEBUG - System speaker has 68 words
[Rank 0] 2026-01-23 12:34:55,281 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:55,281 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:55,281 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:55,282 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:55,309 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:55,396 - podcast_processing.episode_processor - INFO -   Processing chunk 15/15 (27.1s)
[Rank 0] 2026-01-23 12:34:55,402 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/649584 samples zeroed
[Rank 0] 2026-01-23 12:34:55,452 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 339]), System codes shape: torch.Size([1, 8, 339])
[Rank 0] 2026-01-23 12:34:55,452 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:34:55,452 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 339])
[Rank 0] 2026-01-23 12:34:55,452 - podcast_processing.episode_processor - DEBUG - Padded to max_t=339
[Rank 0] 2026-01-23 12:34:55,452 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 339]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:55,453 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 340])
[Rank 0] 2026-01-23 12:34:55,486 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 339, 4096])
[Rank 0] 2026-01-23 12:34:55,665 - podcast_processing.episode_processor - INFO - Combined 15 chunks into final output shape: torch.Size([37089, 4096])
[Rank 0] 2026-01-23 12:34:57,447 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Art & Company Podcast_Cat del Buono and Yeon Jin Kim Women Artists and the Allure of New Media  - #9/features_assignment_0.npy
[Rank 0] 2026-01-23 12:34:57,448 - podcast_processing.episode_processor - INFO -   Saved features: 37089 frames
[Rank 0] 2026-01-23 12:34:57,448 - podcast_processing.label_generator - DEBUG - Processing 29 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:34:57,467 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Art & Company Podcast_Cat del Buono and Yeon Jin Kim Women Artists and the Allure of New Media  - #9/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:34:57,468 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 187/37089 positive
[Rank 0] 2026-01-23 12:34:57,468 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:34:57,481 - podcast_processing.audio_masking - DEBUG - Creating mask from 29 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:34:57,545 - podcast_processing.audio_masking - DEBUG - Mask covers 356863/71209584 samples (0.50%)
[Rank 0] 2026-01-23 12:34:57,580 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 356863/71209584 samples masked
[Rank 0] 2026-01-23 12:34:58,336 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 356863/71209584 samples zeroed
[Rank 0] 2026-01-23 12:34:58,336 - podcast_processing.episode_processor - INFO - Audio is 2967.1s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:34:58,336 - podcast_processing.episode_processor - INFO - Processing 2967.1s audio in 15 chunks of 210s each
[Rank 0] 2026-01-23 12:34:58,336 - podcast_processing.episode_processor - INFO -   Processing chunk 1/15 (210.0s)
[Rank 0] 2026-01-23 12:34:58,370 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:58,453 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:58,453 - podcast_processing.episode_processor - DEBUG - System speaker has 471 words
[Rank 0] 2026-01-23 12:34:58,499 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:58,499 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:58,499 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:58,500 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:58,527 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:58,641 - podcast_processing.episode_processor - INFO -   Processing chunk 2/15 (210.0s)
[Rank 0] 2026-01-23 12:34:58,675 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:58,775 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:58,775 - podcast_processing.episode_processor - DEBUG - System speaker has 395 words
[Rank 0] 2026-01-23 12:34:58,822 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:58,822 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:58,822 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:58,823 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:58,850 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:59,711 - podcast_processing.episode_processor - INFO -   Processing chunk 3/15 (210.0s)
[Rank 0] 2026-01-23 12:34:59,747 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 32400/5040000 samples zeroed
[Rank 0] 2026-01-23 12:34:59,829 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:34:59,830 - podcast_processing.episode_processor - DEBUG - System speaker has 248 words
[Rank 0] 2026-01-23 12:34:59,876 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:34:59,876 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:34:59,876 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:34:59,876 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:34:59,904 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:34:59,986 - podcast_processing.episode_processor - INFO -   Processing chunk 4/15 (210.0s)
[Rank 0] 2026-01-23 12:35:00,021 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 19200/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:00,103 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:00,103 - podcast_processing.episode_processor - DEBUG - System speaker has 313 words
[Rank 0] 2026-01-23 12:35:00,150 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:00,150 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:00,150 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:00,150 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:00,177 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:00,260 - podcast_processing.episode_processor - INFO -   Processing chunk 5/15 (210.0s)
[Rank 0] 2026-01-23 12:35:00,295 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 36002/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:00,376 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:00,376 - podcast_processing.episode_processor - DEBUG - System speaker has 303 words
[Rank 0] 2026-01-23 12:35:00,423 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:00,423 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:00,423 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:00,424 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:00,451 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:00,534 - podcast_processing.episode_processor - INFO -   Processing chunk 6/15 (210.0s)
[Rank 0] 2026-01-23 12:35:00,569 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 13437/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:00,662 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:00,662 - podcast_processing.episode_processor - DEBUG - System speaker has 194 words
[Rank 0] 2026-01-23 12:35:00,709 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:00,709 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:00,709 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:00,709 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:00,736 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:00,827 - podcast_processing.episode_processor - INFO -   Processing chunk 7/15 (210.0s)
[Rank 0] 2026-01-23 12:35:00,862 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 56875/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:00,954 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:00,954 - podcast_processing.episode_processor - DEBUG - System speaker has 498 words
[Rank 0] 2026-01-23 12:35:01,001 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:01,001 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:01,001 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:01,002 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:01,029 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:01,129 - podcast_processing.episode_processor - INFO -   Processing chunk 8/15 (210.0s)
[Rank 0] 2026-01-23 12:35:01,164 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20162/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:01,246 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:01,882 - podcast_processing.episode_processor - DEBUG - System speaker has 106 words
[Rank 0] 2026-01-23 12:35:01,884 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:01,884 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:01,884 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:01,884 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:01,912 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:02,001 - podcast_processing.episode_processor - INFO -   Processing chunk 9/15 (210.0s)
[Rank 0] 2026-01-23 12:35:02,037 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:02,118 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:02,119 - podcast_processing.episode_processor - DEBUG - System speaker has 124 words
[Rank 0] 2026-01-23 12:35:02,165 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:02,165 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:02,166 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:02,166 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:02,194 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:02,276 - podcast_processing.episode_processor - INFO -   Processing chunk 10/15 (210.0s)
[Rank 0] 2026-01-23 12:35:02,317 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 17039/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:02,410 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:02,411 - podcast_processing.episode_processor - DEBUG - System speaker has 96 words
[Rank 0] 2026-01-23 12:35:02,457 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:02,457 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:02,457 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:02,458 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:02,485 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:02,572 - podcast_processing.episode_processor - INFO -   Processing chunk 11/15 (210.0s)
[Rank 0] 2026-01-23 12:35:02,607 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:02,703 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:02,704 - podcast_processing.episode_processor - DEBUG - System speaker has 158 words
[Rank 0] 2026-01-23 12:35:02,750 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:02,750 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:02,750 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:02,751 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:02,778 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:02,878 - podcast_processing.episode_processor - INFO -   Processing chunk 12/15 (210.0s)
[Rank 0] 2026-01-23 12:35:02,912 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 38396/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:03,028 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:03,028 - podcast_processing.episode_processor - DEBUG - System speaker has 270 words
[Rank 0] 2026-01-23 12:35:03,075 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:03,075 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:03,075 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:03,076 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:03,103 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:03,221 - podcast_processing.episode_processor - INFO -   Processing chunk 13/15 (210.0s)
[Rank 0] 2026-01-23 12:35:03,789 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 97680/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:03,878 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:03,878 - podcast_processing.episode_processor - DEBUG - System speaker has 328 words
[Rank 0] 2026-01-23 12:35:03,924 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:03,924 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:03,924 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:03,925 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:03,952 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:04,035 - podcast_processing.episode_processor - INFO -   Processing chunk 14/15 (210.0s)
[Rank 0] 2026-01-23 12:35:04,081 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 25672/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:04,163 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:04,164 - podcast_processing.episode_processor - DEBUG - System speaker has 290 words
[Rank 0] 2026-01-23 12:35:04,210 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:04,210 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:04,210 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:04,211 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:04,238 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:04,339 - podcast_processing.episode_processor - INFO -   Processing chunk 15/15 (27.1s)
[Rank 0] 2026-01-23 12:35:04,345 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/649584 samples zeroed
[Rank 0] 2026-01-23 12:35:04,369 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 339]), System codes shape: torch.Size([1, 8, 339])
[Rank 0] 2026-01-23 12:35:04,370 - podcast_processing.episode_processor - DEBUG - System speaker has 56 words
[Rank 0] 2026-01-23 12:35:04,370 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 339])
[Rank 0] 2026-01-23 12:35:04,370 - podcast_processing.episode_processor - DEBUG - Padded to max_t=339
[Rank 0] 2026-01-23 12:35:04,370 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 339]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:04,371 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 340])
[Rank 0] 2026-01-23 12:35:04,397 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 339, 4096])
[Rank 0] 2026-01-23 12:35:04,573 - podcast_processing.episode_processor - INFO - Combined 15 chunks into final output shape: torch.Size([37089, 4096])
[Rank 0] 2026-01-23 12:35:06,389 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Art & Company Podcast_Cat del Buono and Yeon Jin Kim Women Artists and the Allure of New Media  - #9/features_assignment_1.npy
[Rank 0] 2026-01-23 12:35:06,389 - podcast_processing.episode_processor - INFO -   Saved features: 37089 frames
[Rank 0] 2026-01-23 12:35:06,772 - podcast_processing.label_generator - DEBUG - Processing 45 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:35:06,814 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Art & Company Podcast_Cat del Buono and Yeon Jin Kim Women Artists and the Allure of New Media  - #9/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:35:06,814 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 280/37089 positive
[Rank 0] 2026-01-23 12:35:06,833 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Art & Company Podcast_Cat del Buono and Yeon Jin Kim Women Artists and the Allure of New Media  - #9/metadata_shift_1.json
[Rank 0] 2026-01-23 12:35:06,833 - podcast_processing.episode_processor - INFO - Completed episode: Art & Company Podcast_Cat del Buono and Yeon Jin Kim Women Artists and the Allure of New Media  - #9
[Rank 0] 2026-01-23 12:35:06,909 - podcast_processing.distributed_orchestrator - INFO - âœ“ Art & Company Podcast_Cat del Buono and Yeon Jin Kim Women Artists and the Allure of New Media  - #9
[Rank 0] 2026-01-23 12:35:06,939 - podcast_processing.episode_processor - INFO - Processing episode: Arts Council England_Arts digital R&D podcast 4 data and archives
[Rank 0] 2026-01-23 12:35:06,959 - podcast_processing.label_generator - DEBUG - Loaded 1 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Arts Council England_Arts digital R&D podcast 4 data and archives.json
[Rank 0] 2026-01-23 12:35:06,959 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_03 (longer), SPEAKER_01 (shorter)
[Rank 0] 2026-01-23 12:35:07,283 - podcast_processing.alignment_merger - INFO - Created 6722 word alignments
[Rank 0] 2026-01-23 12:35:07,807 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_03: torch.Size([1, 54615772]), SPEAKER_01: torch.Size([1, 54615772])
[Rank 0] 2026-01-23 12:35:07,807 - podcast_processing.episode_processor - INFO - Episode duration: 2275.66s
[Rank 0] 2026-01-23 12:35:07,807 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:35:07,811 - podcast_processing.audio_masking - DEBUG - No laughter events found for SPEAKER_01
[Rank 0] 2026-01-23 12:35:07,812 - podcast_processing.episode_processor - INFO - Audio is 2275.7s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:35:07,812 - podcast_processing.episode_processor - INFO - Processing 2275.7s audio in 11 chunks of 210s each
[Rank 0] 2026-01-23 12:35:07,812 - podcast_processing.episode_processor - INFO -   Processing chunk 1/11 (210.0s)
[Rank 0] 2026-01-23 12:35:07,913 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:07,913 - podcast_processing.episode_processor - DEBUG - System speaker has 53 words
[Rank 0] 2026-01-23 12:35:07,959 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:07,959 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:07,959 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:07,960 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:07,989 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:08,071 - podcast_processing.episode_processor - INFO -   Processing chunk 2/11 (210.0s)
[Rank 0] 2026-01-23 12:35:08,155 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:08,155 - podcast_processing.episode_processor - DEBUG - System speaker has 131 words
[Rank 0] 2026-01-23 12:35:08,202 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:08,202 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:08,202 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:08,203 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:08,233 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:08,313 - podcast_processing.episode_processor - INFO -   Processing chunk 3/11 (210.0s)
[Rank 0] 2026-01-23 12:35:08,413 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:08,413 - podcast_processing.episode_processor - DEBUG - System speaker has 332 words
[Rank 0] 2026-01-23 12:35:08,459 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:08,459 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:08,460 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:08,460 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:08,492 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:08,570 - podcast_processing.episode_processor - INFO -   Processing chunk 4/11 (210.0s)
[Rank 0] 2026-01-23 12:35:08,653 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:08,653 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:08,699 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:08,700 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:08,700 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:08,700 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:08,727 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:08,819 - podcast_processing.episode_processor - INFO -   Processing chunk 5/11 (210.0s)
[Rank 0] 2026-01-23 12:35:09,208 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:09,208 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:09,254 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:09,254 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:09,254 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:09,255 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:09,282 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:09,363 - podcast_processing.episode_processor - INFO -   Processing chunk 6/11 (210.0s)
[Rank 0] 2026-01-23 12:35:09,656 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:09,656 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:09,702 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:09,702 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:09,703 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:09,703 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:09,731 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:09,821 - podcast_processing.episode_processor - INFO -   Processing chunk 7/11 (210.0s)
[Rank 0] 2026-01-23 12:35:09,903 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:09,903 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:09,950 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:09,950 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:09,951 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:09,951 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:09,978 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:10,061 - podcast_processing.episode_processor - INFO -   Processing chunk 8/11 (210.0s)
[Rank 0] 2026-01-23 12:35:10,143 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:10,143 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:10,190 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:10,190 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:10,190 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:10,190 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:10,217 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:10,301 - podcast_processing.episode_processor - INFO -   Processing chunk 9/11 (210.0s)
[Rank 0] 2026-01-23 12:35:10,404 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:10,404 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:10,447 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:10,448 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:10,448 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:10,448 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:10,480 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:10,585 - podcast_processing.episode_processor - INFO -   Processing chunk 10/11 (210.0s)
[Rank 0] 2026-01-23 12:35:10,683 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:10,683 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:10,730 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:10,730 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:10,730 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:10,731 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:10,758 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:10,858 - podcast_processing.episode_processor - INFO -   Processing chunk 11/11 (175.7s)
[Rank 0] 2026-01-23 12:35:11,311 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2196]), System codes shape: torch.Size([1, 8, 2196])
[Rank 0] 2026-01-23 12:35:11,320 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:11,346 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2196])
[Rank 0] 2026-01-23 12:35:11,347 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2196
[Rank 0] 2026-01-23 12:35:11,347 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2196]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:11,347 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2197])
[Rank 0] 2026-01-23 12:35:11,420 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2196, 4096])
[Rank 0] 2026-01-23 12:35:11,573 - podcast_processing.episode_processor - INFO - Combined 11 chunks into final output shape: torch.Size([28446, 4096])
[Rank 0] 2026-01-23 12:35:13,571 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Arts Council England_Arts digital R&D podcast 4 data and archives/features_assignment_0.npy
[Rank 0] 2026-01-23 12:35:13,571 - podcast_processing.episode_processor - INFO -   Saved features: 28446 frames
[Rank 0] 2026-01-23 12:35:13,571 - podcast_processing.label_generator - DEBUG - Processing 1 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:35:13,627 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Arts Council England_Arts digital R&D podcast 4 data and archives/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:35:13,627 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 10/28446 positive
[Rank 0] 2026-01-23 12:35:13,627 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:35:13,634 - podcast_processing.audio_masking - DEBUG - Creating mask from 1 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:35:13,695 - podcast_processing.audio_masking - DEBUG - Mask covers 19920/54615772 samples (0.04%)
[Rank 0] 2026-01-23 12:35:13,725 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 19920/54615772 samples masked
[Rank 0] 2026-01-23 12:35:14,309 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 19920/54615772 samples zeroed
[Rank 0] 2026-01-23 12:35:14,309 - podcast_processing.episode_processor - INFO - Audio is 2275.7s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:35:14,310 - podcast_processing.episode_processor - INFO - Processing 2275.7s audio in 11 chunks of 210s each
[Rank 0] 2026-01-23 12:35:14,310 - podcast_processing.episode_processor - INFO -   Processing chunk 1/11 (210.0s)
[Rank 0] 2026-01-23 12:35:14,345 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:14,436 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:14,436 - podcast_processing.episode_processor - DEBUG - System speaker has 480 words
[Rank 0] 2026-01-23 12:35:14,482 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:14,482 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:14,482 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:14,483 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:14,510 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:14,616 - podcast_processing.episode_processor - INFO -   Processing chunk 2/11 (210.0s)
[Rank 0] 2026-01-23 12:35:14,650 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:14,732 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:14,732 - podcast_processing.episode_processor - DEBUG - System speaker has 514 words
[Rank 0] 2026-01-23 12:35:14,779 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:14,779 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:14,779 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:14,780 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:14,806 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:14,897 - podcast_processing.episode_processor - INFO -   Processing chunk 3/11 (210.0s)
[Rank 0] 2026-01-23 12:35:14,931 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:15,012 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:15,012 - podcast_processing.episode_processor - DEBUG - System speaker has 256 words
[Rank 0] 2026-01-23 12:35:15,059 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:15,059 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:15,059 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:15,060 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:15,086 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:15,180 - podcast_processing.episode_processor - INFO -   Processing chunk 4/11 (210.0s)
[Rank 0] 2026-01-23 12:35:15,215 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:15,297 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:15,297 - podcast_processing.episode_processor - DEBUG - System speaker has 617 words
[Rank 0] 2026-01-23 12:35:15,344 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:15,344 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:15,344 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:15,345 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:15,371 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:15,458 - podcast_processing.episode_processor - INFO -   Processing chunk 5/11 (210.0s)
[Rank 0] 2026-01-23 12:35:15,498 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:15,597 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:15,597 - podcast_processing.episode_processor - DEBUG - System speaker has 303 words
[Rank 0] 2026-01-23 12:35:15,644 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:15,644 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:15,644 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:15,644 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:15,671 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:15,784 - podcast_processing.episode_processor - INFO -   Processing chunk 6/11 (210.0s)
[Rank 0] 2026-01-23 12:35:15,819 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:15,932 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:15,932 - podcast_processing.episode_processor - DEBUG - System speaker has 479 words
[Rank 0] 2026-01-23 12:35:15,979 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:15,979 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:15,979 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:15,979 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:16,006 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:16,117 - podcast_processing.episode_processor - INFO -   Processing chunk 7/11 (210.0s)
[Rank 0] 2026-01-23 12:35:16,152 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:16,252 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:16,252 - podcast_processing.episode_processor - DEBUG - System speaker has 563 words
[Rank 0] 2026-01-23 12:35:16,299 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:16,446 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:16,446 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:16,446 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:16,473 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:16,561 - podcast_processing.episode_processor - INFO -   Processing chunk 8/11 (210.0s)
[Rank 0] 2026-01-23 12:35:16,596 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:16,678 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:16,679 - podcast_processing.episode_processor - DEBUG - System speaker has 599 words
[Rank 0] 2026-01-23 12:35:16,725 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:16,725 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:16,726 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:16,726 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:16,753 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:16,848 - podcast_processing.episode_processor - INFO -   Processing chunk 9/11 (210.0s)
[Rank 0] 2026-01-23 12:35:16,882 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:16,973 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:16,973 - podcast_processing.episode_processor - DEBUG - System speaker has 685 words
[Rank 0] 2026-01-23 12:35:17,020 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:17,020 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:17,020 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:17,021 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:17,048 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:17,131 - podcast_processing.episode_processor - INFO -   Processing chunk 10/11 (210.0s)
[Rank 0] 2026-01-23 12:35:17,166 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 19920/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:17,247 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:17,247 - podcast_processing.episode_processor - DEBUG - System speaker has 601 words
[Rank 0] 2026-01-23 12:35:17,294 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:17,294 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:17,294 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:17,295 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:17,322 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:17,408 - podcast_processing.episode_processor - INFO -   Processing chunk 11/11 (175.7s)
[Rank 0] 2026-01-23 12:35:17,446 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/4215772 samples zeroed
[Rank 0] 2026-01-23 12:35:17,525 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2196]), System codes shape: torch.Size([1, 8, 2196])
[Rank 0] 2026-01-23 12:35:17,525 - podcast_processing.episode_processor - DEBUG - System speaker has 409 words
[Rank 0] 2026-01-23 12:35:17,560 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2196])
[Rank 0] 2026-01-23 12:35:17,560 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2196
[Rank 0] 2026-01-23 12:35:17,560 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2196]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:17,561 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2197])
[Rank 0] 2026-01-23 12:35:17,588 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2196, 4096])
[Rank 0] 2026-01-23 12:35:17,786 - podcast_processing.episode_processor - INFO - Combined 11 chunks into final output shape: torch.Size([28446, 4096])
[Rank 0] 2026-01-23 12:35:19,289 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Arts Council England_Arts digital R&D podcast 4 data and archives/features_assignment_1.npy
[Rank 0] 2026-01-23 12:35:19,290 - podcast_processing.episode_processor - INFO -   Saved features: 28446 frames
[Rank 0] 2026-01-23 12:35:19,290 - podcast_processing.label_generator - DEBUG - Processing 0 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:35:19,875 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Arts Council England_Arts digital R&D podcast 4 data and archives/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:35:19,875 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 0/28446 positive
[Rank 0] 2026-01-23 12:35:19,904 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Arts Council England_Arts digital R&D podcast 4 data and archives/metadata_shift_1.json
[Rank 0] 2026-01-23 12:35:19,916 - podcast_processing.episode_processor - INFO - Completed episode: Arts Council England_Arts digital R&D podcast 4 data and archives
[Rank 0] 2026-01-23 12:35:19,980 - podcast_processing.distributed_orchestrator - INFO - âœ“ Arts Council England_Arts digital R&D podcast 4 data and archives
[Rank 0] 2026-01-23 12:35:19,982 - podcast_processing.episode_processor - INFO - Processing episode: Arts Council England_Digital R&D for the Arts Forum distributing content discussion
[Rank 0] 2026-01-23 12:35:19,991 - podcast_processing.label_generator - DEBUG - Loaded 4 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Arts Council England_Digital R&D for the Arts Forum distributing content discussion.json
[Rank 0] 2026-01-23 12:35:19,992 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_03 (longer), SPEAKER_01 (shorter)
[Rank 0] 2026-01-23 12:35:20,039 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [147.66, 147.93], using fallback
[Rank 0] 2026-01-23 12:35:20,107 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [557.09, 557.09], using fallback
[Rank 0] 2026-01-23 12:35:20,266 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1512.54, 1512.72], using fallback
[Rank 0] 2026-01-23 12:35:20,269 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1535.85, 1536.19], using fallback
[Rank 0] 2026-01-23 12:35:20,270 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1538.67, 1538.84], using fallback
[Rank 0] 2026-01-23 12:35:20,367 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2096.32, 2096.74], using fallback
[Rank 0] 2026-01-23 12:35:20,420 - podcast_processing.alignment_merger - INFO - Created 6294 word alignments
[Rank 0] 2026-01-23 12:35:20,980 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_03: torch.Size([1, 57112240]), SPEAKER_01: torch.Size([1, 57112240])
[Rank 0] 2026-01-23 12:35:20,980 - podcast_processing.episode_processor - INFO - Episode duration: 2379.68s
[Rank 0] 2026-01-23 12:35:20,980 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:35:20,985 - podcast_processing.audio_masking - DEBUG - No laughter events found for SPEAKER_01
[Rank 0] 2026-01-23 12:35:20,986 - podcast_processing.episode_processor - INFO - Audio is 2379.7s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:35:20,986 - podcast_processing.episode_processor - INFO - Processing 2379.7s audio in 12 chunks of 210s each
[Rank 0] 2026-01-23 12:35:20,986 - podcast_processing.episode_processor - INFO -   Processing chunk 1/12 (210.0s)
[Rank 0] 2026-01-23 12:35:21,072 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:21,072 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:21,118 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:21,118 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:21,118 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:21,118 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:21,146 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:21,247 - podcast_processing.episode_processor - INFO -   Processing chunk 2/12 (210.0s)
[Rank 0] 2026-01-23 12:35:21,367 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:21,367 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:21,414 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:21,414 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:21,414 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:21,414 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:21,442 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:21,544 - podcast_processing.episode_processor - INFO -   Processing chunk 3/12 (210.0s)
[Rank 0] 2026-01-23 12:35:21,676 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:21,676 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:21,723 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:21,723 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:21,723 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:21,724 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:21,751 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:21,834 - podcast_processing.episode_processor - INFO -   Processing chunk 4/12 (210.0s)
[Rank 0] 2026-01-23 12:35:21,931 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:21,931 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:21,978 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:21,978 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:21,978 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:21,978 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:22,008 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:22,091 - podcast_processing.episode_processor - INFO -   Processing chunk 5/12 (210.0s)
[Rank 0] 2026-01-23 12:35:22,173 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:22,513 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:22,513 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:22,513 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:22,513 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:22,514 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:22,541 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:22,635 - podcast_processing.episode_processor - INFO -   Processing chunk 6/12 (210.0s)
[Rank 0] 2026-01-23 12:35:22,755 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:22,756 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:22,802 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:22,802 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:22,803 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:22,803 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:22,830 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:22,922 - podcast_processing.episode_processor - INFO -   Processing chunk 7/12 (210.0s)
[Rank 0] 2026-01-23 12:35:23,004 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:23,004 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:23,051 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:23,051 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:23,051 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:23,052 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:23,079 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:23,175 - podcast_processing.episode_processor - INFO -   Processing chunk 8/12 (210.0s)
[Rank 0] 2026-01-23 12:35:23,271 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:23,271 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:23,318 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:23,318 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:23,318 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:23,319 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:23,346 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:23,430 - podcast_processing.episode_processor - INFO -   Processing chunk 9/12 (210.0s)
[Rank 0] 2026-01-23 12:35:23,513 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:23,513 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:23,559 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:23,560 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:23,560 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:23,560 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:23,587 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:24,294 - podcast_processing.episode_processor - INFO -   Processing chunk 10/12 (210.0s)
[Rank 0] 2026-01-23 12:35:24,375 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:24,376 - podcast_processing.episode_processor - DEBUG - System speaker has 25 words
[Rank 0] 2026-01-23 12:35:24,422 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:24,422 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:24,422 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:24,423 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:24,450 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:24,537 - podcast_processing.episode_processor - INFO -   Processing chunk 11/12 (210.0s)
[Rank 0] 2026-01-23 12:35:24,619 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:24,619 - podcast_processing.episode_processor - DEBUG - System speaker has 549 words
[Rank 0] 2026-01-23 12:35:24,666 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:24,666 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:24,666 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:24,666 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:24,694 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:24,778 - podcast_processing.episode_processor - INFO -   Processing chunk 12/12 (69.7s)
[Rank 0] 2026-01-23 12:35:24,830 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 871]), System codes shape: torch.Size([1, 8, 871])
[Rank 0] 2026-01-23 12:35:24,830 - podcast_processing.episode_processor - DEBUG - System speaker has 147 words
[Rank 0] 2026-01-23 12:35:24,836 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 871])
[Rank 0] 2026-01-23 12:35:24,836 - podcast_processing.episode_processor - DEBUG - Padded to max_t=871
[Rank 0] 2026-01-23 12:35:24,836 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 871]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:24,837 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 872])
[Rank 0] 2026-01-23 12:35:24,865 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 871, 4096])
[Rank 0] 2026-01-23 12:35:25,019 - podcast_processing.episode_processor - INFO - Combined 12 chunks into final output shape: torch.Size([29746, 4096])
[Rank 0] 2026-01-23 12:35:27,923 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Arts Council England_Digital R&D for the Arts Forum distributing content discussion/features_assignment_0.npy
[Rank 0] 2026-01-23 12:35:27,923 - podcast_processing.episode_processor - INFO -   Saved features: 29746 frames
[Rank 0] 2026-01-23 12:35:27,923 - podcast_processing.label_generator - DEBUG - Processing 4 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:35:27,946 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Arts Council England_Digital R&D for the Arts Forum distributing content discussion/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:35:27,946 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 15/29746 positive
[Rank 0] 2026-01-23 12:35:27,947 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:35:27,954 - podcast_processing.audio_masking - DEBUG - Creating mask from 4 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:35:28,016 - podcast_processing.audio_masking - DEBUG - Mask covers 28079/57112240 samples (0.05%)
[Rank 0] 2026-01-23 12:35:28,046 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 28079/57112240 samples masked
[Rank 0] 2026-01-23 12:35:28,665 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 28079/57112240 samples zeroed
[Rank 0] 2026-01-23 12:35:28,665 - podcast_processing.episode_processor - INFO - Audio is 2379.7s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:35:28,666 - podcast_processing.episode_processor - INFO - Processing 2379.7s audio in 12 chunks of 210s each
[Rank 0] 2026-01-23 12:35:28,666 - podcast_processing.episode_processor - INFO -   Processing chunk 1/12 (210.0s)
[Rank 0] 2026-01-23 12:35:28,710 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:28,803 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:28,803 - podcast_processing.episode_processor - DEBUG - System speaker has 535 words
[Rank 0] 2026-01-23 12:35:28,849 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:28,849 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:28,850 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:28,850 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:28,878 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:28,964 - podcast_processing.episode_processor - INFO -   Processing chunk 2/12 (210.0s)
[Rank 0] 2026-01-23 12:35:28,999 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 9360/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:29,082 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:29,082 - podcast_processing.episode_processor - DEBUG - System speaker has 528 words
[Rank 0] 2026-01-23 12:35:29,128 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:29,128 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:29,129 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:29,129 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:29,157 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:29,245 - podcast_processing.episode_processor - INFO -   Processing chunk 3/12 (210.0s)
[Rank 0] 2026-01-23 12:35:29,280 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:29,363 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:29,363 - podcast_processing.episode_processor - DEBUG - System speaker has 512 words
[Rank 0] 2026-01-23 12:35:29,409 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:29,409 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:29,410 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:29,410 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:29,438 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:29,523 - podcast_processing.episode_processor - INFO -   Processing chunk 4/12 (210.0s)
[Rank 0] 2026-01-23 12:35:29,569 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7919/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:29,651 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:29,651 - podcast_processing.episode_processor - DEBUG - System speaker has 536 words
[Rank 0] 2026-01-23 12:35:29,698 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:29,698 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:29,698 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:29,699 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:29,726 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:29,810 - podcast_processing.episode_processor - INFO -   Processing chunk 5/12 (210.0s)
[Rank 0] 2026-01-23 12:35:29,851 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:29,934 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:29,934 - podcast_processing.episode_processor - DEBUG - System speaker has 512 words
[Rank 0] 2026-01-23 12:35:29,981 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:29,981 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:29,981 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:29,982 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:30,009 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:30,093 - podcast_processing.episode_processor - INFO -   Processing chunk 6/12 (210.0s)
[Rank 0] 2026-01-23 12:35:30,140 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6960/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:30,240 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:30,240 - podcast_processing.episode_processor - DEBUG - System speaker has 587 words
[Rank 0] 2026-01-23 12:35:30,287 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:30,287 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:30,287 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:30,287 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:30,315 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:30,399 - podcast_processing.episode_processor - INFO -   Processing chunk 7/12 (210.0s)
[Rank 0] 2026-01-23 12:35:30,438 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:30,520 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:30,520 - podcast_processing.episode_processor - DEBUG - System speaker has 565 words
[Rank 0] 2026-01-23 12:35:30,567 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:30,567 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:30,567 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:30,568 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:30,595 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:30,697 - podcast_processing.episode_processor - INFO -   Processing chunk 8/12 (210.0s)
[Rank 0] 2026-01-23 12:35:30,733 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3840/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:30,815 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:30,815 - podcast_processing.episode_processor - DEBUG - System speaker has 547 words
[Rank 0] 2026-01-23 12:35:30,861 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:30,862 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:30,862 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:30,862 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:30,890 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:30,973 - podcast_processing.episode_processor - INFO -   Processing chunk 9/12 (210.0s)
[Rank 0] 2026-01-23 12:35:31,018 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:31,101 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:31,101 - podcast_processing.episode_processor - DEBUG - System speaker has 415 words
[Rank 0] 2026-01-23 12:35:31,147 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:31,147 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:31,147 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:31,148 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:31,175 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:31,257 - podcast_processing.episode_processor - INFO -   Processing chunk 10/12 (210.0s)
[Rank 0] 2026-01-23 12:35:31,293 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:31,376 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:31,377 - podcast_processing.episode_processor - DEBUG - System speaker has 258 words
[Rank 0] 2026-01-23 12:35:31,423 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:31,423 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:31,423 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:31,424 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:31,451 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:31,533 - podcast_processing.episode_processor - INFO -   Processing chunk 11/12 (210.0s)
[Rank 0] 2026-01-23 12:35:31,581 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:31,663 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:31,663 - podcast_processing.episode_processor - DEBUG - System speaker has 79 words
[Rank 0] 2026-01-23 12:35:31,709 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:31,710 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:31,710 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:31,710 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:31,738 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:31,820 - podcast_processing.episode_processor - INFO -   Processing chunk 12/12 (69.7s)
[Rank 0] 2026-01-23 12:35:31,836 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/1672240 samples zeroed
[Rank 0] 2026-01-23 12:35:31,867 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 871]), System codes shape: torch.Size([1, 8, 871])
[Rank 0] 2026-01-23 12:35:31,867 - podcast_processing.episode_processor - DEBUG - System speaker has 50 words
[Rank 0] 2026-01-23 12:35:31,873 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 871])
[Rank 0] 2026-01-23 12:35:31,874 - podcast_processing.episode_processor - DEBUG - Padded to max_t=871
[Rank 0] 2026-01-23 12:35:31,874 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 871]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:31,874 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 872])
[Rank 0] 2026-01-23 12:35:31,902 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 871, 4096])
[Rank 0] 2026-01-23 12:35:32,072 - podcast_processing.episode_processor - INFO - Combined 12 chunks into final output shape: torch.Size([29746, 4096])
[Rank 0] 2026-01-23 12:35:33,734 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Arts Council England_Digital R&D for the Arts Forum distributing content discussion/features_assignment_1.npy
[Rank 0] 2026-01-23 12:35:33,735 - podcast_processing.episode_processor - INFO -   Saved features: 29746 frames
[Rank 0] 2026-01-23 12:35:33,735 - podcast_processing.label_generator - DEBUG - Processing 0 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:35:33,800 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Arts Council England_Digital R&D for the Arts Forum distributing content discussion/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:35:33,816 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 0/29746 positive
[Rank 0] 2026-01-23 12:35:33,858 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Arts Council England_Digital R&D for the Arts Forum distributing content discussion/metadata_shift_1.json
[Rank 0] 2026-01-23 12:35:33,858 - podcast_processing.episode_processor - INFO - Completed episode: Arts Council England_Digital R&D for the Arts Forum distributing content discussion
[Rank 0] 2026-01-23 12:35:33,926 - podcast_processing.distributed_orchestrator - INFO - âœ“ Arts Council England_Digital R&D for the Arts Forum distributing content discussion
[Rank 0] 2026-01-23 12:35:33,975 - podcast_processing.episode_processor - INFO - Processing episode: Bear and Bear Cub Family Gaming_Episode 17_The One Where No Man's Sky Is Finally Out!
[Rank 0] 2026-01-23 12:35:34,013 - podcast_processing.label_generator - DEBUG - Loaded 42 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Bear and Bear Cub Family Gaming_Episode 17_The One Where No Man's Sky Is Finally Out!.json
[Rank 0] 2026-01-23 12:35:34,017 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_02 (longer), SPEAKER_00 (shorter)
[Rank 0] 2026-01-23 12:35:34,301 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [477.94, 477.94], using fallback
[Rank 0] 2026-01-23 12:35:34,526 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [921.72, 922.02], using fallback
[Rank 0] 2026-01-23 12:35:34,981 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1863.21, 1863.80], using fallback
[Rank 0] 2026-01-23 12:35:35,401 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2295.10, 2295.46], using fallback
[Rank 0] 2026-01-23 12:35:35,502 - podcast_processing.alignment_merger - INFO - Created 6551 word alignments
[Rank 0] 2026-01-23 12:35:36,062 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_02: torch.Size([1, 60952248]), SPEAKER_00: torch.Size([1, 60952248])
[Rank 0] 2026-01-23 12:35:36,062 - podcast_processing.episode_processor - INFO - Episode duration: 2539.68s
[Rank 0] 2026-01-23 12:35:36,063 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:35:36,082 - podcast_processing.audio_masking - DEBUG - Creating mask from 22 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:35:36,111 - podcast_processing.audio_masking - DEBUG - Mask covers 175926/60952248 samples (0.29%)
[Rank 0] 2026-01-23 12:35:36,140 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 175926/60952248 samples masked
[Rank 0] 2026-01-23 12:35:36,783 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 175926/60952248 samples zeroed
[Rank 0] 2026-01-23 12:35:36,783 - podcast_processing.episode_processor - INFO - Audio is 2539.7s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:35:36,783 - podcast_processing.episode_processor - INFO - Processing 2539.7s audio in 13 chunks of 210s each
[Rank 0] 2026-01-23 12:35:36,784 - podcast_processing.episode_processor - INFO -   Processing chunk 1/13 (210.0s)
[Rank 0] 2026-01-23 12:35:36,818 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 44641/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:36,947 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:36,948 - podcast_processing.episode_processor - DEBUG - System speaker has 144 words
[Rank 0] 2026-01-23 12:35:36,994 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:36,994 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:36,994 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:36,995 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:37,023 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:37,109 - podcast_processing.episode_processor - INFO -   Processing chunk 2/13 (210.0s)
[Rank 0] 2026-01-23 12:35:37,143 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 24480/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:37,240 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:37,241 - podcast_processing.episode_processor - DEBUG - System speaker has 172 words
[Rank 0] 2026-01-23 12:35:37,287 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:37,287 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:37,288 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:37,288 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:37,315 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:37,399 - podcast_processing.episode_processor - INFO -   Processing chunk 3/13 (210.0s)
[Rank 0] 2026-01-23 12:35:37,434 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:37,515 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:37,515 - podcast_processing.episode_processor - DEBUG - System speaker has 100 words
[Rank 0] 2026-01-23 12:35:37,562 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:37,562 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:37,562 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:37,563 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:37,590 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:37,674 - podcast_processing.episode_processor - INFO -   Processing chunk 4/13 (210.0s)
[Rank 0] 2026-01-23 12:35:37,708 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:37,796 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:37,796 - podcast_processing.episode_processor - DEBUG - System speaker has 118 words
[Rank 0] 2026-01-23 12:35:37,843 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:37,843 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:37,843 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:37,843 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:37,871 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:37,954 - podcast_processing.episode_processor - INFO -   Processing chunk 5/13 (210.0s)
[Rank 0] 2026-01-23 12:35:37,988 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20640/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:38,094 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:38,095 - podcast_processing.episode_processor - DEBUG - System speaker has 143 words
[Rank 0] 2026-01-23 12:35:38,141 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:38,141 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:38,141 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:38,142 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:38,169 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:38,280 - podcast_processing.episode_processor - INFO -   Processing chunk 6/13 (210.0s)
[Rank 0] 2026-01-23 12:35:38,774 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11521/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:38,856 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:38,856 - podcast_processing.episode_processor - DEBUG - System speaker has 195 words
[Rank 0] 2026-01-23 12:35:38,903 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:38,903 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:38,903 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:38,904 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:38,931 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:39,028 - podcast_processing.episode_processor - INFO -   Processing chunk 7/13 (210.0s)
[Rank 0] 2026-01-23 12:35:39,067 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:39,164 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:39,164 - podcast_processing.episode_processor - DEBUG - System speaker has 362 words
[Rank 0] 2026-01-23 12:35:39,211 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:39,211 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:39,211 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:39,211 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:39,239 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:39,330 - podcast_processing.episode_processor - INFO -   Processing chunk 8/13 (210.0s)
[Rank 0] 2026-01-23 12:35:39,365 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 22079/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:39,452 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:39,452 - podcast_processing.episode_processor - DEBUG - System speaker has 138 words
[Rank 0] 2026-01-23 12:35:39,498 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:39,499 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:39,499 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:39,499 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:39,528 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:39,610 - podcast_processing.episode_processor - INFO -   Processing chunk 9/13 (210.0s)
[Rank 0] 2026-01-23 12:35:39,645 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 36003/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:39,727 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:39,727 - podcast_processing.episode_processor - DEBUG - System speaker has 126 words
[Rank 0] 2026-01-23 12:35:39,774 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:39,774 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:39,774 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:39,775 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:39,802 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:39,885 - podcast_processing.episode_processor - INFO -   Processing chunk 10/13 (210.0s)
[Rank 0] 2026-01-23 12:35:39,932 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7680/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:40,016 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:40,016 - podcast_processing.episode_processor - DEBUG - System speaker has 176 words
[Rank 0] 2026-01-23 12:35:40,062 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:40,062 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:40,062 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:40,063 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:40,090 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:40,180 - podcast_processing.episode_processor - INFO -   Processing chunk 11/13 (210.0s)
[Rank 0] 2026-01-23 12:35:40,227 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:40,310 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:40,310 - podcast_processing.episode_processor - DEBUG - System speaker has 145 words
[Rank 0] 2026-01-23 12:35:40,357 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:40,357 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:40,357 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:40,358 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:40,385 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:40,491 - podcast_processing.episode_processor - INFO -   Processing chunk 12/13 (210.0s)
[Rank 0] 2026-01-23 12:35:40,538 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 8882/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:40,620 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:40,621 - podcast_processing.episode_processor - DEBUG - System speaker has 84 words
[Rank 0] 2026-01-23 12:35:40,667 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:40,667 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:40,667 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:40,668 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:40,695 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:40,797 - podcast_processing.episode_processor - INFO -   Processing chunk 13/13 (19.7s)
[Rank 0] 2026-01-23 12:35:40,802 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/472248 samples zeroed
[Rank 0] 2026-01-23 12:35:40,853 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 246]), System codes shape: torch.Size([1, 8, 246])
[Rank 0] 2026-01-23 12:35:40,853 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:40,853 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 246])
[Rank 0] 2026-01-23 12:35:40,853 - podcast_processing.episode_processor - DEBUG - Padded to max_t=246
[Rank 0] 2026-01-23 12:35:40,853 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 246]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:40,854 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 247])
[Rank 0] 2026-01-23 12:35:40,892 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 246, 4096])
[Rank 0] 2026-01-23 12:35:41,044 - podcast_processing.episode_processor - INFO - Combined 13 chunks into final output shape: torch.Size([31746, 4096])
[Rank 0] 2026-01-23 12:35:42,451 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 17_The One Where No Man's Sky Is Finally Out!/features_assignment_0.npy
[Rank 0] 2026-01-23 12:35:42,451 - podcast_processing.episode_processor - INFO -   Saved features: 31746 frames
[Rank 0] 2026-01-23 12:35:42,451 - podcast_processing.label_generator - DEBUG - Processing 20 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:35:42,821 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 17_The One Where No Man's Sky Is Finally Out!/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:35:42,821 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 78/31746 positive
[Rank 0] 2026-01-23 12:35:42,821 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:35:42,829 - podcast_processing.audio_masking - DEBUG - Creating mask from 20 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:35:42,900 - podcast_processing.audio_masking - DEBUG - Mask covers 145922/60952248 samples (0.24%)
[Rank 0] 2026-01-23 12:35:42,931 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 145922/60952248 samples masked
[Rank 0] 2026-01-23 12:35:43,580 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 145922/60952248 samples zeroed
[Rank 0] 2026-01-23 12:35:43,580 - podcast_processing.episode_processor - INFO - Audio is 2539.7s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:35:43,581 - podcast_processing.episode_processor - INFO - Processing 2539.7s audio in 13 chunks of 210s each
[Rank 0] 2026-01-23 12:35:43,581 - podcast_processing.episode_processor - INFO -   Processing chunk 1/13 (210.0s)
[Rank 0] 2026-01-23 12:35:43,615 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3839/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:43,697 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:43,697 - podcast_processing.episode_processor - DEBUG - System speaker has 310 words
[Rank 0] 2026-01-23 12:35:43,744 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:43,744 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:43,744 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:43,745 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:43,772 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:43,868 - podcast_processing.episode_processor - INFO -   Processing chunk 2/13 (210.0s)
[Rank 0] 2026-01-23 12:35:43,903 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20640/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:43,985 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:43,986 - podcast_processing.episode_processor - DEBUG - System speaker has 415 words
[Rank 0] 2026-01-23 12:35:44,032 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:44,032 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:44,033 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:44,033 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:44,060 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:44,184 - podcast_processing.episode_processor - INFO -   Processing chunk 3/13 (210.0s)
[Rank 0] 2026-01-23 12:35:44,218 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11521/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:44,317 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:44,317 - podcast_processing.episode_processor - DEBUG - System speaker has 459 words
[Rank 0] 2026-01-23 12:35:44,364 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:44,364 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:44,364 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:44,365 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:44,392 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:44,484 - podcast_processing.episode_processor - INFO -   Processing chunk 4/13 (210.0s)
[Rank 0] 2026-01-23 12:35:44,519 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 33840/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:44,600 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:44,601 - podcast_processing.episode_processor - DEBUG - System speaker has 506 words
[Rank 0] 2026-01-23 12:35:44,647 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:44,647 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:44,647 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:44,648 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:44,675 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:44,765 - podcast_processing.episode_processor - INFO -   Processing chunk 5/13 (210.0s)
[Rank 0] 2026-01-23 12:35:44,800 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:44,915 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:44,915 - podcast_processing.episode_processor - DEBUG - System speaker has 418 words
[Rank 0] 2026-01-23 12:35:44,961 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:44,962 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:44,962 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:44,962 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:44,989 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:45,073 - podcast_processing.episode_processor - INFO -   Processing chunk 6/13 (210.0s)
[Rank 0] 2026-01-23 12:35:45,108 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 25440/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:45,190 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:45,190 - podcast_processing.episode_processor - DEBUG - System speaker has 344 words
[Rank 0] 2026-01-23 12:35:45,237 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:45,628 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:45,628 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:45,628 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:45,655 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:45,761 - podcast_processing.episode_processor - INFO -   Processing chunk 7/13 (210.0s)
[Rank 0] 2026-01-23 12:35:45,798 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:45,939 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:45,939 - podcast_processing.episode_processor - DEBUG - System speaker has 86 words
[Rank 0] 2026-01-23 12:35:45,985 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:45,985 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:45,986 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:45,986 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:46,013 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:46,097 - podcast_processing.episode_processor - INFO -   Processing chunk 8/13 (210.0s)
[Rank 0] 2026-01-23 12:35:46,132 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 10322/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:46,214 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:46,214 - podcast_processing.episode_processor - DEBUG - System speaker has 437 words
[Rank 0] 2026-01-23 12:35:46,261 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:46,261 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:46,261 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:46,262 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:46,289 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:46,372 - podcast_processing.episode_processor - INFO -   Processing chunk 9/13 (210.0s)
[Rank 0] 2026-01-23 12:35:46,407 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 22800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:46,495 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:46,495 - podcast_processing.episode_processor - DEBUG - System speaker has 432 words
[Rank 0] 2026-01-23 12:35:46,542 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:46,542 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:46,543 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:46,543 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:46,570 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:46,669 - podcast_processing.episode_processor - INFO -   Processing chunk 10/13 (210.0s)
[Rank 0] 2026-01-23 12:35:46,704 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12720/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:46,785 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:46,785 - podcast_processing.episode_processor - DEBUG - System speaker has 358 words
[Rank 0] 2026-01-23 12:35:46,832 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:46,832 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:46,832 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:46,833 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:46,860 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:46,942 - podcast_processing.episode_processor - INFO -   Processing chunk 11/13 (210.0s)
[Rank 0] 2026-01-23 12:35:46,989 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:47,070 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:47,070 - podcast_processing.episode_processor - DEBUG - System speaker has 430 words
[Rank 0] 2026-01-23 12:35:47,117 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:47,117 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:47,117 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:47,118 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:47,145 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:47,228 - podcast_processing.episode_processor - INFO -   Processing chunk 12/13 (210.0s)
[Rank 0] 2026-01-23 12:35:47,275 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:47,357 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:47,357 - podcast_processing.episode_processor - DEBUG - System speaker has 392 words
[Rank 0] 2026-01-23 12:35:47,404 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:47,404 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:47,404 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:47,404 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:47,432 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:47,525 - podcast_processing.episode_processor - INFO -   Processing chunk 13/13 (19.7s)
[Rank 0] 2026-01-23 12:35:47,529 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/472248 samples zeroed
[Rank 0] 2026-01-23 12:35:47,552 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 246]), System codes shape: torch.Size([1, 8, 246])
[Rank 0] 2026-01-23 12:35:47,552 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:35:47,552 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 246])
[Rank 0] 2026-01-23 12:35:47,552 - podcast_processing.episode_processor - DEBUG - Padded to max_t=246
[Rank 0] 2026-01-23 12:35:47,552 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 246]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:47,553 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 247])
[Rank 0] 2026-01-23 12:35:47,579 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 246, 4096])
[Rank 0] 2026-01-23 12:35:47,733 - podcast_processing.episode_processor - INFO - Combined 13 chunks into final output shape: torch.Size([31746, 4096])
[Rank 0] 2026-01-23 12:35:50,212 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 17_The One Where No Man's Sky Is Finally Out!/features_assignment_1.npy
[Rank 0] 2026-01-23 12:35:50,334 - podcast_processing.episode_processor - INFO -   Saved features: 31746 frames
[Rank 0] 2026-01-23 12:35:50,347 - podcast_processing.label_generator - DEBUG - Processing 22 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:35:50,387 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 17_The One Where No Man's Sky Is Finally Out!/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:35:50,387 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 91/31746 positive
[Rank 0] 2026-01-23 12:35:50,412 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 17_The One Where No Man's Sky Is Finally Out!/metadata_shift_1.json
[Rank 0] 2026-01-23 12:35:50,412 - podcast_processing.episode_processor - INFO - Completed episode: Bear and Bear Cub Family Gaming_Episode 17_The One Where No Man's Sky Is Finally Out!
[Rank 0] 2026-01-23 12:35:50,482 - podcast_processing.distributed_orchestrator - INFO - âœ“ Bear and Bear Cub Family Gaming_Episode 17_The One Where No Man's Sky Is Finally Out!
[Rank 0] 2026-01-23 12:35:50,575 - podcast_processing.episode_processor - INFO - Processing episode: Bear and Bear Cub Family Gaming_Episode 20_The One Where We're All VR Geeked
[Rank 0] 2026-01-23 12:35:50,605 - podcast_processing.label_generator - DEBUG - Loaded 156 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Bear and Bear Cub Family Gaming_Episode 20_The One Where We're All VR Geeked.json
[Rank 0] 2026-01-23 12:35:50,609 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_02 (longer), SPEAKER_00 (shorter)
[Rank 0] 2026-01-23 12:35:51,076 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [686.76, 686.96], using fallback
[Rank 0] 2026-01-23 12:35:51,089 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [713.92, 714.33], using fallback
[Rank 0] 2026-01-23 12:35:51,134 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [792.55, 792.55], using fallback
[Rank 0] 2026-01-23 12:35:51,347 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1118.10, 1118.12], using fallback
[Rank 0] 2026-01-23 12:35:51,465 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1310.92, 1310.97], using fallback
[Rank 0] 2026-01-23 12:35:51,576 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1493.00, 1493.00], using fallback
[Rank 0] 2026-01-23 12:35:51,697 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1674.43, 1674.48], using fallback
[Rank 0] 2026-01-23 12:35:51,952 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2085.86, 2086.02], using fallback
[Rank 0] 2026-01-23 12:35:52,053 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2254.63, 2255.13], using fallback
[Rank 0] 2026-01-23 12:35:52,296 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2773.42, 2773.42], using fallback
[Rank 0] 2026-01-23 12:35:52,484 - podcast_processing.alignment_merger - INFO - Created 7443 word alignments
[Rank 0] 2026-01-23 12:35:53,112 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_02: torch.Size([1, 67332488]), SPEAKER_00: torch.Size([1, 67332488])
[Rank 0] 2026-01-23 12:35:53,112 - podcast_processing.episode_processor - INFO - Episode duration: 2805.52s
[Rank 0] 2026-01-23 12:35:53,112 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:35:53,118 - podcast_processing.audio_masking - DEBUG - Creating mask from 78 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:35:53,151 - podcast_processing.audio_masking - DEBUG - Mask covers 619688/67332488 samples (0.92%)
[Rank 0] 2026-01-23 12:35:53,183 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 619688/67332488 samples masked
[Rank 0] 2026-01-23 12:35:53,895 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 619688/67332488 samples zeroed
[Rank 0] 2026-01-23 12:35:53,895 - podcast_processing.episode_processor - INFO - Audio is 2805.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:35:53,895 - podcast_processing.episode_processor - INFO - Processing 2805.5s audio in 14 chunks of 210s each
[Rank 0] 2026-01-23 12:35:53,895 - podcast_processing.episode_processor - INFO -   Processing chunk 1/14 (210.0s)
[Rank 0] 2026-01-23 12:35:53,930 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 39840/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:54,012 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:54,012 - podcast_processing.episode_processor - DEBUG - System speaker has 113 words
[Rank 0] 2026-01-23 12:35:54,059 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:54,059 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:54,059 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:54,060 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:54,087 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:54,182 - podcast_processing.episode_processor - INFO -   Processing chunk 2/14 (210.0s)
[Rank 0] 2026-01-23 12:35:54,216 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 71281/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:54,299 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:54,299 - podcast_processing.episode_processor - DEBUG - System speaker has 294 words
[Rank 0] 2026-01-23 12:35:54,346 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:54,346 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:54,346 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:54,347 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:54,373 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:54,477 - podcast_processing.episode_processor - INFO -   Processing chunk 3/14 (210.0s)
[Rank 0] 2026-01-23 12:35:54,511 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11520/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:54,599 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:54,599 - podcast_processing.episode_processor - DEBUG - System speaker has 113 words
[Rank 0] 2026-01-23 12:35:54,646 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:54,646 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:54,646 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:54,647 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:54,674 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:54,772 - podcast_processing.episode_processor - INFO -   Processing chunk 4/14 (210.0s)
[Rank 0] 2026-01-23 12:35:54,806 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 85438/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:54,901 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:54,901 - podcast_processing.episode_processor - DEBUG - System speaker has 79 words
[Rank 0] 2026-01-23 12:35:54,947 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:54,948 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:54,948 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:54,948 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:54,975 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:55,074 - podcast_processing.episode_processor - INFO -   Processing chunk 5/14 (210.0s)
[Rank 0] 2026-01-23 12:35:55,111 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20400/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:55,201 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:55,202 - podcast_processing.episode_processor - DEBUG - System speaker has 153 words
[Rank 0] 2026-01-23 12:35:55,248 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:55,248 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:55,248 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:55,249 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:55,276 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:55,359 - podcast_processing.episode_processor - INFO -   Processing chunk 6/14 (210.0s)
[Rank 0] 2026-01-23 12:35:55,395 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 22800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:55,529 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:55,837 - podcast_processing.episode_processor - DEBUG - System speaker has 99 words
[Rank 0] 2026-01-23 12:35:55,839 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:55,839 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:55,839 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:55,839 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:55,867 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:55,950 - podcast_processing.episode_processor - INFO -   Processing chunk 7/14 (210.0s)
[Rank 0] 2026-01-23 12:35:55,984 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 25437/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:56,084 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:56,085 - podcast_processing.episode_processor - DEBUG - System speaker has 225 words
[Rank 0] 2026-01-23 12:35:56,131 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:56,131 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:56,131 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:56,132 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:56,159 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:56,243 - podcast_processing.episode_processor - INFO -   Processing chunk 8/14 (210.0s)
[Rank 0] 2026-01-23 12:35:56,278 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:56,367 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:56,368 - podcast_processing.episode_processor - DEBUG - System speaker has 160 words
[Rank 0] 2026-01-23 12:35:56,414 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:56,414 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:56,414 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:56,415 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:56,442 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:56,525 - podcast_processing.episode_processor - INFO -   Processing chunk 9/14 (210.0s)
[Rank 0] 2026-01-23 12:35:56,560 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 117360/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:56,641 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:56,641 - podcast_processing.episode_processor - DEBUG - System speaker has 182 words
[Rank 0] 2026-01-23 12:35:56,688 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:56,688 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:56,688 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:56,689 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:56,715 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:56,810 - podcast_processing.episode_processor - INFO -   Processing chunk 10/14 (210.0s)
[Rank 0] 2026-01-23 12:35:56,846 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 25441/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:56,927 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:56,927 - podcast_processing.episode_processor - DEBUG - System speaker has 64 words
[Rank 0] 2026-01-23 12:35:56,973 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:56,973 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:56,973 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:56,974 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:57,001 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:57,084 - podcast_processing.episode_processor - INFO -   Processing chunk 11/14 (210.0s)
[Rank 0] 2026-01-23 12:35:57,136 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 21843/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:57,220 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:57,221 - podcast_processing.episode_processor - DEBUG - System speaker has 35 words
[Rank 0] 2026-01-23 12:35:57,267 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:57,267 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:57,267 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:57,268 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:57,295 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:57,378 - podcast_processing.episode_processor - INFO -   Processing chunk 12/14 (210.0s)
[Rank 0] 2026-01-23 12:35:57,425 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 61683/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:57,514 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:57,514 - podcast_processing.episode_processor - DEBUG - System speaker has 60 words
[Rank 0] 2026-01-23 12:35:57,561 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:57,561 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:57,561 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:57,562 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:57,588 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:57,682 - podcast_processing.episode_processor - INFO -   Processing chunk 13/14 (210.0s)
[Rank 0] 2026-01-23 12:35:57,728 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 62641/5040000 samples zeroed
[Rank 0] 2026-01-23 12:35:57,829 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:35:57,829 - podcast_processing.episode_processor - DEBUG - System speaker has 104 words
[Rank 0] 2026-01-23 12:35:57,876 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:35:57,876 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:35:57,876 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:57,876 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:35:57,903 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:35:58,021 - podcast_processing.episode_processor - INFO -   Processing chunk 14/14 (75.5s)
[Rank 0] 2026-01-23 12:35:58,034 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 54004/1812488 samples zeroed
[Rank 0] 2026-01-23 12:35:58,085 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 945]), System codes shape: torch.Size([1, 8, 945])
[Rank 0] 2026-01-23 12:35:58,085 - podcast_processing.episode_processor - DEBUG - System speaker has 31 words
[Rank 0] 2026-01-23 12:35:58,093 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 945])
[Rank 0] 2026-01-23 12:35:58,093 - podcast_processing.episode_processor - DEBUG - Padded to max_t=945
[Rank 0] 2026-01-23 12:35:58,093 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 945]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:35:58,093 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 946])
[Rank 0] 2026-01-23 12:35:58,125 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 945, 4096])
[Rank 0] 2026-01-23 12:35:58,299 - podcast_processing.episode_processor - INFO - Combined 14 chunks into final output shape: torch.Size([35070, 4096])
[Rank 0] 2026-01-23 12:36:00,151 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 20_The One Where We're All VR Geeked/features_assignment_0.npy
[Rank 0] 2026-01-23 12:36:00,151 - podcast_processing.episode_processor - INFO -   Saved features: 35070 frames
[Rank 0] 2026-01-23 12:36:00,158 - podcast_processing.label_generator - DEBUG - Processing 78 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:36:00,181 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 20_The One Where We're All VR Geeked/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:36:00,181 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 324/35070 positive
[Rank 0] 2026-01-23 12:36:00,187 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:36:00,195 - podcast_processing.audio_masking - DEBUG - Creating mask from 78 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:36:00,257 - podcast_processing.audio_masking - DEBUG - Mask covers 608162/67332488 samples (0.90%)
[Rank 0] 2026-01-23 12:36:00,290 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 608162/67332488 samples masked
[Rank 0] 2026-01-23 12:36:01,019 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 608162/67332488 samples zeroed
[Rank 0] 2026-01-23 12:36:01,019 - podcast_processing.episode_processor - INFO - Audio is 2805.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:36:01,019 - podcast_processing.episode_processor - INFO - Processing 2805.5s audio in 14 chunks of 210s each
[Rank 0] 2026-01-23 12:36:01,019 - podcast_processing.episode_processor - INFO -   Processing chunk 1/14 (210.0s)
[Rank 0] 2026-01-23 12:36:01,054 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 43680/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:01,136 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:01,136 - podcast_processing.episode_processor - DEBUG - System speaker has 359 words
[Rank 0] 2026-01-23 12:36:01,183 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:01,183 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:01,183 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:01,183 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:01,211 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:01,298 - podcast_processing.episode_processor - INFO -   Processing chunk 2/14 (210.0s)
[Rank 0] 2026-01-23 12:36:01,334 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:01,416 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:01,416 - podcast_processing.episode_processor - DEBUG - System speaker has 236 words
[Rank 0] 2026-01-23 12:36:01,463 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:01,463 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:01,463 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:01,463 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:01,490 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:01,585 - podcast_processing.episode_processor - INFO -   Processing chunk 3/14 (210.0s)
[Rank 0] 2026-01-23 12:36:01,620 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20881/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:01,701 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:01,701 - podcast_processing.episode_processor - DEBUG - System speaker has 524 words
[Rank 0] 2026-01-23 12:36:01,748 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:01,748 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:01,748 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:01,748 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:01,775 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:01,863 - podcast_processing.episode_processor - INFO -   Processing chunk 4/14 (210.0s)
[Rank 0] 2026-01-23 12:36:01,902 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 18240/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:01,983 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:01,983 - podcast_processing.episode_processor - DEBUG - System speaker has 480 words
[Rank 0] 2026-01-23 12:36:02,030 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:02,030 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:02,030 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:02,031 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:02,058 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:02,141 - podcast_processing.episode_processor - INFO -   Processing chunk 5/14 (210.0s)
[Rank 0] 2026-01-23 12:36:02,176 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20400/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:02,475 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:02,475 - podcast_processing.episode_processor - DEBUG - System speaker has 507 words
[Rank 0] 2026-01-23 12:36:02,520 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:02,520 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:02,520 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:02,521 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:02,550 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:02,631 - podcast_processing.episode_processor - INFO -   Processing chunk 6/14 (210.0s)
[Rank 0] 2026-01-23 12:36:02,666 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 66961/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:02,765 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:02,765 - podcast_processing.episode_processor - DEBUG - System speaker has 490 words
[Rank 0] 2026-01-23 12:36:02,811 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:02,812 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:02,812 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:02,812 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:02,839 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:02,923 - podcast_processing.episode_processor - INFO -   Processing chunk 7/14 (210.0s)
[Rank 0] 2026-01-23 12:36:02,957 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 81118/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:03,039 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:03,039 - podcast_processing.episode_processor - DEBUG - System speaker has 344 words
[Rank 0] 2026-01-23 12:36:03,086 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:03,118 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:03,118 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:03,118 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:03,145 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:03,256 - podcast_processing.episode_processor - INFO -   Processing chunk 8/14 (210.0s)
[Rank 0] 2026-01-23 12:36:03,291 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 47518/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:03,426 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:03,426 - podcast_processing.episode_processor - DEBUG - System speaker has 469 words
[Rank 0] 2026-01-23 12:36:03,473 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:03,473 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:03,473 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:03,474 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:03,501 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:03,584 - podcast_processing.episode_processor - INFO -   Processing chunk 9/14 (210.0s)
[Rank 0] 2026-01-23 12:36:03,619 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 54719/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:03,700 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:03,700 - podcast_processing.episode_processor - DEBUG - System speaker has 387 words
[Rank 0] 2026-01-23 12:36:03,746 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:03,747 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:03,747 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:03,747 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:03,774 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:03,879 - podcast_processing.episode_processor - INFO -   Processing chunk 10/14 (210.0s)
[Rank 0] 2026-01-23 12:36:03,914 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 59520/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:03,995 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:03,995 - podcast_processing.episode_processor - DEBUG - System speaker has 557 words
[Rank 0] 2026-01-23 12:36:04,042 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:04,042 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:04,042 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:04,043 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:04,070 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:04,170 - podcast_processing.episode_processor - INFO -   Processing chunk 11/14 (210.0s)
[Rank 0] 2026-01-23 12:36:04,205 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:04,285 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:04,286 - podcast_processing.episode_processor - DEBUG - System speaker has 544 words
[Rank 0] 2026-01-23 12:36:04,332 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:04,332 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:04,333 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:04,333 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:04,360 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:04,455 - podcast_processing.episode_processor - INFO -   Processing chunk 12/14 (210.0s)
[Rank 0] 2026-01-23 12:36:04,501 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 26400/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:04,582 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:04,582 - podcast_processing.episode_processor - DEBUG - System speaker has 480 words
[Rank 0] 2026-01-23 12:36:04,629 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:04,629 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:04,629 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:04,630 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:04,657 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:04,740 - podcast_processing.episode_processor - INFO -   Processing chunk 13/14 (210.0s)
[Rank 0] 2026-01-23 12:36:04,789 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 83041/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:04,870 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:04,870 - podcast_processing.episode_processor - DEBUG - System speaker has 279 words
[Rank 0] 2026-01-23 12:36:04,917 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:04,917 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:04,917 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:04,918 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:04,948 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:05,039 - podcast_processing.episode_processor - INFO -   Processing chunk 14/14 (75.5s)
[Rank 0] 2026-01-23 12:36:05,058 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 85684/1812488 samples zeroed
[Rank 0] 2026-01-23 12:36:05,094 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 945]), System codes shape: torch.Size([1, 8, 945])
[Rank 0] 2026-01-23 12:36:05,420 - podcast_processing.episode_processor - DEBUG - System speaker has 16 words
[Rank 0] 2026-01-23 12:36:05,421 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 945])
[Rank 0] 2026-01-23 12:36:05,421 - podcast_processing.episode_processor - DEBUG - Padded to max_t=945
[Rank 0] 2026-01-23 12:36:05,421 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 945]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:05,422 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 946])
[Rank 0] 2026-01-23 12:36:05,450 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 945, 4096])
[Rank 0] 2026-01-23 12:36:05,634 - podcast_processing.episode_processor - INFO - Combined 14 chunks into final output shape: torch.Size([35070, 4096])
[Rank 0] 2026-01-23 12:36:06,965 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 20_The One Where We're All VR Geeked/features_assignment_1.npy
[Rank 0] 2026-01-23 12:36:06,965 - podcast_processing.episode_processor - INFO -   Saved features: 35070 frames
[Rank 0] 2026-01-23 12:36:06,965 - podcast_processing.label_generator - DEBUG - Processing 78 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:36:07,026 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 20_The One Where We're All VR Geeked/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:36:07,026 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 323/35070 positive
[Rank 0] 2026-01-23 12:36:07,063 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 20_The One Where We're All VR Geeked/metadata_shift_1.json
[Rank 0] 2026-01-23 12:36:07,064 - podcast_processing.episode_processor - INFO - Completed episode: Bear and Bear Cub Family Gaming_Episode 20_The One Where We're All VR Geeked
[Rank 0] 2026-01-23 12:36:07,135 - podcast_processing.distributed_orchestrator - INFO - âœ“ Bear and Bear Cub Family Gaming_Episode 20_The One Where We're All VR Geeked
[Rank 0] 2026-01-23 12:36:07,151 - podcast_processing.episode_processor - INFO - Processing episode: Bear and Bear Cub Family Gaming_Episode 22_The One Where We're All About The Nintendo Switch
[Rank 0] 2026-01-23 12:36:07,622 - podcast_processing.label_generator - DEBUG - Loaded 54 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Bear and Bear Cub Family Gaming_Episode 22_The One Where We're All About The Nintendo Switch.json
[Rank 0] 2026-01-23 12:36:07,625 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_00 (longer), SPEAKER_01 (shorter)
[Rank 0] 2026-01-23 12:36:07,692 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [61.82, 62.20], using fallback
[Rank 0] 2026-01-23 12:36:07,791 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [258.84, 258.84], using fallback
[Rank 0] 2026-01-23 12:36:07,904 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [551.57, 551.73], using fallback
[Rank 0] 2026-01-23 12:36:07,945 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [646.95, 647.20], using fallback
[Rank 0] 2026-01-23 12:36:08,038 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [871.48, 871.80], using fallback
[Rank 0] 2026-01-23 12:36:08,038 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [872.19, 872.29], using fallback
[Rank 0] 2026-01-23 12:36:08,041 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [880.92, 881.07], using fallback
[Rank 0] 2026-01-23 12:36:08,121 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1077.08, 1077.45], using fallback
[Rank 0] 2026-01-23 12:36:08,612 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2274.15, 2274.15], using fallback
[Rank 0] 2026-01-23 12:36:08,667 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2440.75, 2441.22], using fallback
[Rank 0] 2026-01-23 12:36:08,705 - podcast_processing.alignment_merger - INFO - Created 6622 word alignments
[Rank 0] 2026-01-23 12:36:09,281 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_00: torch.Size([1, 62518484]), SPEAKER_01: torch.Size([1, 62518484])
[Rank 0] 2026-01-23 12:36:09,281 - podcast_processing.episode_processor - INFO - Episode duration: 2604.94s
[Rank 0] 2026-01-23 12:36:09,281 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:36:09,286 - podcast_processing.audio_masking - DEBUG - Creating mask from 29 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:36:09,316 - podcast_processing.audio_masking - DEBUG - Mask covers 217438/62518484 samples (0.35%)
[Rank 0] 2026-01-23 12:36:09,347 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 217438/62518484 samples masked
[Rank 0] 2026-01-23 12:36:10,020 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 217438/62518484 samples zeroed
[Rank 0] 2026-01-23 12:36:10,020 - podcast_processing.episode_processor - INFO - Audio is 2604.9s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:36:10,020 - podcast_processing.episode_processor - INFO - Processing 2604.9s audio in 13 chunks of 210s each
[Rank 0] 2026-01-23 12:36:10,020 - podcast_processing.episode_processor - INFO -   Processing chunk 1/13 (210.0s)
[Rank 0] 2026-01-23 12:36:10,065 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 22800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:10,186 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:10,186 - podcast_processing.episode_processor - DEBUG - System speaker has 99 words
[Rank 0] 2026-01-23 12:36:10,232 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:10,232 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:10,232 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:10,233 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:10,265 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:10,375 - podcast_processing.episode_processor - INFO -   Processing chunk 2/13 (210.0s)
[Rank 0] 2026-01-23 12:36:10,410 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16080/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:10,536 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:10,536 - podcast_processing.episode_processor - DEBUG - System speaker has 117 words
[Rank 0] 2026-01-23 12:36:10,583 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:10,583 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:10,583 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:10,583 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:10,612 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:10,701 - podcast_processing.episode_processor - INFO -   Processing chunk 3/13 (210.0s)
[Rank 0] 2026-01-23 12:36:10,748 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 23520/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:10,853 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:10,854 - podcast_processing.episode_processor - DEBUG - System speaker has 75 words
[Rank 0] 2026-01-23 12:36:10,898 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:10,898 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:10,899 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:10,899 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:10,930 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:11,010 - podcast_processing.episode_processor - INFO -   Processing chunk 4/13 (210.0s)
[Rank 0] 2026-01-23 12:36:11,052 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 18479/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:11,189 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:11,189 - podcast_processing.episode_processor - DEBUG - System speaker has 60 words
[Rank 0] 2026-01-23 12:36:11,236 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:11,236 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:11,236 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:11,236 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:11,263 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:11,347 - podcast_processing.episode_processor - INFO -   Processing chunk 5/13 (210.0s)
[Rank 0] 2026-01-23 12:36:11,392 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 10081/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:11,490 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:11,490 - podcast_processing.episode_processor - DEBUG - System speaker has 24 words
[Rank 0] 2026-01-23 12:36:11,537 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:11,537 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:11,537 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:11,537 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:11,564 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:11,646 - podcast_processing.episode_processor - INFO -   Processing chunk 6/13 (210.0s)
[Rank 0] 2026-01-23 12:36:11,686 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 14880/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:11,783 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:11,783 - podcast_processing.episode_processor - DEBUG - System speaker has 89 words
[Rank 0] 2026-01-23 12:36:11,829 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:11,830 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:11,830 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:11,830 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:11,857 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:11,940 - podcast_processing.episode_processor - INFO -   Processing chunk 7/13 (210.0s)
[Rank 0] 2026-01-23 12:36:11,975 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11519/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:12,075 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:12,075 - podcast_processing.episode_processor - DEBUG - System speaker has 56 words
[Rank 0] 2026-01-23 12:36:12,121 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:12,122 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:12,122 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:12,122 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:12,150 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:12,232 - podcast_processing.episode_processor - INFO -   Processing chunk 8/13 (210.0s)
[Rank 0] 2026-01-23 12:36:12,277 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12480/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:12,414 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:12,414 - podcast_processing.episode_processor - DEBUG - System speaker has 24 words
[Rank 0] 2026-01-23 12:36:12,461 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:12,461 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:12,461 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:12,462 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:12,489 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:12,575 - podcast_processing.episode_processor - INFO -   Processing chunk 9/13 (210.0s)
[Rank 0] 2026-01-23 12:36:12,615 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 35519/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:12,696 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:12,696 - podcast_processing.episode_processor - DEBUG - System speaker has 20 words
[Rank 0] 2026-01-23 12:36:12,743 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:12,743 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:12,743 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:12,744 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:12,770 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:12,853 - podcast_processing.episode_processor - INFO -   Processing chunk 10/13 (210.0s)
[Rank 0] 2026-01-23 12:36:12,888 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3600/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:12,969 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:12,969 - podcast_processing.episode_processor - DEBUG - System speaker has 20 words
[Rank 0] 2026-01-23 12:36:13,016 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:13,016 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:13,016 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:13,017 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:13,044 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:13,126 - podcast_processing.episode_processor - INFO -   Processing chunk 11/13 (210.0s)
[Rank 0] 2026-01-23 12:36:13,160 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 41280/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:13,241 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:13,241 - podcast_processing.episode_processor - DEBUG - System speaker has 199 words
[Rank 0] 2026-01-23 12:36:13,288 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:13,288 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:13,288 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:13,289 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:13,315 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:13,398 - podcast_processing.episode_processor - INFO -   Processing chunk 12/13 (210.0s)
[Rank 0] 2026-01-23 12:36:13,432 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7200/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:13,514 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:13,514 - podcast_processing.episode_processor - DEBUG - System speaker has 169 words
[Rank 0] 2026-01-23 12:36:13,560 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:13,560 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:13,561 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:13,561 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:13,588 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:13,694 - podcast_processing.episode_processor - INFO -   Processing chunk 13/13 (84.9s)
[Rank 0] 2026-01-23 12:36:13,710 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/2038484 samples zeroed
[Rank 0] 2026-01-23 12:36:13,762 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1062]), System codes shape: torch.Size([1, 8, 1062])
[Rank 0] 2026-01-23 12:36:13,762 - podcast_processing.episode_processor - DEBUG - System speaker has 8 words
[Rank 0] 2026-01-23 12:36:13,772 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1062])
[Rank 0] 2026-01-23 12:36:13,772 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1062
[Rank 0] 2026-01-23 12:36:13,772 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1062]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:13,773 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1063])
[Rank 0] 2026-01-23 12:36:13,807 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1062, 4096])
[Rank 0] 2026-01-23 12:36:13,992 - podcast_processing.episode_processor - INFO - Combined 13 chunks into final output shape: torch.Size([32562, 4096])
[Rank 0] 2026-01-23 12:36:15,482 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 22_The One Where We're All About The Nintendo Switch/features_assignment_0.npy
[Rank 0] 2026-01-23 12:36:15,482 - podcast_processing.episode_processor - INFO -   Saved features: 32562 frames
[Rank 0] 2026-01-23 12:36:15,482 - podcast_processing.label_generator - DEBUG - Processing 25 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:36:15,486 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 22_The One Where We're All About The Nintendo Switch/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:36:15,486 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 73/32562 positive
[Rank 0] 2026-01-23 12:36:15,486 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:36:15,508 - podcast_processing.audio_masking - DEBUG - Creating mask from 25 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:36:15,538 - podcast_processing.audio_masking - DEBUG - Mask covers 138721/62518484 samples (0.22%)
[Rank 0] 2026-01-23 12:36:15,568 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 138721/62518484 samples masked
[Rank 0] 2026-01-23 12:36:16,237 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 138721/62518484 samples zeroed
[Rank 0] 2026-01-23 12:36:16,237 - podcast_processing.episode_processor - INFO - Audio is 2604.9s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:36:16,237 - podcast_processing.episode_processor - INFO - Processing 2604.9s audio in 13 chunks of 210s each
[Rank 0] 2026-01-23 12:36:16,237 - podcast_processing.episode_processor - INFO -   Processing chunk 1/13 (210.0s)
[Rank 0] 2026-01-23 12:36:16,272 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 26160/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:16,354 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:16,354 - podcast_processing.episode_processor - DEBUG - System speaker has 390 words
[Rank 0] 2026-01-23 12:36:16,400 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:16,400 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:16,401 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:16,401 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:16,428 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:16,522 - podcast_processing.episode_processor - INFO -   Processing chunk 2/13 (210.0s)
[Rank 0] 2026-01-23 12:36:16,556 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:16,638 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:16,638 - podcast_processing.episode_processor - DEBUG - System speaker has 436 words
[Rank 0] 2026-01-23 12:36:16,685 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:16,685 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:16,685 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:16,685 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:16,713 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:16,814 - podcast_processing.episode_processor - INFO -   Processing chunk 3/13 (210.0s)
[Rank 0] 2026-01-23 12:36:16,849 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3840/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:16,941 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:16,941 - podcast_processing.episode_processor - DEBUG - System speaker has 467 words
[Rank 0] 2026-01-23 12:36:16,988 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:16,988 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:16,988 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:16,989 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:17,018 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:17,117 - podcast_processing.episode_processor - INFO -   Processing chunk 4/13 (210.0s)
[Rank 0] 2026-01-23 12:36:17,154 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:17,245 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:17,245 - podcast_processing.episode_processor - DEBUG - System speaker has 515 words
[Rank 0] 2026-01-23 12:36:17,292 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:17,292 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:17,292 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:17,292 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:17,319 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:17,414 - podcast_processing.episode_processor - INFO -   Processing chunk 5/13 (210.0s)
[Rank 0] 2026-01-23 12:36:17,451 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 46080/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:17,537 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:17,537 - podcast_processing.episode_processor - DEBUG - System speaker has 527 words
[Rank 0] 2026-01-23 12:36:17,583 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:17,583 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:17,583 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:17,584 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:17,612 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:17,696 - podcast_processing.episode_processor - INFO -   Processing chunk 6/13 (210.0s)
[Rank 0] 2026-01-23 12:36:17,730 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:17,812 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:17,812 - podcast_processing.episode_processor - DEBUG - System speaker has 498 words
[Rank 0] 2026-01-23 12:36:17,859 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:17,859 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:17,859 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:17,860 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:17,894 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:17,971 - podcast_processing.episode_processor - INFO -   Processing chunk 7/13 (210.0s)
[Rank 0] 2026-01-23 12:36:18,013 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 14400/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:18,095 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:18,095 - podcast_processing.episode_processor - DEBUG - System speaker has 508 words
[Rank 0] 2026-01-23 12:36:18,142 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:18,142 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:18,142 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:18,143 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:18,171 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:18,260 - podcast_processing.episode_processor - INFO -   Processing chunk 8/13 (210.0s)
[Rank 0] 2026-01-23 12:36:18,641 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 15120/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:18,723 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:18,723 - podcast_processing.episode_processor - DEBUG - System speaker has 479 words
[Rank 0] 2026-01-23 12:36:18,769 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:18,769 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:18,769 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:18,770 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:18,799 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:18,896 - podcast_processing.episode_processor - INFO -   Processing chunk 9/13 (210.0s)
[Rank 0] 2026-01-23 12:36:18,931 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:19,013 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:19,013 - podcast_processing.episode_processor - DEBUG - System speaker has 564 words
[Rank 0] 2026-01-23 12:36:19,060 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:19,060 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:19,060 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:19,060 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:19,088 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:19,174 - podcast_processing.episode_processor - INFO -   Processing chunk 10/13 (210.0s)
[Rank 0] 2026-01-23 12:36:19,209 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6480/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:19,294 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:19,294 - podcast_processing.episode_processor - DEBUG - System speaker has 551 words
[Rank 0] 2026-01-23 12:36:19,341 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:19,341 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:19,655 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:19,655 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:19,683 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:19,765 - podcast_processing.episode_processor - INFO -   Processing chunk 11/13 (210.0s)
[Rank 0] 2026-01-23 12:36:19,804 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:19,891 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:19,891 - podcast_processing.episode_processor - DEBUG - System speaker has 355 words
[Rank 0] 2026-01-23 12:36:19,938 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:19,938 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:19,938 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:19,938 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:19,966 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:20,049 - podcast_processing.episode_processor - INFO -   Processing chunk 12/13 (210.0s)
[Rank 0] 2026-01-23 12:36:20,084 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6721/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:20,165 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:20,165 - podcast_processing.episode_processor - DEBUG - System speaker has 297 words
[Rank 0] 2026-01-23 12:36:20,212 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:20,212 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:20,212 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:20,212 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:20,240 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:20,322 - podcast_processing.episode_processor - INFO -   Processing chunk 13/13 (84.9s)
[Rank 0] 2026-01-23 12:36:20,649 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 19920/2038484 samples zeroed
[Rank 0] 2026-01-23 12:36:20,685 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1062]), System codes shape: torch.Size([1, 8, 1062])
[Rank 0] 2026-01-23 12:36:20,685 - podcast_processing.episode_processor - DEBUG - System speaker has 65 words
[Rank 0] 2026-01-23 12:36:20,695 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1062])
[Rank 0] 2026-01-23 12:36:20,695 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1062
[Rank 0] 2026-01-23 12:36:20,695 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1062]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:20,696 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1063])
[Rank 0] 2026-01-23 12:36:20,723 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1062, 4096])
[Rank 0] 2026-01-23 12:36:20,887 - podcast_processing.episode_processor - INFO - Combined 13 chunks into final output shape: torch.Size([32562, 4096])
[Rank 0] 2026-01-23 12:36:23,174 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 22_The One Where We're All About The Nintendo Switch/features_assignment_1.npy
[Rank 0] 2026-01-23 12:36:23,175 - podcast_processing.episode_processor - INFO -   Saved features: 32562 frames
[Rank 0] 2026-01-23 12:36:23,175 - podcast_processing.label_generator - DEBUG - Processing 29 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:36:23,682 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 22_The One Where We're All About The Nintendo Switch/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:36:23,682 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 117/32562 positive
[Rank 0] 2026-01-23 12:36:23,794 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Bear and Bear Cub Family Gaming_Episode 22_The One Where We're All About The Nintendo Switch/metadata_shift_1.json
[Rank 0] 2026-01-23 12:36:23,794 - podcast_processing.episode_processor - INFO - Completed episode: Bear and Bear Cub Family Gaming_Episode 22_The One Where We're All About The Nintendo Switch
[Rank 0] 2026-01-23 12:36:23,860 - podcast_processing.distributed_orchestrator - INFO - âœ“ Bear and Bear Cub Family Gaming_Episode 22_The One Where We're All About The Nintendo Switch
[Rank 0] 2026-01-23 12:36:23,863 - podcast_processing.episode_processor - INFO - Processing episode: Borderless Podcast_What does the Trump Plan, Vacation Rentals and Bitcoin Mean for Your Taxes?
[Rank 0] 2026-01-23 12:36:23,874 - podcast_processing.label_generator - DEBUG - Loaded 12 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Borderless Podcast_What does the Trump Plan, Vacation Rentals and Bitcoin Mean for Your Taxes?.json
[Rank 0] 2026-01-23 12:36:23,875 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_00 (longer), SPEAKER_02 (shorter)
[Rank 0] 2026-01-23 12:36:24,508 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1737.55, 1737.63], using fallback
[Rank 0] 2026-01-23 12:36:24,509 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1737.64, 1737.76], using fallback
[Rank 0] 2026-01-23 12:36:24,583 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1953.17, 1953.17], using fallback
[Rank 0] 2026-01-23 12:36:24,795 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2566.70, 2566.85], using fallback
[Rank 0] 2026-01-23 12:36:25,000 - podcast_processing.alignment_merger - INFO - Created 9513 word alignments
[Rank 0] 2026-01-23 12:36:25,701 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_00: torch.Size([1, 76230048]), SPEAKER_02: torch.Size([1, 76230048])
[Rank 0] 2026-01-23 12:36:25,701 - podcast_processing.episode_processor - INFO - Episode duration: 3176.25s
[Rank 0] 2026-01-23 12:36:25,701 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:36:25,702 - podcast_processing.audio_masking - DEBUG - Creating mask from 8 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:36:25,747 - podcast_processing.audio_masking - DEBUG - Mask covers 61923/76230048 samples (0.08%)
[Rank 0] 2026-01-23 12:36:25,781 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 61923/76230048 samples masked
[Rank 0] 2026-01-23 12:36:26,586 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 61923/76230048 samples zeroed
[Rank 0] 2026-01-23 12:36:26,586 - podcast_processing.episode_processor - INFO - Audio is 3176.3s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:36:26,586 - podcast_processing.episode_processor - INFO - Processing 3176.3s audio in 16 chunks of 210s each
[Rank 0] 2026-01-23 12:36:26,586 - podcast_processing.episode_processor - INFO -   Processing chunk 1/16 (210.0s)
[Rank 0] 2026-01-23 12:36:26,621 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:26,759 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:26,759 - podcast_processing.episode_processor - DEBUG - System speaker has 338 words
[Rank 0] 2026-01-23 12:36:26,805 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:26,805 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:26,806 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:26,806 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:26,834 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:26,918 - podcast_processing.episode_processor - INFO -   Processing chunk 2/16 (210.0s)
[Rank 0] 2026-01-23 12:36:26,953 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:27,047 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:27,047 - podcast_processing.episode_processor - DEBUG - System speaker has 192 words
[Rank 0] 2026-01-23 12:36:27,094 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:27,094 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:27,094 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:27,095 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:27,122 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:27,207 - podcast_processing.episode_processor - INFO -   Processing chunk 3/16 (210.0s)
[Rank 0] 2026-01-23 12:36:27,242 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:27,324 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:27,324 - podcast_processing.episode_processor - DEBUG - System speaker has 142 words
[Rank 0] 2026-01-23 12:36:27,371 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:27,371 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:27,371 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:27,372 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:27,404 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:27,483 - podcast_processing.episode_processor - INFO -   Processing chunk 4/16 (210.0s)
[Rank 0] 2026-01-23 12:36:27,518 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:27,599 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:27,922 - podcast_processing.episode_processor - DEBUG - System speaker has 209 words
[Rank 0] 2026-01-23 12:36:27,925 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:27,925 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:27,925 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:27,926 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:27,953 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:28,035 - podcast_processing.episode_processor - INFO -   Processing chunk 5/16 (210.0s)
[Rank 0] 2026-01-23 12:36:28,070 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:28,152 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:28,152 - podcast_processing.episode_processor - DEBUG - System speaker has 256 words
[Rank 0] 2026-01-23 12:36:28,199 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:28,199 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:28,199 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:28,199 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:28,227 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:28,309 - podcast_processing.episode_processor - INFO -   Processing chunk 6/16 (210.0s)
[Rank 0] 2026-01-23 12:36:28,346 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 21602/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:28,428 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:28,428 - podcast_processing.episode_processor - DEBUG - System speaker has 219 words
[Rank 0] 2026-01-23 12:36:28,474 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:28,474 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:28,474 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:28,475 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:28,502 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:28,588 - podcast_processing.episode_processor - INFO -   Processing chunk 7/16 (210.0s)
[Rank 0] 2026-01-23 12:36:28,624 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3600/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:28,705 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:28,935 - podcast_processing.episode_processor - DEBUG - System speaker has 106 words
[Rank 0] 2026-01-23 12:36:28,937 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:28,937 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:28,937 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:28,938 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:28,968 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:29,047 - podcast_processing.episode_processor - INFO -   Processing chunk 8/16 (210.0s)
[Rank 0] 2026-01-23 12:36:29,084 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:29,204 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:29,205 - podcast_processing.episode_processor - DEBUG - System speaker has 396 words
[Rank 0] 2026-01-23 12:36:29,251 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:29,251 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:29,251 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:29,252 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:29,279 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:29,374 - podcast_processing.episode_processor - INFO -   Processing chunk 9/16 (210.0s)
[Rank 0] 2026-01-23 12:36:29,408 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:29,523 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:29,523 - podcast_processing.episode_processor - DEBUG - System speaker has 391 words
[Rank 0] 2026-01-23 12:36:29,569 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:29,569 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:29,569 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:29,570 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:29,597 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:29,715 - podcast_processing.episode_processor - INFO -   Processing chunk 10/16 (210.0s)
[Rank 0] 2026-01-23 12:36:29,750 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 19440/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:29,850 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:29,851 - podcast_processing.episode_processor - DEBUG - System speaker has 519 words
[Rank 0] 2026-01-23 12:36:29,897 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:29,897 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:29,897 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:29,898 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:29,925 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:30,025 - podcast_processing.episode_processor - INFO -   Processing chunk 11/16 (210.0s)
[Rank 0] 2026-01-23 12:36:30,061 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:30,148 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:30,148 - podcast_processing.episode_processor - DEBUG - System speaker has 127 words
[Rank 0] 2026-01-23 12:36:30,195 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:30,195 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:30,195 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:30,196 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:30,223 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:30,313 - podcast_processing.episode_processor - INFO -   Processing chunk 12/16 (210.0s)
[Rank 0] 2026-01-23 12:36:30,348 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:30,444 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:30,444 - podcast_processing.episode_processor - DEBUG - System speaker has 425 words
[Rank 0] 2026-01-23 12:36:30,491 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:30,491 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:30,491 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:30,492 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:30,519 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:30,613 - podcast_processing.episode_processor - INFO -   Processing chunk 13/16 (210.0s)
[Rank 0] 2026-01-23 12:36:30,647 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:30,731 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:30,731 - podcast_processing.episode_processor - DEBUG - System speaker has 331 words
[Rank 0] 2026-01-23 12:36:30,777 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:30,778 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:30,778 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:30,778 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:30,806 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:30,898 - podcast_processing.episode_processor - INFO -   Processing chunk 14/16 (210.0s)
[Rank 0] 2026-01-23 12:36:30,933 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 8160/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:31,017 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:31,017 - podcast_processing.episode_processor - DEBUG - System speaker has 178 words
[Rank 0] 2026-01-23 12:36:31,063 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:31,063 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:31,064 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:31,064 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:31,092 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:31,183 - podcast_processing.episode_processor - INFO -   Processing chunk 15/16 (210.0s)
[Rank 0] 2026-01-23 12:36:31,230 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 9121/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:31,312 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:31,313 - podcast_processing.episode_processor - DEBUG - System speaker has 464 words
[Rank 0] 2026-01-23 12:36:31,359 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:31,359 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:31,360 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:31,360 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:31,387 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:31,482 - podcast_processing.episode_processor - INFO -   Processing chunk 16/16 (26.3s)
[Rank 0] 2026-01-23 12:36:31,487 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/630048 samples zeroed
[Rank 0] 2026-01-23 12:36:31,535 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 329]), System codes shape: torch.Size([1, 8, 329])
[Rank 0] 2026-01-23 12:36:31,535 - podcast_processing.episode_processor - DEBUG - System speaker has 25 words
[Rank 0] 2026-01-23 12:36:31,535 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 329])
[Rank 0] 2026-01-23 12:36:31,535 - podcast_processing.episode_processor - DEBUG - Padded to max_t=329
[Rank 0] 2026-01-23 12:36:31,535 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 329]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:31,536 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 330])
[Rank 0] 2026-01-23 12:36:31,572 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 329, 4096])
[Rank 0] 2026-01-23 12:36:31,765 - podcast_processing.episode_processor - INFO - Combined 16 chunks into final output shape: torch.Size([39704, 4096])
[Rank 0] 2026-01-23 12:36:34,069 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Borderless Podcast_What does the Trump Plan, Vacation Rentals and Bitcoin Mean for Your Taxes?/features_assignment_0.npy
[Rank 0] 2026-01-23 12:36:34,070 - podcast_processing.episode_processor - INFO -   Saved features: 39704 frames
[Rank 0] 2026-01-23 12:36:34,070 - podcast_processing.label_generator - DEBUG - Processing 4 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:36:34,298 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Borderless Podcast_What does the Trump Plan, Vacation Rentals and Bitcoin Mean for Your Taxes?/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:36:34,298 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 16/39704 positive
[Rank 0] 2026-01-23 12:36:34,298 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:36:34,299 - podcast_processing.audio_masking - DEBUG - Creating mask from 4 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:36:34,399 - podcast_processing.audio_masking - DEBUG - Mask covers 29280/76230048 samples (0.04%)
[Rank 0] 2026-01-23 12:36:34,435 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 29280/76230048 samples masked
[Rank 0] 2026-01-23 12:36:35,269 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 29280/76230048 samples zeroed
[Rank 0] 2026-01-23 12:36:35,269 - podcast_processing.episode_processor - INFO - Audio is 3176.3s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:36:35,269 - podcast_processing.episode_processor - INFO - Processing 3176.3s audio in 16 chunks of 210s each
[Rank 0] 2026-01-23 12:36:35,269 - podcast_processing.episode_processor - INFO -   Processing chunk 1/16 (210.0s)
[Rank 0] 2026-01-23 12:36:35,305 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:35,388 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:35,388 - podcast_processing.episode_processor - DEBUG - System speaker has 296 words
[Rank 0] 2026-01-23 12:36:35,434 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:35,434 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:35,435 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:35,435 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:35,464 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:35,550 - podcast_processing.episode_processor - INFO -   Processing chunk 2/16 (210.0s)
[Rank 0] 2026-01-23 12:36:35,584 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:35,667 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:35,667 - podcast_processing.episode_processor - DEBUG - System speaker has 475 words
[Rank 0] 2026-01-23 12:36:35,713 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:35,714 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:35,714 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:35,714 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:35,742 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:35,825 - podcast_processing.episode_processor - INFO -   Processing chunk 3/16 (210.0s)
[Rank 0] 2026-01-23 12:36:36,106 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:36,206 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:36,206 - podcast_processing.episode_processor - DEBUG - System speaker has 438 words
[Rank 0] 2026-01-23 12:36:36,252 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:36,253 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:36,253 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:36,254 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:36,281 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:36,394 - podcast_processing.episode_processor - INFO -   Processing chunk 4/16 (210.0s)
[Rank 0] 2026-01-23 12:36:36,428 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:36,516 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:36,516 - podcast_processing.episode_processor - DEBUG - System speaker has 371 words
[Rank 0] 2026-01-23 12:36:36,562 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:36,563 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:36,563 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:36,564 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:36,591 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:36,677 - podcast_processing.episode_processor - INFO -   Processing chunk 5/16 (210.0s)
[Rank 0] 2026-01-23 12:36:36,712 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:36,794 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:36,794 - podcast_processing.episode_processor - DEBUG - System speaker has 378 words
[Rank 0] 2026-01-23 12:36:36,840 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:36,840 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:36,841 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:36,841 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:36,868 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:36,952 - podcast_processing.episode_processor - INFO -   Processing chunk 6/16 (210.0s)
[Rank 0] 2026-01-23 12:36:36,987 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 9838/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:37,083 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:37,083 - podcast_processing.episode_processor - DEBUG - System speaker has 421 words
[Rank 0] 2026-01-23 12:36:37,129 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:37,130 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:37,130 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:37,130 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:37,157 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:37,241 - podcast_processing.episode_processor - INFO -   Processing chunk 7/16 (210.0s)
[Rank 0] 2026-01-23 12:36:37,279 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 14640/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:37,360 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:37,360 - podcast_processing.episode_processor - DEBUG - System speaker has 537 words
[Rank 0] 2026-01-23 12:36:37,407 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:37,407 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:37,408 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:37,408 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:37,435 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:37,519 - podcast_processing.episode_processor - INFO -   Processing chunk 8/16 (210.0s)
[Rank 0] 2026-01-23 12:36:37,554 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:37,636 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:37,636 - podcast_processing.episode_processor - DEBUG - System speaker has 237 words
[Rank 0] 2026-01-23 12:36:37,683 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:37,683 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:37,683 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:37,684 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:37,711 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:37,796 - podcast_processing.episode_processor - INFO -   Processing chunk 9/16 (210.0s)
[Rank 0] 2026-01-23 12:36:37,831 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:37,914 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:37,914 - podcast_processing.episode_processor - DEBUG - System speaker has 293 words
[Rank 0] 2026-01-23 12:36:37,961 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:37,961 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:37,961 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:37,962 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:37,989 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:38,076 - podcast_processing.episode_processor - INFO -   Processing chunk 10/16 (210.0s)
[Rank 0] 2026-01-23 12:36:38,112 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:38,194 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:38,194 - podcast_processing.episode_processor - DEBUG - System speaker has 110 words
[Rank 0] 2026-01-23 12:36:38,241 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:38,241 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:38,241 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:38,242 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:38,270 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:38,659 - podcast_processing.episode_processor - INFO -   Processing chunk 11/16 (210.0s)
[Rank 0] 2026-01-23 12:36:38,707 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:38,789 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:38,789 - podcast_processing.episode_processor - DEBUG - System speaker has 487 words
[Rank 0] 2026-01-23 12:36:38,835 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:38,835 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:38,836 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:38,837 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:38,865 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:38,948 - podcast_processing.episode_processor - INFO -   Processing chunk 12/16 (210.0s)
[Rank 0] 2026-01-23 12:36:38,983 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:39,065 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:39,065 - podcast_processing.episode_processor - DEBUG - System speaker has 201 words
[Rank 0] 2026-01-23 12:36:39,111 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:39,112 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:39,112 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:39,112 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:39,140 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:39,223 - podcast_processing.episode_processor - INFO -   Processing chunk 13/16 (210.0s)
[Rank 0] 2026-01-23 12:36:39,258 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:39,360 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:39,360 - podcast_processing.episode_processor - DEBUG - System speaker has 286 words
[Rank 0] 2026-01-23 12:36:39,407 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:39,407 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:39,407 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:39,408 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:39,435 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:39,528 - podcast_processing.episode_processor - INFO -   Processing chunk 14/16 (210.0s)
[Rank 0] 2026-01-23 12:36:39,575 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:39,675 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:39,675 - podcast_processing.episode_processor - DEBUG - System speaker has 440 words
[Rank 0] 2026-01-23 12:36:39,721 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:39,721 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:39,722 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:39,722 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:39,750 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:39,852 - podcast_processing.episode_processor - INFO -   Processing chunk 15/16 (210.0s)
[Rank 0] 2026-01-23 12:36:39,900 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4802/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:39,990 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:39,990 - podcast_processing.episode_processor - DEBUG - System speaker has 166 words
[Rank 0] 2026-01-23 12:36:40,036 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:40,036 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:40,036 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:40,037 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:40,065 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:40,158 - podcast_processing.episode_processor - INFO -   Processing chunk 16/16 (26.3s)
[Rank 0] 2026-01-23 12:36:40,164 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/630048 samples zeroed
[Rank 0] 2026-01-23 12:36:40,187 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 329]), System codes shape: torch.Size([1, 8, 329])
[Rank 0] 2026-01-23 12:36:40,187 - podcast_processing.episode_processor - DEBUG - System speaker has 6 words
[Rank 0] 2026-01-23 12:36:40,187 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 329])
[Rank 0] 2026-01-23 12:36:40,187 - podcast_processing.episode_processor - DEBUG - Padded to max_t=329
[Rank 0] 2026-01-23 12:36:40,187 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 329]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:40,188 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 330])
[Rank 0] 2026-01-23 12:36:40,215 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 329, 4096])
[Rank 0] 2026-01-23 12:36:40,405 - podcast_processing.episode_processor - INFO - Combined 16 chunks into final output shape: torch.Size([39704, 4096])
[Rank 0] 2026-01-23 12:36:43,514 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Borderless Podcast_What does the Trump Plan, Vacation Rentals and Bitcoin Mean for Your Taxes?/features_assignment_1.npy
[Rank 0] 2026-01-23 12:36:43,514 - podcast_processing.episode_processor - INFO -   Saved features: 39704 frames
[Rank 0] 2026-01-23 12:36:43,514 - podcast_processing.label_generator - DEBUG - Processing 8 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:36:43,543 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Borderless Podcast_What does the Trump Plan, Vacation Rentals and Bitcoin Mean for Your Taxes?/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:36:43,543 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 31/39704 positive
[Rank 0] 2026-01-23 12:36:43,557 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Borderless Podcast_What does the Trump Plan, Vacation Rentals and Bitcoin Mean for Your Taxes?/metadata_shift_1.json
[Rank 0] 2026-01-23 12:36:43,557 - podcast_processing.episode_processor - INFO - Completed episode: Borderless Podcast_What does the Trump Plan, Vacation Rentals and Bitcoin Mean for Your Taxes?
[Rank 0] 2026-01-23 12:36:43,625 - podcast_processing.distributed_orchestrator - INFO - âœ“ Borderless Podcast_What does the Trump Plan, Vacation Rentals and Bitcoin Mean for Your Taxes?
[Rank 0] 2026-01-23 12:36:43,661 - podcast_processing.episode_processor - INFO - Processing episode: Conexiones TheLearningSciences_Five Pillars of the Mind Redesigning Education to Suit the Brain
[Rank 0] 2026-01-23 12:36:43,697 - podcast_processing.label_generator - DEBUG - Loaded 46 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Conexiones TheLearningSciences_Five Pillars of the Mind Redesigning Education to Suit the Brain.json
[Rank 0] 2026-01-23 12:36:43,700 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_03 (longer), SPEAKER_02 (shorter)
[Rank 0] 2026-01-23 12:36:44,273 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1582.80, 1582.89], using fallback
[Rank 0] 2026-01-23 12:36:44,333 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1777.99, 1777.99], using fallback
[Rank 0] 2026-01-23 12:36:44,419 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2060.69, 2060.82], using fallback
[Rank 0] 2026-01-23 12:36:44,515 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2352.71, 2353.07], using fallback
[Rank 0] 2026-01-23 12:36:44,864 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3432.52, 3432.61], using fallback
[Rank 0] 2026-01-23 12:36:44,986 - podcast_processing.alignment_merger - INFO - Created 10441 word alignments
[Rank 0] 2026-01-23 12:36:45,872 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_03: torch.Size([1, 94194616]), SPEAKER_02: torch.Size([1, 94194616])
[Rank 0] 2026-01-23 12:36:45,873 - podcast_processing.episode_processor - INFO - Episode duration: 3924.78s
[Rank 0] 2026-01-23 12:36:45,873 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:36:45,873 - podcast_processing.audio_masking - DEBUG - Creating mask from 10 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:36:45,932 - podcast_processing.audio_masking - DEBUG - Mask covers 80639/94194616 samples (0.09%)
[Rank 0] 2026-01-23 12:36:45,982 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 80639/94194616 samples masked
[Rank 0] 2026-01-23 12:36:47,007 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 80639/94194616 samples zeroed
[Rank 0] 2026-01-23 12:36:47,007 - podcast_processing.episode_processor - INFO - Audio is 3924.8s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:36:47,007 - podcast_processing.episode_processor - INFO - Processing 3924.8s audio in 19 chunks of 210s each
[Rank 0] 2026-01-23 12:36:47,014 - podcast_processing.episode_processor - INFO -   Processing chunk 1/19 (210.0s)
[Rank 0] 2026-01-23 12:36:47,049 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:47,142 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:47,142 - podcast_processing.episode_processor - DEBUG - System speaker has 347 words
[Rank 0] 2026-01-23 12:36:47,188 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:47,188 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:47,188 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:47,189 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:47,217 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:47,312 - podcast_processing.episode_processor - INFO -   Processing chunk 2/19 (210.0s)
[Rank 0] 2026-01-23 12:36:47,347 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:47,448 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:47,448 - podcast_processing.episode_processor - DEBUG - System speaker has 46 words
[Rank 0] 2026-01-23 12:36:47,495 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:47,495 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:47,495 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:47,496 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:47,523 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:47,613 - podcast_processing.episode_processor - INFO -   Processing chunk 3/19 (210.0s)
[Rank 0] 2026-01-23 12:36:47,649 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 25201/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:47,743 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:47,743 - podcast_processing.episode_processor - DEBUG - System speaker has 95 words
[Rank 0] 2026-01-23 12:36:47,789 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:47,789 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:47,789 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:47,790 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:47,817 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:47,921 - podcast_processing.episode_processor - INFO -   Processing chunk 4/19 (210.0s)
[Rank 0] 2026-01-23 12:36:47,958 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 43438/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:48,054 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:48,054 - podcast_processing.episode_processor - DEBUG - System speaker has 110 words
[Rank 0] 2026-01-23 12:36:48,101 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:48,101 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:48,101 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:48,101 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:48,129 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:48,221 - podcast_processing.episode_processor - INFO -   Processing chunk 5/19 (210.0s)
[Rank 0] 2026-01-23 12:36:48,256 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:48,349 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:48,349 - podcast_processing.episode_processor - DEBUG - System speaker has 8 words
[Rank 0] 2026-01-23 12:36:48,396 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:48,396 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:48,396 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:48,397 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:48,424 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:48,527 - podcast_processing.episode_processor - INFO -   Processing chunk 6/19 (210.0s)
[Rank 0] 2026-01-23 12:36:48,561 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:48,654 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:48,654 - podcast_processing.episode_processor - DEBUG - System speaker has 56 words
[Rank 0] 2026-01-23 12:36:48,700 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:48,701 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:48,701 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:48,701 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:48,729 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:48,830 - podcast_processing.episode_processor - INFO -   Processing chunk 7/19 (210.0s)
[Rank 0] 2026-01-23 12:36:48,864 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:48,947 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:48,947 - podcast_processing.episode_processor - DEBUG - System speaker has 37 words
[Rank 0] 2026-01-23 12:36:48,993 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:48,993 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:48,993 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:48,994 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:49,025 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:49,105 - podcast_processing.episode_processor - INFO -   Processing chunk 8/19 (210.0s)
[Rank 0] 2026-01-23 12:36:49,142 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:49,249 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:49,249 - podcast_processing.episode_processor - DEBUG - System speaker has 34 words
[Rank 0] 2026-01-23 12:36:49,295 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:49,295 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:49,295 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:49,296 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:49,330 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:49,407 - podcast_processing.episode_processor - INFO -   Processing chunk 9/19 (210.0s)
[Rank 0] 2026-01-23 12:36:49,444 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:49,546 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:49,546 - podcast_processing.episode_processor - DEBUG - System speaker has 77 words
[Rank 0] 2026-01-23 12:36:49,591 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:49,592 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:49,592 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:49,592 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:49,620 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:49,704 - podcast_processing.episode_processor - INFO -   Processing chunk 10/19 (210.0s)
[Rank 0] 2026-01-23 12:36:49,741 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:49,831 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:49,832 - podcast_processing.episode_processor - DEBUG - System speaker has 36 words
[Rank 0] 2026-01-23 12:36:49,878 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:49,878 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:49,878 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:49,878 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:49,910 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:49,990 - podcast_processing.episode_processor - INFO -   Processing chunk 11/19 (210.0s)
[Rank 0] 2026-01-23 12:36:50,027 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:50,110 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:50,110 - podcast_processing.episode_processor - DEBUG - System speaker has 23 words
[Rank 0] 2026-01-23 12:36:50,156 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:50,156 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:50,157 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:50,157 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:50,185 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:50,269 - podcast_processing.episode_processor - INFO -   Processing chunk 12/19 (210.0s)
[Rank 0] 2026-01-23 12:36:50,307 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:50,389 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:50,389 - podcast_processing.episode_processor - DEBUG - System speaker has 55 words
[Rank 0] 2026-01-23 12:36:50,436 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:50,436 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:50,436 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:50,437 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:50,464 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:50,548 - podcast_processing.episode_processor - INFO -   Processing chunk 13/19 (210.0s)
[Rank 0] 2026-01-23 12:36:50,583 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7440/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:50,665 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:50,666 - podcast_processing.episode_processor - DEBUG - System speaker has 76 words
[Rank 0] 2026-01-23 12:36:50,712 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:50,712 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:50,712 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:50,712 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:50,740 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:50,823 - podcast_processing.episode_processor - INFO -   Processing chunk 14/19 (210.0s)
[Rank 0] 2026-01-23 12:36:50,858 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:50,940 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:50,940 - podcast_processing.episode_processor - DEBUG - System speaker has 9 words
[Rank 0] 2026-01-23 12:36:50,987 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:50,987 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:50,987 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:50,987 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:51,015 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:51,098 - podcast_processing.episode_processor - INFO -   Processing chunk 15/19 (210.0s)
[Rank 0] 2026-01-23 12:36:51,227 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:51,309 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:51,309 - podcast_processing.episode_processor - DEBUG - System speaker has 36 words
[Rank 0] 2026-01-23 12:36:51,356 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:51,356 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:51,356 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:51,356 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:51,384 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:51,467 - podcast_processing.episode_processor - INFO -   Processing chunk 16/19 (210.0s)
[Rank 0] 2026-01-23 12:36:51,514 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:51,596 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:51,596 - podcast_processing.episode_processor - DEBUG - System speaker has 1 words
[Rank 0] 2026-01-23 12:36:51,642 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:51,643 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:51,643 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:51,643 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:51,670 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:51,765 - podcast_processing.episode_processor - INFO -   Processing chunk 17/19 (210.0s)
[Rank 0] 2026-01-23 12:36:51,811 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:51,894 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:51,894 - podcast_processing.episode_processor - DEBUG - System speaker has 63 words
[Rank 0] 2026-01-23 12:36:51,940 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:51,941 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:51,941 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:51,941 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:51,969 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:52,063 - podcast_processing.episode_processor - INFO -   Processing chunk 18/19 (210.0s)
[Rank 0] 2026-01-23 12:36:52,109 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:52,192 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:52,192 - podcast_processing.episode_processor - DEBUG - System speaker has 71 words
[Rank 0] 2026-01-23 12:36:52,239 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:52,239 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:52,239 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:52,239 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:52,267 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:52,361 - podcast_processing.episode_processor - INFO -   Processing chunk 19/19 (144.8s)
[Rank 0] 2026-01-23 12:36:52,398 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/3474616 samples zeroed
[Rank 0] 2026-01-23 12:36:52,465 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1810]), System codes shape: torch.Size([1, 8, 1810])
[Rank 0] 2026-01-23 12:36:52,898 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:36:52,899 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1810])
[Rank 0] 2026-01-23 12:36:52,899 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1810
[Rank 0] 2026-01-23 12:36:52,899 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1810]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:52,899 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1811])
[Rank 0] 2026-01-23 12:36:52,928 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1810, 4096])
[Rank 0] 2026-01-23 12:36:53,221 - podcast_processing.episode_processor - INFO - Combined 19 chunks into final output shape: torch.Size([49060, 4096])
[Rank 0] 2026-01-23 12:36:55,249 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Conexiones TheLearningSciences_Five Pillars of the Mind Redesigning Education to Suit the Brain/features_assignment_0.npy
[Rank 0] 2026-01-23 12:36:55,249 - podcast_processing.episode_processor - INFO -   Saved features: 49060 frames
[Rank 0] 2026-01-23 12:36:55,250 - podcast_processing.label_generator - DEBUG - Processing 36 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:36:55,253 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Conexiones TheLearningSciences_Five Pillars of the Mind Redesigning Education to Suit the Brain/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:36:55,253 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 170/49060 positive
[Rank 0] 2026-01-23 12:36:55,254 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:36:55,254 - podcast_processing.audio_masking - DEBUG - Creating mask from 36 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:36:55,314 - podcast_processing.audio_masking - DEBUG - Mask covers 327599/94194616 samples (0.35%)
[Rank 0] 2026-01-23 12:36:55,358 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 327599/94194616 samples masked
[Rank 0] 2026-01-23 12:36:56,361 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 327599/94194616 samples zeroed
[Rank 0] 2026-01-23 12:36:56,362 - podcast_processing.episode_processor - INFO - Audio is 3924.8s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:36:56,362 - podcast_processing.episode_processor - INFO - Processing 3924.8s audio in 19 chunks of 210s each
[Rank 0] 2026-01-23 12:36:56,362 - podcast_processing.episode_processor - INFO -   Processing chunk 1/19 (210.0s)
[Rank 0] 2026-01-23 12:36:56,397 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 35519/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:56,479 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:56,480 - podcast_processing.episode_processor - DEBUG - System speaker has 157 words
[Rank 0] 2026-01-23 12:36:56,526 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:56,526 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:56,526 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:56,526 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:56,554 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:56,646 - podcast_processing.episode_processor - INFO -   Processing chunk 2/19 (210.0s)
[Rank 0] 2026-01-23 12:36:56,681 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 37679/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:56,763 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:56,763 - podcast_processing.episode_processor - DEBUG - System speaker has 514 words
[Rank 0] 2026-01-23 12:36:56,810 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:56,810 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:56,810 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:56,811 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:56,838 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:56,929 - podcast_processing.episode_processor - INFO -   Processing chunk 3/19 (210.0s)
[Rank 0] 2026-01-23 12:36:56,964 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 32161/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:57,046 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:57,046 - podcast_processing.episode_processor - DEBUG - System speaker has 527 words
[Rank 0] 2026-01-23 12:36:57,093 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:57,093 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:57,093 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:57,093 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:57,120 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:57,204 - podcast_processing.episode_processor - INFO -   Processing chunk 4/19 (210.0s)
[Rank 0] 2026-01-23 12:36:57,244 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:57,351 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:57,351 - podcast_processing.episode_processor - DEBUG - System speaker has 517 words
[Rank 0] 2026-01-23 12:36:57,398 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:57,398 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:57,398 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:57,399 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:57,426 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:57,530 - podcast_processing.episode_processor - INFO -   Processing chunk 5/19 (210.0s)
[Rank 0] 2026-01-23 12:36:57,566 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:57,653 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:57,654 - podcast_processing.episode_processor - DEBUG - System speaker has 570 words
[Rank 0] 2026-01-23 12:36:57,700 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:57,701 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:57,701 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:57,702 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:57,729 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:57,850 - podcast_processing.episode_processor - INFO -   Processing chunk 6/19 (210.0s)
[Rank 0] 2026-01-23 12:36:57,894 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 28081/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:57,983 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:57,983 - podcast_processing.episode_processor - DEBUG - System speaker has 459 words
[Rank 0] 2026-01-23 12:36:58,029 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:58,030 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:58,030 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:58,030 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:58,058 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:58,150 - podcast_processing.episode_processor - INFO -   Processing chunk 7/19 (210.0s)
[Rank 0] 2026-01-23 12:36:58,185 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:58,267 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:58,267 - podcast_processing.episode_processor - DEBUG - System speaker has 559 words
[Rank 0] 2026-01-23 12:36:58,314 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:58,582 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:58,582 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:58,583 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:58,624 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:58,713 - podcast_processing.episode_processor - INFO -   Processing chunk 8/19 (210.0s)
[Rank 0] 2026-01-23 12:36:58,759 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 32161/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:58,858 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:58,858 - podcast_processing.episode_processor - DEBUG - System speaker has 527 words
[Rank 0] 2026-01-23 12:36:58,904 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:58,905 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:58,905 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:58,905 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:58,933 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:59,029 - podcast_processing.episode_processor - INFO -   Processing chunk 9/19 (210.0s)
[Rank 0] 2026-01-23 12:36:59,069 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 21840/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:59,157 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:59,157 - podcast_processing.episode_processor - DEBUG - System speaker has 457 words
[Rank 0] 2026-01-23 12:36:59,203 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:59,203 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:59,203 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:59,204 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:59,232 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:59,322 - podcast_processing.episode_processor - INFO -   Processing chunk 10/19 (210.0s)
[Rank 0] 2026-01-23 12:36:59,357 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:36:59,451 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:36:59,452 - podcast_processing.episode_processor - DEBUG - System speaker has 510 words
[Rank 0] 2026-01-23 12:36:59,498 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:36:59,498 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:36:59,498 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:36:59,499 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:36:59,526 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:36:59,620 - podcast_processing.episode_processor - INFO -   Processing chunk 11/19 (210.0s)
[Rank 0] 2026-01-23 12:37:00,156 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 9363/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:00,238 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:00,239 - podcast_processing.episode_processor - DEBUG - System speaker has 587 words
[Rank 0] 2026-01-23 12:37:00,285 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:00,286 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:00,286 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:00,286 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:00,314 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:00,638 - podcast_processing.episode_processor - INFO -   Processing chunk 12/19 (210.0s)
[Rank 0] 2026-01-23 12:37:00,702 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4326/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:00,797 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:00,798 - podcast_processing.episode_processor - DEBUG - System speaker has 485 words
[Rank 0] 2026-01-23 12:37:00,844 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:00,844 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:00,844 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:00,845 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:00,872 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:00,983 - podcast_processing.episode_processor - INFO -   Processing chunk 13/19 (210.0s)
[Rank 0] 2026-01-23 12:37:01,018 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 15122/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:01,103 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:01,104 - podcast_processing.episode_processor - DEBUG - System speaker has 536 words
[Rank 0] 2026-01-23 12:37:01,150 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:01,150 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:01,151 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:01,151 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:01,179 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:01,277 - podcast_processing.episode_processor - INFO -   Processing chunk 14/19 (210.0s)
[Rank 0] 2026-01-23 12:37:01,325 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 9359/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:01,415 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:01,415 - podcast_processing.episode_processor - DEBUG - System speaker has 619 words
[Rank 0] 2026-01-23 12:37:01,460 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:01,460 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:01,460 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:01,461 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:01,494 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:01,580 - podcast_processing.episode_processor - INFO -   Processing chunk 15/19 (210.0s)
[Rank 0] 2026-01-23 12:37:01,626 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:01,708 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:01,708 - podcast_processing.episode_processor - DEBUG - System speaker has 483 words
[Rank 0] 2026-01-23 12:37:01,755 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:01,755 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:01,755 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:01,756 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:01,783 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:01,866 - podcast_processing.episode_processor - INFO -   Processing chunk 16/19 (210.0s)
[Rank 0] 2026-01-23 12:37:01,912 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 24473/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:01,997 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:01,997 - podcast_processing.episode_processor - DEBUG - System speaker has 591 words
[Rank 0] 2026-01-23 12:37:02,044 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:02,044 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:02,044 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:02,045 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:02,072 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:02,166 - podcast_processing.episode_processor - INFO -   Processing chunk 17/19 (210.0s)
[Rank 0] 2026-01-23 12:37:02,212 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 35522/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:02,294 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:02,294 - podcast_processing.episode_processor - DEBUG - System speaker has 534 words
[Rank 0] 2026-01-23 12:37:02,340 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:02,340 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:02,341 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:02,341 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:02,368 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:02,476 - podcast_processing.episode_processor - INFO -   Processing chunk 18/19 (210.0s)
[Rank 0] 2026-01-23 12:37:02,523 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 41993/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:02,604 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:02,812 - podcast_processing.episode_processor - DEBUG - System speaker has 444 words
[Rank 0] 2026-01-23 12:37:02,817 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:02,817 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:02,817 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:02,817 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:02,847 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:02,937 - podcast_processing.episode_processor - INFO -   Processing chunk 19/19 (144.8s)
[Rank 0] 2026-01-23 12:37:03,502 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/3474616 samples zeroed
[Rank 0] 2026-01-23 12:37:03,559 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1810]), System codes shape: torch.Size([1, 8, 1810])
[Rank 0] 2026-01-23 12:37:03,559 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:03,585 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1810])
[Rank 0] 2026-01-23 12:37:03,585 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1810
[Rank 0] 2026-01-23 12:37:03,585 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1810]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:03,585 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1811])
[Rank 0] 2026-01-23 12:37:03,612 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1810, 4096])
[Rank 0] 2026-01-23 12:37:03,924 - podcast_processing.episode_processor - INFO - Combined 19 chunks into final output shape: torch.Size([49060, 4096])
[Rank 0] 2026-01-23 12:37:06,212 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Conexiones TheLearningSciences_Five Pillars of the Mind Redesigning Education to Suit the Brain/features_assignment_1.npy
[Rank 0] 2026-01-23 12:37:06,212 - podcast_processing.episode_processor - INFO -   Saved features: 49060 frames
[Rank 0] 2026-01-23 12:37:06,212 - podcast_processing.label_generator - DEBUG - Processing 10 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:37:06,235 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Conexiones TheLearningSciences_Five Pillars of the Mind Redesigning Education to Suit the Brain/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:37:06,235 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 44/49060 positive
[Rank 0] 2026-01-23 12:37:06,256 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Conexiones TheLearningSciences_Five Pillars of the Mind Redesigning Education to Suit the Brain/metadata_shift_1.json
[Rank 0] 2026-01-23 12:37:06,256 - podcast_processing.episode_processor - INFO - Completed episode: Conexiones TheLearningSciences_Five Pillars of the Mind Redesigning Education to Suit the Brain
[Rank 0] 2026-01-23 12:37:06,333 - podcast_processing.distributed_orchestrator - INFO - âœ“ Conexiones TheLearningSciences_Five Pillars of the Mind Redesigning Education to Suit the Brain
[Rank 0] 2026-01-23 12:37:06,363 - podcast_processing.episode_processor - INFO - Processing episode: Dickens Olewe_Panel at Global Defence of Media Freedom conference in London
[Rank 0] 2026-01-23 12:37:06,382 - podcast_processing.label_generator - DEBUG - Loaded 1 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Dickens Olewe_Panel at Global Defence of Media Freedom conference in London.json
[Rank 0] 2026-01-23 12:37:06,382 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_03 (longer), SPEAKER_01 (shorter)
[Rank 0] 2026-01-23 12:37:06,568 - podcast_processing.alignment_merger - INFO - Created 6286 word alignments
[Rank 0] 2026-01-23 12:37:07,135 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_03: torch.Size([1, 57791352]), SPEAKER_01: torch.Size([1, 57791352])
[Rank 0] 2026-01-23 12:37:07,757 - podcast_processing.episode_processor - INFO - Episode duration: 2407.97s
[Rank 0] 2026-01-23 12:37:07,758 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:37:07,763 - podcast_processing.audio_masking - DEBUG - No laughter events found for SPEAKER_01
[Rank 0] 2026-01-23 12:37:07,763 - podcast_processing.episode_processor - INFO - Audio is 2408.0s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:37:07,763 - podcast_processing.episode_processor - INFO - Processing 2408.0s audio in 12 chunks of 210s each
[Rank 0] 2026-01-23 12:37:07,763 - podcast_processing.episode_processor - INFO -   Processing chunk 1/12 (210.0s)
[Rank 0] 2026-01-23 12:37:07,868 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:07,868 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:07,914 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:07,914 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:07,914 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:07,914 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:07,942 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:08,027 - podcast_processing.episode_processor - INFO -   Processing chunk 2/12 (210.0s)
[Rank 0] 2026-01-23 12:37:08,137 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:08,137 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:08,183 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:08,183 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:08,184 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:08,184 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:08,212 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:08,295 - podcast_processing.episode_processor - INFO -   Processing chunk 3/12 (210.0s)
[Rank 0] 2026-01-23 12:37:08,378 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:08,378 - podcast_processing.episode_processor - DEBUG - System speaker has 447 words
[Rank 0] 2026-01-23 12:37:08,425 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:08,425 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:08,425 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:08,425 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:08,453 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:08,536 - podcast_processing.episode_processor - INFO -   Processing chunk 4/12 (210.0s)
[Rank 0] 2026-01-23 12:37:08,621 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:08,621 - podcast_processing.episode_processor - DEBUG - System speaker has 67 words
[Rank 0] 2026-01-23 12:37:08,667 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:08,667 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:08,667 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:08,668 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:08,697 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:08,791 - podcast_processing.episode_processor - INFO -   Processing chunk 5/12 (210.0s)
[Rank 0] 2026-01-23 12:37:08,875 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:09,164 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:09,165 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:09,165 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:09,165 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:09,166 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:09,193 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:09,280 - podcast_processing.episode_processor - INFO -   Processing chunk 6/12 (210.0s)
[Rank 0] 2026-01-23 12:37:09,403 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:09,404 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:09,450 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:09,450 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:09,451 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:09,451 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:09,478 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:09,577 - podcast_processing.episode_processor - INFO -   Processing chunk 7/12 (210.0s)
[Rank 0] 2026-01-23 12:37:09,694 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:09,694 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:09,740 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:09,740 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:09,740 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:09,740 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:09,772 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:09,872 - podcast_processing.episode_processor - INFO -   Processing chunk 8/12 (210.0s)
[Rank 0] 2026-01-23 12:37:09,988 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:09,988 - podcast_processing.episode_processor - DEBUG - System speaker has 380 words
[Rank 0] 2026-01-23 12:37:10,035 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:10,195 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:10,195 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:10,195 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:10,223 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:10,346 - podcast_processing.episode_processor - INFO -   Processing chunk 9/12 (210.0s)
[Rank 0] 2026-01-23 12:37:10,446 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:10,446 - podcast_processing.episode_processor - DEBUG - System speaker has 105 words
[Rank 0] 2026-01-23 12:37:10,492 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:10,492 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:10,493 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:10,493 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:10,521 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:10,642 - podcast_processing.episode_processor - INFO -   Processing chunk 10/12 (210.0s)
[Rank 0] 2026-01-23 12:37:10,771 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:10,772 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:10,818 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:10,818 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:10,818 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:10,819 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:10,846 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:10,940 - podcast_processing.episode_processor - INFO -   Processing chunk 11/12 (210.0s)
[Rank 0] 2026-01-23 12:37:11,104 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:11,105 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:11,151 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:11,151 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:11,151 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:11,152 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:11,179 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:11,269 - podcast_processing.episode_processor - INFO -   Processing chunk 12/12 (98.0s)
[Rank 0] 2026-01-23 12:37:11,325 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1225]), System codes shape: torch.Size([1, 8, 1225])
[Rank 0] 2026-01-23 12:37:11,326 - podcast_processing.episode_processor - DEBUG - System speaker has 168 words
[Rank 0] 2026-01-23 12:37:11,339 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1225])
[Rank 0] 2026-01-23 12:37:11,339 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1225
[Rank 0] 2026-01-23 12:37:11,339 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1225]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:11,340 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1226])
[Rank 0] 2026-01-23 12:37:11,371 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1225, 4096])
[Rank 0] 2026-01-23 12:37:11,544 - podcast_processing.episode_processor - INFO - Combined 12 chunks into final output shape: torch.Size([30100, 4096])
[Rank 0] 2026-01-23 12:37:15,019 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Dickens Olewe_Panel at Global Defence of Media Freedom conference in London/features_assignment_0.npy
[Rank 0] 2026-01-23 12:37:15,019 - podcast_processing.episode_processor - INFO -   Saved features: 30100 frames
[Rank 0] 2026-01-23 12:37:15,020 - podcast_processing.label_generator - DEBUG - Processing 1 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:37:15,081 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Dickens Olewe_Panel at Global Defence of Media Freedom conference in London/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:37:15,081 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 2/30100 positive
[Rank 0] 2026-01-23 12:37:15,081 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:37:15,095 - podcast_processing.audio_masking - DEBUG - Creating mask from 1 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:37:15,147 - podcast_processing.audio_masking - DEBUG - Mask covers 3600/57791352 samples (0.01%)
[Rank 0] 2026-01-23 12:37:15,175 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 3600/57791352 samples masked
[Rank 0] 2026-01-23 12:37:15,800 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3600/57791352 samples zeroed
[Rank 0] 2026-01-23 12:37:15,800 - podcast_processing.episode_processor - INFO - Audio is 2408.0s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:37:15,800 - podcast_processing.episode_processor - INFO - Processing 2408.0s audio in 12 chunks of 210s each
[Rank 0] 2026-01-23 12:37:15,806 - podcast_processing.episode_processor - INFO -   Processing chunk 1/12 (210.0s)
[Rank 0] 2026-01-23 12:37:15,848 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:15,930 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:15,931 - podcast_processing.episode_processor - DEBUG - System speaker has 502 words
[Rank 0] 2026-01-23 12:37:15,977 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:15,977 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:15,977 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:15,978 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:16,005 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:16,129 - podcast_processing.episode_processor - INFO -   Processing chunk 2/12 (210.0s)
[Rank 0] 2026-01-23 12:37:16,163 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:16,246 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:16,246 - podcast_processing.episode_processor - DEBUG - System speaker has 473 words
[Rank 0] 2026-01-23 12:37:16,292 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:16,292 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:16,293 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:16,293 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:16,321 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:16,417 - podcast_processing.episode_processor - INFO -   Processing chunk 3/12 (210.0s)
[Rank 0] 2026-01-23 12:37:16,456 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:16,587 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:16,587 - podcast_processing.episode_processor - DEBUG - System speaker has 95 words
[Rank 0] 2026-01-23 12:37:16,634 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:16,634 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:16,635 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:16,635 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:16,663 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:16,802 - podcast_processing.episode_processor - INFO -   Processing chunk 4/12 (210.0s)
[Rank 0] 2026-01-23 12:37:16,842 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:16,959 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:16,959 - podcast_processing.episode_processor - DEBUG - System speaker has 72 words
[Rank 0] 2026-01-23 12:37:17,006 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:17,006 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:17,006 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:17,007 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:17,034 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:17,149 - podcast_processing.episode_processor - INFO -   Processing chunk 5/12 (210.0s)
[Rank 0] 2026-01-23 12:37:17,184 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:17,315 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:17,315 - podcast_processing.episode_processor - DEBUG - System speaker has 370 words
[Rank 0] 2026-01-23 12:37:17,362 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:17,362 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:17,362 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:17,363 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:17,390 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:17,475 - podcast_processing.episode_processor - INFO -   Processing chunk 6/12 (210.0s)
[Rank 0] 2026-01-23 12:37:17,515 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:17,647 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:17,647 - podcast_processing.episode_processor - DEBUG - System speaker has 580 words
[Rank 0] 2026-01-23 12:37:17,694 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:17,694 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:17,694 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:17,695 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:17,722 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:17,830 - podcast_processing.episode_processor - INFO -   Processing chunk 7/12 (210.0s)
[Rank 0] 2026-01-23 12:37:17,864 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:17,972 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:17,972 - podcast_processing.episode_processor - DEBUG - System speaker has 606 words
[Rank 0] 2026-01-23 12:37:18,019 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:18,019 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:18,019 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:18,020 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:18,047 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:18,133 - podcast_processing.episode_processor - INFO -   Processing chunk 8/12 (210.0s)
[Rank 0] 2026-01-23 12:37:18,173 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:18,310 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:18,310 - podcast_processing.episode_processor - DEBUG - System speaker has 207 words
[Rank 0] 2026-01-23 12:37:18,357 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:18,357 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:18,357 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:18,357 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:18,385 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:18,469 - podcast_processing.episode_processor - INFO -   Processing chunk 9/12 (210.0s)
[Rank 0] 2026-01-23 12:37:18,721 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:18,803 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:18,803 - podcast_processing.episode_processor - DEBUG - System speaker has 33 words
[Rank 0] 2026-01-23 12:37:18,849 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:18,850 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:18,850 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:18,850 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:18,878 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:18,962 - podcast_processing.episode_processor - INFO -   Processing chunk 10/12 (210.0s)
[Rank 0] 2026-01-23 12:37:18,997 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:19,092 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:19,092 - podcast_processing.episode_processor - DEBUG - System speaker has 506 words
[Rank 0] 2026-01-23 12:37:19,139 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:19,139 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:19,139 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:19,140 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:19,171 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:19,270 - podcast_processing.episode_processor - INFO -   Processing chunk 11/12 (210.0s)
[Rank 0] 2026-01-23 12:37:19,315 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3600/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:19,402 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:19,402 - podcast_processing.episode_processor - DEBUG - System speaker has 442 words
[Rank 0] 2026-01-23 12:37:19,449 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:19,449 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:19,449 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:19,449 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:19,477 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:19,566 - podcast_processing.episode_processor - INFO -   Processing chunk 12/12 (98.0s)
[Rank 0] 2026-01-23 12:37:19,584 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/2351352 samples zeroed
[Rank 0] 2026-01-23 12:37:19,627 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1225]), System codes shape: torch.Size([1, 8, 1225])
[Rank 0] 2026-01-23 12:37:19,627 - podcast_processing.episode_processor - DEBUG - System speaker has 109 words
[Rank 0] 2026-01-23 12:37:19,640 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1225])
[Rank 0] 2026-01-23 12:37:19,640 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1225
[Rank 0] 2026-01-23 12:37:19,640 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1225]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:19,640 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1226])
[Rank 0] 2026-01-23 12:37:19,668 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1225, 4096])
[Rank 0] 2026-01-23 12:37:19,832 - podcast_processing.episode_processor - INFO - Combined 12 chunks into final output shape: torch.Size([30100, 4096])
[Rank 0] 2026-01-23 12:37:22,130 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Dickens Olewe_Panel at Global Defence of Media Freedom conference in London/features_assignment_1.npy
[Rank 0] 2026-01-23 12:37:22,130 - podcast_processing.episode_processor - INFO -   Saved features: 30100 frames
[Rank 0] 2026-01-23 12:37:22,145 - podcast_processing.label_generator - DEBUG - Processing 0 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:37:22,191 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Dickens Olewe_Panel at Global Defence of Media Freedom conference in London/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:37:22,192 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 0/30100 positive
[Rank 0] 2026-01-23 12:37:22,217 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Dickens Olewe_Panel at Global Defence of Media Freedom conference in London/metadata_shift_1.json
[Rank 0] 2026-01-23 12:37:22,217 - podcast_processing.episode_processor - INFO - Completed episode: Dickens Olewe_Panel at Global Defence of Media Freedom conference in London
[Rank 0] 2026-01-23 12:37:22,279 - podcast_processing.distributed_orchestrator - INFO - âœ“ Dickens Olewe_Panel at Global Defence of Media Freedom conference in London
[Rank 0] 2026-01-23 12:37:22,316 - podcast_processing.episode_processor - INFO - Processing episode: E2M Interview_From 2 Employees to 100 in 4 years!
[Rank 0] 2026-01-23 12:37:22,344 - podcast_processing.label_generator - DEBUG - Loaded 13 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/E2M Interview_From 2 Employees to 100 in 4 years!.json
[Rank 0] 2026-01-23 12:37:22,345 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_01 (longer), SPEAKER_03 (shorter)
[Rank 0] 2026-01-23 12:37:22,373 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [6.02, 6.30], using fallback
[Rank 0] 2026-01-23 12:37:22,374 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [8.52, 8.85], using fallback
[Rank 0] 2026-01-23 12:37:22,387 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [27.76, 28.09], using fallback
[Rank 0] 2026-01-23 12:37:22,388 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [28.09, 28.18], using fallback
[Rank 0] 2026-01-23 12:37:22,388 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [28.18, 28.54], using fallback
[Rank 0] 2026-01-23 12:37:22,388 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [28.54, 28.75], using fallback
[Rank 0] 2026-01-23 12:37:22,389 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [29.23, 29.41], using fallback
[Rank 0] 2026-01-23 12:37:22,389 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [29.41, 29.56], using fallback
[Rank 0] 2026-01-23 12:37:22,389 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [29.56, 30.10], using fallback
[Rank 0] 2026-01-23 12:37:22,613 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [943.04, 943.33], using fallback
[Rank 0] 2026-01-23 12:37:22,619 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [970.93, 971.06], using fallback
[Rank 0] 2026-01-23 12:37:22,620 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [976.22, 976.32], using fallback
[Rank 0] 2026-01-23 12:37:22,665 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1204.35, 1204.46], using fallback
[Rank 0] 2026-01-23 12:37:22,839 - podcast_processing.alignment_merger - INFO - Created 5160 word alignments
[Rank 0] 2026-01-23 12:37:23,436 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_01: torch.Size([1, 47665528]), SPEAKER_03: torch.Size([1, 47665528])
[Rank 0] 2026-01-23 12:37:23,436 - podcast_processing.episode_processor - INFO - Episode duration: 1986.06s
[Rank 0] 2026-01-23 12:37:23,436 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:37:23,440 - podcast_processing.audio_masking - DEBUG - Creating mask from 11 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:37:23,463 - podcast_processing.audio_masking - DEBUG - Mask covers 140882/47665528 samples (0.30%)
[Rank 0] 2026-01-23 12:37:23,486 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 140882/47665528 samples masked
[Rank 0] 2026-01-23 12:37:24,003 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 140882/47665528 samples zeroed
[Rank 0] 2026-01-23 12:37:24,003 - podcast_processing.episode_processor - INFO - Audio is 1986.1s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:37:24,003 - podcast_processing.episode_processor - INFO - Processing 1986.1s audio in 10 chunks of 210s each
[Rank 0] 2026-01-23 12:37:24,003 - podcast_processing.episode_processor - INFO -   Processing chunk 1/10 (210.0s)
[Rank 0] 2026-01-23 12:37:24,038 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:24,135 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:24,135 - podcast_processing.episode_processor - DEBUG - System speaker has 157 words
[Rank 0] 2026-01-23 12:37:24,181 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:24,368 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:24,368 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:24,368 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:24,397 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:24,492 - podcast_processing.episode_processor - INFO -   Processing chunk 2/10 (210.0s)
[Rank 0] 2026-01-23 12:37:24,528 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 22800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:24,616 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:24,617 - podcast_processing.episode_processor - DEBUG - System speaker has 106 words
[Rank 0] 2026-01-23 12:37:24,663 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:24,663 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:24,664 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:24,664 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:24,692 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:24,785 - podcast_processing.episode_processor - INFO -   Processing chunk 3/10 (210.0s)
[Rank 0] 2026-01-23 12:37:24,820 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 43681/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:24,905 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:24,905 - podcast_processing.episode_processor - DEBUG - System speaker has 285 words
[Rank 0] 2026-01-23 12:37:24,951 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:24,951 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:24,952 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:24,952 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:24,980 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:25,063 - podcast_processing.episode_processor - INFO -   Processing chunk 4/10 (210.0s)
[Rank 0] 2026-01-23 12:37:25,098 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 19442/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:25,186 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:25,186 - podcast_processing.episode_processor - DEBUG - System speaker has 266 words
[Rank 0] 2026-01-23 12:37:25,233 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:25,233 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:25,233 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:25,234 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:25,261 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:25,344 - podcast_processing.episode_processor - INFO -   Processing chunk 5/10 (210.0s)
[Rank 0] 2026-01-23 12:37:25,379 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 8640/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:25,494 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:25,494 - podcast_processing.episode_processor - DEBUG - System speaker has 274 words
[Rank 0] 2026-01-23 12:37:25,540 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:25,540 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:25,541 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:25,541 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:25,569 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:25,651 - podcast_processing.episode_processor - INFO -   Processing chunk 6/10 (210.0s)
[Rank 0] 2026-01-23 12:37:25,686 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 10560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:25,795 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:25,795 - podcast_processing.episode_processor - DEBUG - System speaker has 143 words
[Rank 0] 2026-01-23 12:37:25,842 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:25,842 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:25,842 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:25,843 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:25,870 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:25,951 - podcast_processing.episode_processor - INFO -   Processing chunk 7/10 (210.0s)
[Rank 0] 2026-01-23 12:37:25,986 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:26,067 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:26,068 - podcast_processing.episode_processor - DEBUG - System speaker has 226 words
[Rank 0] 2026-01-23 12:37:26,114 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:26,114 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:26,114 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:26,115 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:26,143 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:26,550 - podcast_processing.episode_processor - INFO -   Processing chunk 8/10 (210.0s)
[Rank 0] 2026-01-23 12:37:26,586 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 15839/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:26,668 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:26,668 - podcast_processing.episode_processor - DEBUG - System speaker has 270 words
[Rank 0] 2026-01-23 12:37:26,714 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:26,714 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:26,714 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:26,714 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:26,742 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:26,834 - podcast_processing.episode_processor - INFO -   Processing chunk 9/10 (210.0s)
[Rank 0] 2026-01-23 12:37:26,869 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 19920/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:26,951 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:27,013 - podcast_processing.episode_processor - DEBUG - System speaker has 272 words
[Rank 0] 2026-01-23 12:37:27,016 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:27,016 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:27,016 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:27,017 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:27,044 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:27,126 - podcast_processing.episode_processor - INFO -   Processing chunk 10/10 (96.1s)
[Rank 0] 2026-01-23 12:37:27,142 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/2305528 samples zeroed
[Rank 0] 2026-01-23 12:37:27,196 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1201]), System codes shape: torch.Size([1, 8, 1201])
[Rank 0] 2026-01-23 12:37:27,196 - podcast_processing.episode_processor - DEBUG - System speaker has 117 words
[Rank 0] 2026-01-23 12:37:27,208 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1201])
[Rank 0] 2026-01-23 12:37:27,208 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1201
[Rank 0] 2026-01-23 12:37:27,208 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1201]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:27,209 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1202])
[Rank 0] 2026-01-23 12:37:27,239 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1201, 4096])
[Rank 0] 2026-01-23 12:37:27,379 - podcast_processing.episode_processor - INFO - Combined 10 chunks into final output shape: torch.Size([24826, 4096])
[Rank 0] 2026-01-23 12:37:28,840 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/E2M Interview_From 2 Employees to 100 in 4 years!/features_assignment_0.npy
[Rank 0] 2026-01-23 12:37:28,840 - podcast_processing.episode_processor - INFO -   Saved features: 24826 frames
[Rank 0] 2026-01-23 12:37:28,841 - podcast_processing.label_generator - DEBUG - Processing 2 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:37:28,856 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/E2M Interview_From 2 Employees to 100 in 4 years!/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:37:28,860 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 18/24826 positive
[Rank 0] 2026-01-23 12:37:28,861 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:37:28,869 - podcast_processing.audio_masking - DEBUG - Creating mask from 2 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:37:28,917 - podcast_processing.audio_masking - DEBUG - Mask covers 35760/47665528 samples (0.08%)
[Rank 0] 2026-01-23 12:37:28,944 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 35760/47665528 samples masked
[Rank 0] 2026-01-23 12:37:29,456 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 35760/47665528 samples zeroed
[Rank 0] 2026-01-23 12:37:29,456 - podcast_processing.episode_processor - INFO - Audio is 1986.1s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:37:29,456 - podcast_processing.episode_processor - INFO - Processing 1986.1s audio in 10 chunks of 210s each
[Rank 0] 2026-01-23 12:37:29,456 - podcast_processing.episode_processor - INFO -   Processing chunk 1/10 (210.0s)
[Rank 0] 2026-01-23 12:37:29,491 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:29,574 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:29,574 - podcast_processing.episode_processor - DEBUG - System speaker has 275 words
[Rank 0] 2026-01-23 12:37:29,620 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:29,620 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:29,620 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:29,621 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:29,649 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:29,738 - podcast_processing.episode_processor - INFO -   Processing chunk 2/10 (210.0s)
[Rank 0] 2026-01-23 12:37:29,773 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:29,868 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:29,868 - podcast_processing.episode_processor - DEBUG - System speaker has 452 words
[Rank 0] 2026-01-23 12:37:29,914 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:29,915 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:29,915 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:29,915 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:29,943 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:30,026 - podcast_processing.episode_processor - INFO -   Processing chunk 3/10 (210.0s)
[Rank 0] 2026-01-23 12:37:30,061 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:30,159 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:30,159 - podcast_processing.episode_processor - DEBUG - System speaker has 288 words
[Rank 0] 2026-01-23 12:37:30,205 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:30,573 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:30,574 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:30,574 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:30,602 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:30,698 - podcast_processing.episode_processor - INFO -   Processing chunk 4/10 (210.0s)
[Rank 0] 2026-01-23 12:37:30,735 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 35760/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:30,816 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:30,817 - podcast_processing.episode_processor - DEBUG - System speaker has 218 words
[Rank 0] 2026-01-23 12:37:30,863 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:30,863 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:30,863 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:30,864 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:30,891 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:30,974 - podcast_processing.episode_processor - INFO -   Processing chunk 5/10 (210.0s)
[Rank 0] 2026-01-23 12:37:31,009 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:31,108 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:31,108 - podcast_processing.episode_processor - DEBUG - System speaker has 277 words
[Rank 0] 2026-01-23 12:37:31,154 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:31,154 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:31,154 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:31,155 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:31,182 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:31,270 - podcast_processing.episode_processor - INFO -   Processing chunk 6/10 (210.0s)
[Rank 0] 2026-01-23 12:37:31,305 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:31,426 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:31,657 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:31,657 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:31,657 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:31,657 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:31,658 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:31,685 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:31,773 - podcast_processing.episode_processor - INFO -   Processing chunk 7/10 (210.0s)
[Rank 0] 2026-01-23 12:37:31,811 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:31,898 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:31,898 - podcast_processing.episode_processor - DEBUG - System speaker has 361 words
[Rank 0] 2026-01-23 12:37:31,945 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:31,945 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:31,945 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:31,946 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:31,973 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:32,063 - podcast_processing.episode_processor - INFO -   Processing chunk 8/10 (210.0s)
[Rank 0] 2026-01-23 12:37:32,098 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:32,181 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:32,181 - podcast_processing.episode_processor - DEBUG - System speaker has 340 words
[Rank 0] 2026-01-23 12:37:32,228 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:32,228 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:32,228 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:32,229 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:32,256 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:32,341 - podcast_processing.episode_processor - INFO -   Processing chunk 9/10 (210.0s)
[Rank 0] 2026-01-23 12:37:32,376 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:32,457 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:32,457 - podcast_processing.episode_processor - DEBUG - System speaker has 20 words
[Rank 0] 2026-01-23 12:37:32,503 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:32,504 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:32,504 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:32,504 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:32,532 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:32,620 - podcast_processing.episode_processor - INFO -   Processing chunk 10/10 (96.1s)
[Rank 0] 2026-01-23 12:37:32,637 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/2305528 samples zeroed
[Rank 0] 2026-01-23 12:37:32,676 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1201]), System codes shape: torch.Size([1, 8, 1201])
[Rank 0] 2026-01-23 12:37:32,676 - podcast_processing.episode_processor - DEBUG - System speaker has 11 words
[Rank 0] 2026-01-23 12:37:32,689 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1201])
[Rank 0] 2026-01-23 12:37:32,689 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1201
[Rank 0] 2026-01-23 12:37:32,689 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1201]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:32,690 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1202])
[Rank 0] 2026-01-23 12:37:32,717 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1201, 4096])
[Rank 0] 2026-01-23 12:37:32,853 - podcast_processing.episode_processor - INFO - Combined 10 chunks into final output shape: torch.Size([24826, 4096])
[Rank 0] 2026-01-23 12:37:34,950 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/E2M Interview_From 2 Employees to 100 in 4 years!/features_assignment_1.npy
[Rank 0] 2026-01-23 12:37:34,950 - podcast_processing.episode_processor - INFO -   Saved features: 24826 frames
[Rank 0] 2026-01-23 12:37:34,951 - podcast_processing.label_generator - DEBUG - Processing 11 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:37:34,983 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/E2M Interview_From 2 Employees to 100 in 4 years!/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:37:34,983 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 74/24826 positive
[Rank 0] 2026-01-23 12:37:34,989 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/E2M Interview_From 2 Employees to 100 in 4 years!/metadata_shift_1.json
[Rank 0] 2026-01-23 12:37:34,989 - podcast_processing.episode_processor - INFO - Completed episode: E2M Interview_From 2 Employees to 100 in 4 years!
[Rank 0] 2026-01-23 12:37:35,034 - podcast_processing.distributed_orchestrator - INFO - âœ“ E2M Interview_From 2 Employees to 100 in 4 years!
[Rank 0] 2026-01-23 12:37:35,038 - podcast_processing.episode_processor - INFO - Processing episode: Education-Factory_Teens Talking
[Rank 0] 2026-01-23 12:37:35,044 - podcast_processing.label_generator - DEBUG - Loaded 62 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Education-Factory_Teens Talking.json
[Rank 0] 2026-01-23 12:37:35,045 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_02 (longer), SPEAKER_03 (shorter)
[Rank 0] 2026-01-23 12:37:35,287 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [354.44, 354.44], using fallback
[Rank 0] 2026-01-23 12:37:35,584 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [834.35, 834.55], using fallback
[Rank 0] 2026-01-23 12:37:35,676 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [848.19, 848.62], using fallback
[Rank 0] 2026-01-23 12:37:35,703 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [892.34, 892.37], using fallback
[Rank 0] 2026-01-23 12:37:36,719 - podcast_processing.alignment_merger - INFO - Created 8570 word alignments
[Rank 0] 2026-01-23 12:37:37,280 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_02: torch.Size([1, 60424704]), SPEAKER_03: torch.Size([1, 60424704])
[Rank 0] 2026-01-23 12:37:37,280 - podcast_processing.episode_processor - INFO - Episode duration: 2517.70s
[Rank 0] 2026-01-23 12:37:37,280 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:37:37,286 - podcast_processing.audio_masking - DEBUG - Creating mask from 29 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:37:37,315 - podcast_processing.audio_masking - DEBUG - Mask covers 365512/60424704 samples (0.60%)
[Rank 0] 2026-01-23 12:37:37,344 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 365512/60424704 samples masked
[Rank 0] 2026-01-23 12:37:37,997 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 365512/60424704 samples zeroed
[Rank 0] 2026-01-23 12:37:37,997 - podcast_processing.episode_processor - INFO - Audio is 2517.7s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:37:37,997 - podcast_processing.episode_processor - INFO - Processing 2517.7s audio in 12 chunks of 210s each
[Rank 0] 2026-01-23 12:37:37,997 - podcast_processing.episode_processor - INFO -   Processing chunk 1/12 (210.0s)
[Rank 0] 2026-01-23 12:37:38,033 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 57361/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:38,131 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:38,131 - podcast_processing.episode_processor - DEBUG - System speaker has 414 words
[Rank 0] 2026-01-23 12:37:38,177 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:38,177 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:38,177 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:38,178 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:38,206 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:38,315 - podcast_processing.episode_processor - INFO -   Processing chunk 2/12 (210.0s)
[Rank 0] 2026-01-23 12:37:38,351 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 10800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:38,434 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:38,434 - podcast_processing.episode_processor - DEBUG - System speaker has 265 words
[Rank 0] 2026-01-23 12:37:38,481 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:38,481 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:38,481 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:38,482 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:38,509 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:38,593 - podcast_processing.episode_processor - INFO -   Processing chunk 3/12 (210.0s)
[Rank 0] 2026-01-23 12:37:38,628 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:38,724 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:38,724 - podcast_processing.episode_processor - DEBUG - System speaker has 334 words
[Rank 0] 2026-01-23 12:37:38,770 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:38,770 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:38,771 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:38,771 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:38,799 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:38,883 - podcast_processing.episode_processor - INFO -   Processing chunk 4/12 (210.0s)
[Rank 0] 2026-01-23 12:37:38,918 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5759/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:39,017 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:39,017 - podcast_processing.episode_processor - DEBUG - System speaker has 148 words
[Rank 0] 2026-01-23 12:37:39,064 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:39,064 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:39,064 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:39,065 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:39,092 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:39,176 - podcast_processing.episode_processor - INFO -   Processing chunk 5/12 (210.0s)
[Rank 0] 2026-01-23 12:37:39,211 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 33120/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:39,304 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:39,304 - podcast_processing.episode_processor - DEBUG - System speaker has 290 words
[Rank 0] 2026-01-23 12:37:39,351 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:39,351 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:39,351 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:39,352 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:39,379 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:39,462 - podcast_processing.episode_processor - INFO -   Processing chunk 6/12 (210.0s)
[Rank 0] 2026-01-23 12:37:39,498 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 83040/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:39,580 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:39,580 - podcast_processing.episode_processor - DEBUG - System speaker has 475 words
[Rank 0] 2026-01-23 12:37:39,626 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:39,627 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:39,627 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:39,627 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:39,655 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:39,738 - podcast_processing.episode_processor - INFO -   Processing chunk 7/12 (210.0s)
[Rank 0] 2026-01-23 12:37:39,773 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 80882/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:39,855 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:39,855 - podcast_processing.episode_processor - DEBUG - System speaker has 434 words
[Rank 0] 2026-01-23 12:37:39,902 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:39,902 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:39,902 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:39,902 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:39,929 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:40,013 - podcast_processing.episode_processor - INFO -   Processing chunk 8/12 (210.0s)
[Rank 0] 2026-01-23 12:37:40,048 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:40,130 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:40,131 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:40,177 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:40,177 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:40,177 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:40,178 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:40,205 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:40,286 - podcast_processing.episode_processor - INFO -   Processing chunk 9/12 (210.0s)
[Rank 0] 2026-01-23 12:37:40,322 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:40,404 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:40,404 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:40,450 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:40,930 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:40,930 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:40,930 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:40,958 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:41,049 - podcast_processing.episode_processor - INFO -   Processing chunk 10/12 (210.0s)
[Rank 0] 2026-01-23 12:37:41,084 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 47274/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:41,167 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:41,219 - podcast_processing.episode_processor - DEBUG - System speaker has 290 words
[Rank 0] 2026-01-23 12:37:41,222 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:41,222 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:41,222 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:41,223 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:41,250 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:41,333 - podcast_processing.episode_processor - INFO -   Processing chunk 11/12 (210.0s)
[Rank 0] 2026-01-23 12:37:41,379 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 47276/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:41,462 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:41,462 - podcast_processing.episode_processor - DEBUG - System speaker has 332 words
[Rank 0] 2026-01-23 12:37:41,508 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:41,717 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:41,717 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:41,718 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:41,745 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:41,839 - podcast_processing.episode_processor - INFO -   Processing chunk 12/12 (207.7s)
[Rank 0] 2026-01-23 12:37:41,886 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/4984704 samples zeroed
[Rank 0] 2026-01-23 12:37:41,969 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2597]), System codes shape: torch.Size([1, 8, 2597])
[Rank 0] 2026-01-23 12:37:41,969 - podcast_processing.episode_processor - DEBUG - System speaker has 165 words
[Rank 0] 2026-01-23 12:37:42,013 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2597])
[Rank 0] 2026-01-23 12:37:42,013 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2597
[Rank 0] 2026-01-23 12:37:42,013 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2597]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:42,014 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2598])
[Rank 0] 2026-01-23 12:37:42,043 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2597, 4096])
[Rank 0] 2026-01-23 12:37:42,269 - podcast_processing.episode_processor - INFO - Combined 12 chunks into final output shape: torch.Size([31472, 4096])
[Rank 0] 2026-01-23 12:37:44,807 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Education-Factory_Teens Talking/features_assignment_0.npy
[Rank 0] 2026-01-23 12:37:44,807 - podcast_processing.episode_processor - INFO -   Saved features: 31472 frames
[Rank 0] 2026-01-23 12:37:44,809 - podcast_processing.label_generator - DEBUG - Processing 33 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:37:44,816 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Education-Factory_Teens Talking/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:37:44,816 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 204/31472 positive
[Rank 0] 2026-01-23 12:37:44,816 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:37:44,822 - podcast_processing.audio_masking - DEBUG - Creating mask from 33 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:37:44,875 - podcast_processing.audio_masking - DEBUG - Mask covers 399352/60424704 samples (0.66%)
[Rank 0] 2026-01-23 12:37:44,904 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 399352/60424704 samples masked
[Rank 0] 2026-01-23 12:37:45,563 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 399352/60424704 samples zeroed
[Rank 0] 2026-01-23 12:37:45,563 - podcast_processing.episode_processor - INFO - Audio is 2517.7s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:37:45,563 - podcast_processing.episode_processor - INFO - Processing 2517.7s audio in 12 chunks of 210s each
[Rank 0] 2026-01-23 12:37:45,563 - podcast_processing.episode_processor - INFO -   Processing chunk 1/12 (210.0s)
[Rank 0] 2026-01-23 12:37:45,599 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5280/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:45,683 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:45,683 - podcast_processing.episode_processor - DEBUG - System speaker has 357 words
[Rank 0] 2026-01-23 12:37:45,728 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:45,728 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:45,728 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:45,729 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:45,760 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:45,852 - podcast_processing.episode_processor - INFO -   Processing chunk 2/12 (210.0s)
[Rank 0] 2026-01-23 12:37:45,890 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 70320/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:45,975 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:45,975 - podcast_processing.episode_processor - DEBUG - System speaker has 370 words
[Rank 0] 2026-01-23 12:37:46,020 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:46,020 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:46,020 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:46,021 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:46,050 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:46,235 - podcast_processing.episode_processor - INFO -   Processing chunk 3/12 (210.0s)
[Rank 0] 2026-01-23 12:37:46,275 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 18479/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:46,358 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:46,358 - podcast_processing.episode_processor - DEBUG - System speaker has 119 words
[Rank 0] 2026-01-23 12:37:46,405 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:46,405 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:46,405 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:46,406 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:46,433 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:46,515 - podcast_processing.episode_processor - INFO -   Processing chunk 4/12 (210.0s)
[Rank 0] 2026-01-23 12:37:46,551 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20159/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:46,633 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:46,634 - podcast_processing.episode_processor - DEBUG - System speaker has 361 words
[Rank 0] 2026-01-23 12:37:46,680 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:46,680 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:46,681 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:46,681 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:46,709 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:46,816 - podcast_processing.episode_processor - INFO -   Processing chunk 5/12 (210.0s)
[Rank 0] 2026-01-23 12:37:46,852 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 44640/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:46,936 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:46,936 - podcast_processing.episode_processor - DEBUG - System speaker has 355 words
[Rank 0] 2026-01-23 12:37:46,982 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:46,983 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:46,983 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:46,983 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:47,011 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:47,101 - podcast_processing.episode_processor - INFO -   Processing chunk 6/12 (210.0s)
[Rank 0] 2026-01-23 12:37:47,137 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16081/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:47,219 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:47,220 - podcast_processing.episode_processor - DEBUG - System speaker has 297 words
[Rank 0] 2026-01-23 12:37:47,266 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:47,266 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:47,266 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:47,267 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:47,295 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:47,382 - podcast_processing.episode_processor - INFO -   Processing chunk 7/12 (210.0s)
[Rank 0] 2026-01-23 12:37:47,422 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 41040/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:47,504 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:47,504 - podcast_processing.episode_processor - DEBUG - System speaker has 229 words
[Rank 0] 2026-01-23 12:37:47,551 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:47,551 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:47,551 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:47,552 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:47,583 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:47,681 - podcast_processing.episode_processor - INFO -   Processing chunk 8/12 (210.0s)
[Rank 0] 2026-01-23 12:37:47,716 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:47,887 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:47,888 - podcast_processing.episode_processor - DEBUG - System speaker has 82 words
[Rank 0] 2026-01-23 12:37:47,934 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:47,934 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:47,934 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:47,935 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:47,962 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:48,055 - podcast_processing.episode_processor - INFO -   Processing chunk 9/12 (210.0s)
[Rank 0] 2026-01-23 12:37:48,090 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 84956/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:48,178 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:48,178 - podcast_processing.episode_processor - DEBUG - System speaker has 484 words
[Rank 0] 2026-01-23 12:37:48,225 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:48,225 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:48,225 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:48,226 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:48,253 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:48,344 - podcast_processing.episode_processor - INFO -   Processing chunk 10/12 (210.0s)
[Rank 0] 2026-01-23 12:37:48,379 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 23760/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:48,463 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:48,463 - podcast_processing.episode_processor - DEBUG - System speaker has 175 words
[Rank 0] 2026-01-23 12:37:48,509 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:48,509 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:48,509 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:48,510 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:48,537 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:48,620 - podcast_processing.episode_processor - INFO -   Processing chunk 11/12 (210.0s)
[Rank 0] 2026-01-23 12:37:48,669 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5761/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:48,756 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:48,756 - podcast_processing.episode_processor - DEBUG - System speaker has 191 words
[Rank 0] 2026-01-23 12:37:48,802 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:48,802 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:48,802 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:48,803 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:48,830 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:48,918 - podcast_processing.episode_processor - INFO -   Processing chunk 12/12 (207.7s)
[Rank 0] 2026-01-23 12:37:48,966 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 68876/4984704 samples zeroed
[Rank 0] 2026-01-23 12:37:49,052 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2597]), System codes shape: torch.Size([1, 8, 2597])
[Rank 0] 2026-01-23 12:37:49,052 - podcast_processing.episode_processor - DEBUG - System speaker has 490 words
[Rank 0] 2026-01-23 12:37:49,095 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2597])
[Rank 0] 2026-01-23 12:37:49,095 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2597
[Rank 0] 2026-01-23 12:37:49,096 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2597]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:49,096 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2598])
[Rank 0] 2026-01-23 12:37:49,123 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2597, 4096])
[Rank 0] 2026-01-23 12:37:49,359 - podcast_processing.episode_processor - INFO - Combined 12 chunks into final output shape: torch.Size([31472, 4096])
[Rank 0] 2026-01-23 12:37:51,215 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Education-Factory_Teens Talking/features_assignment_1.npy
[Rank 0] 2026-01-23 12:37:51,216 - podcast_processing.episode_processor - INFO -   Saved features: 31472 frames
[Rank 0] 2026-01-23 12:37:51,216 - podcast_processing.label_generator - DEBUG - Processing 29 laughter events for SPEAKER_03
[Rank 0] 2026-01-23 12:37:51,225 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Education-Factory_Teens Talking/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:37:51,225 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 191/31472 positive
[Rank 0] 2026-01-23 12:37:51,229 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Education-Factory_Teens Talking/metadata_shift_1.json
[Rank 0] 2026-01-23 12:37:51,229 - podcast_processing.episode_processor - INFO - Completed episode: Education-Factory_Teens Talking
[Rank 0] 2026-01-23 12:37:51,265 - podcast_processing.distributed_orchestrator - INFO - âœ“ Education-Factory_Teens Talking
[Rank 0] 2026-01-23 12:37:51,268 - podcast_processing.episode_processor - INFO - Processing episode: FLY Travel Radio, with Melissa Rodway_FLY Travel Radio Episode 170 7+Yrs, Every Country, No Planes. Thor Pedersen, Once Upon A Saga
[Rank 0] 2026-01-23 12:37:51,272 - podcast_processing.label_generator - DEBUG - Loaded 80 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/FLY Travel Radio, with Melissa Rodway_FLY Travel Radio Episode 170 7+Yrs, Every Country, No Planes. Thor Pedersen, Once Upon A Saga.json
[Rank 0] 2026-01-23 12:37:51,272 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_02 (longer), SPEAKER_00 (shorter)
[Rank 0] 2026-01-23 12:37:51,283 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3.70, 3.86], using fallback
[Rank 0] 2026-01-23 12:37:51,822 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1900.93, 1901.11], using fallback
[Rank 0] 2026-01-23 12:37:51,822 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1901.11, 1901.26], using fallback
[Rank 0] 2026-01-23 12:37:52,044 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2683.66, 2684.20], using fallback
[Rank 0] 2026-01-23 12:37:52,188 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3182.09, 3182.63], using fallback
[Rank 0] 2026-01-23 12:37:52,304 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3607.21, 3607.42], using fallback
[Rank 0] 2026-01-23 12:37:52,304 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3608.28, 3608.61], using fallback
[Rank 0] 2026-01-23 12:37:52,304 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3609.44, 3609.73], using fallback
[Rank 0] 2026-01-23 12:37:52,305 - podcast_processing.alignment_merger - INFO - Created 10942 word alignments
[Rank 0] 2026-01-23 12:37:53,139 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_02: torch.Size([1, 87060344]), SPEAKER_00: torch.Size([1, 87060344])
[Rank 0] 2026-01-23 12:37:53,139 - podcast_processing.episode_processor - INFO - Episode duration: 3627.51s
[Rank 0] 2026-01-23 12:37:53,139 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:37:53,139 - podcast_processing.audio_masking - DEBUG - Creating mask from 23 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:37:53,194 - podcast_processing.audio_masking - DEBUG - Mask covers 148081/87060344 samples (0.17%)
[Rank 0] 2026-01-23 12:37:53,235 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 148081/87060344 samples masked
[Rank 0] 2026-01-23 12:37:54,179 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 148081/87060344 samples zeroed
[Rank 0] 2026-01-23 12:37:54,179 - podcast_processing.episode_processor - INFO - Audio is 3627.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:37:54,179 - podcast_processing.episode_processor - INFO - Processing 3627.5s audio in 18 chunks of 210s each
[Rank 0] 2026-01-23 12:37:54,179 - podcast_processing.episode_processor - INFO -   Processing chunk 1/18 (210.0s)
[Rank 0] 2026-01-23 12:37:54,222 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:54,306 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:54,306 - podcast_processing.episode_processor - DEBUG - System speaker has 237 words
[Rank 0] 2026-01-23 12:37:54,352 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:54,352 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:54,353 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:54,353 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:54,381 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:54,467 - podcast_processing.episode_processor - INFO -   Processing chunk 2/18 (210.0s)
[Rank 0] 2026-01-23 12:37:54,502 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:54,585 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:54,585 - podcast_processing.episode_processor - DEBUG - System speaker has 62 words
[Rank 0] 2026-01-23 12:37:54,632 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:54,632 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:54,632 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:54,633 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:54,660 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:54,744 - podcast_processing.episode_processor - INFO -   Processing chunk 3/18 (210.0s)
[Rank 0] 2026-01-23 12:37:54,780 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5760/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:54,877 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:54,877 - podcast_processing.episode_processor - DEBUG - System speaker has 140 words
[Rank 0] 2026-01-23 12:37:54,923 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:54,923 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:54,923 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:54,923 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:54,954 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:55,034 - podcast_processing.episode_processor - INFO -   Processing chunk 4/18 (210.0s)
[Rank 0] 2026-01-23 12:37:55,071 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:55,159 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:55,159 - podcast_processing.episode_processor - DEBUG - System speaker has 72 words
[Rank 0] 2026-01-23 12:37:55,203 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:55,203 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:55,204 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:55,204 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:55,235 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:55,316 - podcast_processing.episode_processor - INFO -   Processing chunk 5/18 (210.0s)
[Rank 0] 2026-01-23 12:37:55,352 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20641/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:55,434 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:55,435 - podcast_processing.episode_processor - DEBUG - System speaker has 66 words
[Rank 0] 2026-01-23 12:37:55,481 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:55,481 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:55,481 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:55,482 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:55,509 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:55,592 - podcast_processing.episode_processor - INFO -   Processing chunk 6/18 (210.0s)
[Rank 0] 2026-01-23 12:37:55,738 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:55,820 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:55,821 - podcast_processing.episode_processor - DEBUG - System speaker has 80 words
[Rank 0] 2026-01-23 12:37:55,867 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:55,867 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:55,867 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:55,868 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:55,895 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:55,979 - podcast_processing.episode_processor - INFO -   Processing chunk 7/18 (210.0s)
[Rank 0] 2026-01-23 12:37:56,020 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20160/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:56,109 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:56,109 - podcast_processing.episode_processor - DEBUG - System speaker has 81 words
[Rank 0] 2026-01-23 12:37:56,155 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:56,155 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:56,155 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:56,156 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:56,185 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:56,267 - podcast_processing.episode_processor - INFO -   Processing chunk 8/18 (210.0s)
[Rank 0] 2026-01-23 12:37:56,302 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 19442/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:56,401 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:56,401 - podcast_processing.episode_processor - DEBUG - System speaker has 199 words
[Rank 0] 2026-01-23 12:37:56,447 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:56,447 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:56,447 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:56,448 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:56,475 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:56,566 - podcast_processing.episode_processor - INFO -   Processing chunk 9/18 (210.0s)
[Rank 0] 2026-01-23 12:37:56,615 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:56,698 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:56,698 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:56,744 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:56,744 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:56,744 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:56,745 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:56,772 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:56,855 - podcast_processing.episode_processor - INFO -   Processing chunk 10/18 (210.0s)
[Rank 0] 2026-01-23 12:37:57,401 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 28560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:57,482 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:57,483 - podcast_processing.episode_processor - DEBUG - System speaker has 107 words
[Rank 0] 2026-01-23 12:37:57,529 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:57,529 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:57,529 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:57,529 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:57,557 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:57,639 - podcast_processing.episode_processor - INFO -   Processing chunk 11/18 (210.0s)
[Rank 0] 2026-01-23 12:37:57,675 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:57,767 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:57,767 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:37:57,814 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:57,814 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:57,814 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:57,814 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:57,842 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:57,924 - podcast_processing.episode_processor - INFO -   Processing chunk 12/18 (210.0s)
[Rank 0] 2026-01-23 12:37:57,960 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 21600/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:58,059 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:58,059 - podcast_processing.episode_processor - DEBUG - System speaker has 70 words
[Rank 0] 2026-01-23 12:37:58,106 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:58,106 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:58,106 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:58,107 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:58,134 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:58,216 - podcast_processing.episode_processor - INFO -   Processing chunk 13/18 (210.0s)
[Rank 0] 2026-01-23 12:37:58,264 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12243/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:58,362 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:58,362 - podcast_processing.episode_processor - DEBUG - System speaker has 192 words
[Rank 0] 2026-01-23 12:37:58,408 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:58,409 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:58,409 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:58,409 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:58,436 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:58,519 - podcast_processing.episode_processor - INFO -   Processing chunk 14/18 (210.0s)
[Rank 0] 2026-01-23 12:37:58,566 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11280/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:58,659 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:58,659 - podcast_processing.episode_processor - DEBUG - System speaker has 102 words
[Rank 0] 2026-01-23 12:37:58,706 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:58,706 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:58,706 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:58,707 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:58,734 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:58,828 - podcast_processing.episode_processor - INFO -   Processing chunk 15/18 (210.0s)
[Rank 0] 2026-01-23 12:37:58,876 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:58,957 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:58,957 - podcast_processing.episode_processor - DEBUG - System speaker has 178 words
[Rank 0] 2026-01-23 12:37:59,004 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:59,004 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:59,004 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:59,005 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:59,032 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:59,125 - podcast_processing.episode_processor - INFO -   Processing chunk 16/18 (210.0s)
[Rank 0] 2026-01-23 12:37:59,172 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:59,253 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:59,253 - podcast_processing.episode_processor - DEBUG - System speaker has 93 words
[Rank 0] 2026-01-23 12:37:59,300 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:59,300 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:59,300 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:59,300 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:59,327 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:59,421 - podcast_processing.episode_processor - INFO -   Processing chunk 17/18 (210.0s)
[Rank 0] 2026-01-23 12:37:59,468 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3835/5040000 samples zeroed
[Rank 0] 2026-01-23 12:37:59,549 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:37:59,549 - podcast_processing.episode_processor - DEBUG - System speaker has 141 words
[Rank 0] 2026-01-23 12:37:59,595 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:37:59,807 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:37:59,807 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:59,807 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:37:59,835 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:37:59,928 - podcast_processing.episode_processor - INFO -   Processing chunk 18/18 (57.5s)
[Rank 0] 2026-01-23 12:37:59,942 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/1380344 samples zeroed
[Rank 0] 2026-01-23 12:37:59,993 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 719]), System codes shape: torch.Size([1, 8, 719])
[Rank 0] 2026-01-23 12:37:59,993 - podcast_processing.episode_processor - DEBUG - System speaker has 100 words
[Rank 0] 2026-01-23 12:37:59,997 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 719])
[Rank 0] 2026-01-23 12:37:59,997 - podcast_processing.episode_processor - DEBUG - Padded to max_t=719
[Rank 0] 2026-01-23 12:37:59,997 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 719]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:37:59,997 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 720])
[Rank 0] 2026-01-23 12:38:00,028 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 719, 4096])
[Rank 0] 2026-01-23 12:38:00,265 - podcast_processing.episode_processor - INFO - Combined 18 chunks into final output shape: torch.Size([45344, 4096])
[Rank 0] 2026-01-23 12:38:02,476 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/FLY Travel Radio, with Melissa Rodway_FLY Travel Radio Episode 170 7+Yrs, Every Country, No Planes. Thor Pedersen, Once Upon A Saga/features_assignment_0.npy
[Rank 0] 2026-01-23 12:38:02,476 - podcast_processing.episode_processor - INFO -   Saved features: 45344 frames
[Rank 0] 2026-01-23 12:38:02,476 - podcast_processing.label_generator - DEBUG - Processing 57 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:38:02,498 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/FLY Travel Radio, with Melissa Rodway_FLY Travel Radio Episode 170 7+Yrs, Every Country, No Planes. Thor Pedersen, Once Upon A Saga/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:38:02,498 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 213/45344 positive
[Rank 0] 2026-01-23 12:38:02,499 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:38:02,499 - podcast_processing.audio_masking - DEBUG - Creating mask from 57 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:38:02,582 - podcast_processing.audio_masking - DEBUG - Mask covers 408471/87060344 samples (0.47%)
[Rank 0] 2026-01-23 12:38:02,623 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 408471/87060344 samples masked
[Rank 0] 2026-01-23 12:38:03,579 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 408471/87060344 samples zeroed
[Rank 0] 2026-01-23 12:38:03,579 - podcast_processing.episode_processor - INFO - Audio is 3627.5s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:38:03,579 - podcast_processing.episode_processor - INFO - Processing 3627.5s audio in 18 chunks of 210s each
[Rank 0] 2026-01-23 12:38:03,579 - podcast_processing.episode_processor - INFO -   Processing chunk 1/18 (210.0s)
[Rank 0] 2026-01-23 12:38:03,622 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:03,707 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:03,707 - podcast_processing.episode_processor - DEBUG - System speaker has 303 words
[Rank 0] 2026-01-23 12:38:03,753 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:03,753 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:03,754 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:03,754 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:03,782 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:03,895 - podcast_processing.episode_processor - INFO -   Processing chunk 2/18 (210.0s)
[Rank 0] 2026-01-23 12:38:03,936 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20639/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:04,036 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:04,036 - podcast_processing.episode_processor - DEBUG - System speaker has 553 words
[Rank 0] 2026-01-23 12:38:04,083 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:04,083 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:04,084 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:04,084 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:04,112 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:04,215 - podcast_processing.episode_processor - INFO -   Processing chunk 3/18 (210.0s)
[Rank 0] 2026-01-23 12:38:04,255 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:04,357 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:04,357 - podcast_processing.episode_processor - DEBUG - System speaker has 486 words
[Rank 0] 2026-01-23 12:38:04,404 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:04,404 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:04,404 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:04,405 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:04,432 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:04,545 - podcast_processing.episode_processor - INFO -   Processing chunk 4/18 (210.0s)
[Rank 0] 2026-01-23 12:38:04,590 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 49922/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:04,695 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:04,695 - podcast_processing.episode_processor - DEBUG - System speaker has 560 words
[Rank 0] 2026-01-23 12:38:04,742 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:04,742 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:04,742 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:04,743 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:04,770 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:04,903 - podcast_processing.episode_processor - INFO -   Processing chunk 5/18 (210.0s)
[Rank 0] 2026-01-23 12:38:04,949 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7440/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:05,053 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:05,053 - podcast_processing.episode_processor - DEBUG - System speaker has 584 words
[Rank 0] 2026-01-23 12:38:05,100 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:05,100 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:05,100 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:05,101 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:05,128 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:05,251 - podcast_processing.episode_processor - INFO -   Processing chunk 6/18 (210.0s)
[Rank 0] 2026-01-23 12:38:05,297 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:05,397 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:05,398 - podcast_processing.episode_processor - DEBUG - System speaker has 586 words
[Rank 0] 2026-01-23 12:38:05,444 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:05,444 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:05,445 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:05,445 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:05,473 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:05,589 - podcast_processing.episode_processor - INFO -   Processing chunk 7/18 (210.0s)
[Rank 0] 2026-01-23 12:38:05,623 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12480/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:05,717 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:05,717 - podcast_processing.episode_processor - DEBUG - System speaker has 578 words
[Rank 0] 2026-01-23 12:38:05,764 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:05,764 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:05,764 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:05,765 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:05,792 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:05,877 - podcast_processing.episode_processor - INFO -   Processing chunk 8/18 (210.0s)
[Rank 0] 2026-01-23 12:38:05,912 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 8158/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:06,027 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:06,027 - podcast_processing.episode_processor - DEBUG - System speaker has 493 words
[Rank 0] 2026-01-23 12:38:06,074 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:06,074 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:06,074 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:06,075 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:06,102 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:06,207 - podcast_processing.episode_processor - INFO -   Processing chunk 9/18 (210.0s)
[Rank 0] 2026-01-23 12:38:06,242 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:06,324 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:06,324 - podcast_processing.episode_processor - DEBUG - System speaker has 651 words
[Rank 0] 2026-01-23 12:38:06,371 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:06,371 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:06,371 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:06,372 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:06,399 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:06,484 - podcast_processing.episode_processor - INFO -   Processing chunk 10/18 (210.0s)
[Rank 0] 2026-01-23 12:38:06,520 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 8400/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:06,626 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:06,626 - podcast_processing.episode_processor - DEBUG - System speaker has 535 words
[Rank 0] 2026-01-23 12:38:06,673 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:06,673 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:06,674 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:06,674 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:06,701 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:06,793 - podcast_processing.episode_processor - INFO -   Processing chunk 11/18 (210.0s)
[Rank 0] 2026-01-23 12:38:06,838 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 78955/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:06,925 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:06,925 - podcast_processing.episode_processor - DEBUG - System speaker has 657 words
[Rank 0] 2026-01-23 12:38:06,972 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:06,972 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:06,972 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:06,972 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:07,005 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:07,098 - podcast_processing.episode_processor - INFO -   Processing chunk 12/18 (210.0s)
[Rank 0] 2026-01-23 12:38:07,136 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 36233/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:07,225 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:07,226 - podcast_processing.episode_processor - DEBUG - System speaker has 552 words
[Rank 0] 2026-01-23 12:38:07,272 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:07,272 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:07,272 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:07,273 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:07,304 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:07,385 - podcast_processing.episode_processor - INFO -   Processing chunk 13/18 (210.0s)
[Rank 0] 2026-01-23 12:38:07,436 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 50157/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:07,520 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:07,520 - podcast_processing.episode_processor - DEBUG - System speaker has 429 words
[Rank 0] 2026-01-23 12:38:07,566 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:07,566 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:07,566 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:07,567 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:07,601 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:07,678 - podcast_processing.episode_processor - INFO -   Processing chunk 14/18 (210.0s)
[Rank 0] 2026-01-23 12:38:07,720 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 17762/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:08,909 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:08,909 - podcast_processing.episode_processor - DEBUG - System speaker has 503 words
[Rank 0] 2026-01-23 12:38:08,955 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:08,955 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:08,955 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:08,955 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:08,989 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:09,067 - podcast_processing.episode_processor - INFO -   Processing chunk 15/18 (210.0s)
[Rank 0] 2026-01-23 12:38:09,116 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:09,199 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:09,200 - podcast_processing.episode_processor - DEBUG - System speaker has 503 words
[Rank 0] 2026-01-23 12:38:09,246 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:09,251 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:09,251 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:09,251 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:09,279 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:09,367 - podcast_processing.episode_processor - INFO -   Processing chunk 16/18 (210.0s)
[Rank 0] 2026-01-23 12:38:09,420 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 91684/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:09,505 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:09,505 - podcast_processing.episode_processor - DEBUG - System speaker has 532 words
[Rank 0] 2026-01-23 12:38:09,549 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:09,549 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:09,549 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:09,550 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:09,578 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:09,672 - podcast_processing.episode_processor - INFO -   Processing chunk 17/18 (210.0s)
[Rank 0] 2026-01-23 12:38:09,719 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:09,801 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:09,801 - podcast_processing.episode_processor - DEBUG - System speaker has 464 words
[Rank 0] 2026-01-23 12:38:09,848 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:09,848 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:09,848 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:09,848 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:09,876 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:09,974 - podcast_processing.episode_processor - INFO -   Processing chunk 18/18 (57.5s)
[Rank 0] 2026-01-23 12:38:09,984 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 26641/1380344 samples zeroed
[Rank 0] 2026-01-23 12:38:10,012 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 719]), System codes shape: torch.Size([1, 8, 719])
[Rank 0] 2026-01-23 12:38:10,012 - podcast_processing.episode_processor - DEBUG - System speaker has 12 words
[Rank 0] 2026-01-23 12:38:10,016 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 719])
[Rank 0] 2026-01-23 12:38:10,016 - podcast_processing.episode_processor - DEBUG - Padded to max_t=719
[Rank 0] 2026-01-23 12:38:10,016 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 719]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:10,017 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 720])
[Rank 0] 2026-01-23 12:38:10,044 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 719, 4096])
[Rank 0] 2026-01-23 12:38:10,270 - podcast_processing.episode_processor - INFO - Combined 18 chunks into final output shape: torch.Size([45344, 4096])
[Rank 0] 2026-01-23 12:38:12,171 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/FLY Travel Radio, with Melissa Rodway_FLY Travel Radio Episode 170 7+Yrs, Every Country, No Planes. Thor Pedersen, Once Upon A Saga/features_assignment_1.npy
[Rank 0] 2026-01-23 12:38:12,171 - podcast_processing.episode_processor - INFO -   Saved features: 45344 frames
[Rank 0] 2026-01-23 12:38:12,171 - podcast_processing.label_generator - DEBUG - Processing 23 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:38:12,181 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/FLY Travel Radio, with Melissa Rodway_FLY Travel Radio Episode 170 7+Yrs, Every Country, No Planes. Thor Pedersen, Once Upon A Saga/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:38:12,185 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 79/45344 positive
[Rank 0] 2026-01-23 12:38:12,191 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/FLY Travel Radio, with Melissa Rodway_FLY Travel Radio Episode 170 7+Yrs, Every Country, No Planes. Thor Pedersen, Once Upon A Saga/metadata_shift_1.json
[Rank 0] 2026-01-23 12:38:12,191 - podcast_processing.episode_processor - INFO - Completed episode: FLY Travel Radio, with Melissa Rodway_FLY Travel Radio Episode 170 7+Yrs, Every Country, No Planes. Thor Pedersen, Once Upon A Saga
[Rank 0] 2026-01-23 12:38:12,236 - podcast_processing.distributed_orchestrator - INFO - âœ“ FLY Travel Radio, with Melissa Rodway_FLY Travel Radio Episode 170 7+Yrs, Every Country, No Planes. Thor Pedersen, Once Upon A Saga
[Rank 0] 2026-01-23 12:38:12,240 - podcast_processing.episode_processor - INFO - Processing episode: GeeklyBiWeekly_Geekly Bi-Weekly Episode 1 WandaVision, Disney+, Spiderman, HBO MAX
[Rank 0] 2026-01-23 12:38:12,249 - podcast_processing.label_generator - DEBUG - Loaded 87 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/GeeklyBiWeekly_Geekly Bi-Weekly Episode 1 WandaVision, Disney+, Spiderman, HBO MAX.json
[Rank 0] 2026-01-23 12:38:12,251 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_00 (longer), SPEAKER_01 (shorter)
[Rank 0] 2026-01-23 12:38:13,141 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [905.43, 905.91], using fallback
[Rank 0] 2026-01-23 12:38:14,656 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2546.06, 2546.47], using fallback
[Rank 0] 2026-01-23 12:38:14,682 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2574.45, 2574.72], using fallback
[Rank 0] 2026-01-23 12:38:14,856 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2752.26, 2752.50], using fallback
[Rank 0] 2026-01-23 12:38:14,869 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2767.32, 2767.62], using fallback
[Rank 0] 2026-01-23 12:38:15,185 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3115.83, 3115.83], using fallback
[Rank 0] 2026-01-23 12:38:15,822 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [3790.14, 3790.25], using fallback
[Rank 0] 2026-01-23 12:38:16,870 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [4949.29, 4949.73], using fallback
[Rank 0] 2026-01-23 12:38:17,007 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [5102.06, 5102.29], using fallback
[Rank 0] 2026-01-23 12:38:17,054 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [5157.66, 5157.86], using fallback
[Rank 0] 2026-01-23 12:38:17,259 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [5356.29, 5356.45], using fallback
[Rank 0] 2026-01-23 12:38:17,368 - podcast_processing.alignment_merger - INFO - Created 14713 word alignments
[Rank 0] 2026-01-23 12:38:18,609 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_00: torch.Size([1, 131569240]), SPEAKER_01: torch.Size([1, 131569240])
[Rank 0] 2026-01-23 12:38:18,609 - podcast_processing.episode_processor - INFO - Episode duration: 5482.05s
[Rank 0] 2026-01-23 12:38:18,609 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:38:18,609 - podcast_processing.audio_masking - DEBUG - Creating mask from 45 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:38:18,693 - podcast_processing.audio_masking - DEBUG - Mask covers 365270/131569240 samples (0.28%)
[Rank 0] 2026-01-23 12:38:18,755 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 365270/131569240 samples masked
[Rank 0] 2026-01-23 12:38:20,209 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 365270/131569240 samples zeroed
[Rank 0] 2026-01-23 12:38:20,209 - podcast_processing.episode_processor - INFO - Audio is 5482.1s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:38:20,209 - podcast_processing.episode_processor - INFO - Processing 5482.1s audio in 27 chunks of 210s each
[Rank 0] 2026-01-23 12:38:20,209 - podcast_processing.episode_processor - INFO -   Processing chunk 1/27 (210.0s)
[Rank 0] 2026-01-23 12:38:20,244 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 35040/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:20,328 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:20,328 - podcast_processing.episode_processor - DEBUG - System speaker has 194 words
[Rank 0] 2026-01-23 12:38:20,374 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:20,374 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:20,374 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:20,375 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:20,402 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:20,490 - podcast_processing.episode_processor - INFO -   Processing chunk 2/27 (210.0s)
[Rank 0] 2026-01-23 12:38:20,525 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 70560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:20,608 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:20,748 - podcast_processing.episode_processor - DEBUG - System speaker has 266 words
[Rank 0] 2026-01-23 12:38:20,751 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:20,776 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:20,776 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:20,776 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:20,804 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:20,898 - podcast_processing.episode_processor - INFO -   Processing chunk 3/27 (210.0s)
[Rank 0] 2026-01-23 12:38:20,933 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:21,016 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:21,016 - podcast_processing.episode_processor - DEBUG - System speaker has 291 words
[Rank 0] 2026-01-23 12:38:21,063 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:21,063 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:21,063 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:21,064 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:21,091 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:21,177 - podcast_processing.episode_processor - INFO -   Processing chunk 4/27 (210.0s)
[Rank 0] 2026-01-23 12:38:21,212 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 9361/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:21,295 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:21,295 - podcast_processing.episode_processor - DEBUG - System speaker has 314 words
[Rank 0] 2026-01-23 12:38:21,342 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:21,342 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:21,342 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:21,343 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:21,370 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:21,454 - podcast_processing.episode_processor - INFO -   Processing chunk 5/27 (210.0s)
[Rank 0] 2026-01-23 12:38:21,488 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5520/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:21,570 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:21,570 - podcast_processing.episode_processor - DEBUG - System speaker has 246 words
[Rank 0] 2026-01-23 12:38:21,617 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:21,617 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:21,618 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:21,618 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:21,645 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:21,728 - podcast_processing.episode_processor - INFO -   Processing chunk 6/27 (210.0s)
[Rank 0] 2026-01-23 12:38:21,764 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6242/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:21,845 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:21,845 - podcast_processing.episode_processor - DEBUG - System speaker has 241 words
[Rank 0] 2026-01-23 12:38:21,892 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:21,892 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:21,893 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:21,893 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:21,920 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:22,003 - podcast_processing.episode_processor - INFO -   Processing chunk 7/27 (210.0s)
[Rank 0] 2026-01-23 12:38:22,038 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:22,120 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:22,120 - podcast_processing.episode_processor - DEBUG - System speaker has 261 words
[Rank 0] 2026-01-23 12:38:22,166 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:22,166 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:22,167 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:22,167 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:22,194 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:22,278 - podcast_processing.episode_processor - INFO -   Processing chunk 8/27 (210.0s)
[Rank 0] 2026-01-23 12:38:22,312 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:22,394 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:22,394 - podcast_processing.episode_processor - DEBUG - System speaker has 324 words
[Rank 0] 2026-01-23 12:38:22,441 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:22,441 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:22,441 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:22,442 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:22,469 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:22,552 - podcast_processing.episode_processor - INFO -   Processing chunk 9/27 (210.0s)
[Rank 0] 2026-01-23 12:38:22,588 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7200/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:22,679 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:22,680 - podcast_processing.episode_processor - DEBUG - System speaker has 188 words
[Rank 0] 2026-01-23 12:38:22,726 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:22,726 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:22,726 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:22,727 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:22,755 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:22,847 - podcast_processing.episode_processor - INFO -   Processing chunk 10/27 (210.0s)
[Rank 0] 2026-01-23 12:38:22,882 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 4800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:22,964 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:22,964 - podcast_processing.episode_processor - DEBUG - System speaker has 231 words
[Rank 0] 2026-01-23 12:38:23,010 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:23,010 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:23,011 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:23,011 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:23,038 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:23,133 - podcast_processing.episode_processor - INFO -   Processing chunk 11/27 (210.0s)
[Rank 0] 2026-01-23 12:38:23,168 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:23,250 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:23,250 - podcast_processing.episode_processor - DEBUG - System speaker has 145 words
[Rank 0] 2026-01-23 12:38:23,296 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:23,296 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:23,297 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:23,297 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:23,324 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:23,415 - podcast_processing.episode_processor - INFO -   Processing chunk 12/27 (210.0s)
[Rank 0] 2026-01-23 12:38:23,454 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:23,536 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:23,536 - podcast_processing.episode_processor - DEBUG - System speaker has 225 words
[Rank 0] 2026-01-23 12:38:23,583 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:23,583 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:23,584 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:23,584 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:23,611 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:23,700 - podcast_processing.episode_processor - INFO -   Processing chunk 13/27 (210.0s)
[Rank 0] 2026-01-23 12:38:23,735 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:23,817 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:23,817 - podcast_processing.episode_processor - DEBUG - System speaker has 248 words
[Rank 0] 2026-01-23 12:38:23,864 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:23,864 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:23,864 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:23,864 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:23,892 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:23,977 - podcast_processing.episode_processor - INFO -   Processing chunk 14/27 (210.0s)
[Rank 0] 2026-01-23 12:38:24,012 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 18247/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:24,093 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:24,403 - podcast_processing.episode_processor - DEBUG - System speaker has 274 words
[Rank 0] 2026-01-23 12:38:24,406 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:24,406 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:24,406 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:24,407 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:24,434 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:24,517 - podcast_processing.episode_processor - INFO -   Processing chunk 15/27 (210.0s)
[Rank 0] 2026-01-23 12:38:24,567 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 12480/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:24,649 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:24,649 - podcast_processing.episode_processor - DEBUG - System speaker has 219 words
[Rank 0] 2026-01-23 12:38:24,695 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:24,696 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:24,696 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:24,697 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:24,724 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:24,822 - podcast_processing.episode_processor - INFO -   Processing chunk 16/27 (210.0s)
[Rank 0] 2026-01-23 12:38:24,868 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:24,951 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:24,951 - podcast_processing.episode_processor - DEBUG - System speaker has 159 words
[Rank 0] 2026-01-23 12:38:24,997 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:24,997 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:24,998 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:24,998 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:25,026 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:25,127 - podcast_processing.episode_processor - INFO -   Processing chunk 17/27 (210.0s)
[Rank 0] 2026-01-23 12:38:25,174 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:25,256 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:25,256 - podcast_processing.episode_processor - DEBUG - System speaker has 271 words
[Rank 0] 2026-01-23 12:38:25,302 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:25,302 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:25,303 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:25,303 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:25,330 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:25,438 - podcast_processing.episode_processor - INFO -   Processing chunk 18/27 (210.0s)
[Rank 0] 2026-01-23 12:38:25,486 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16798/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:25,575 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:25,575 - podcast_processing.episode_processor - DEBUG - System speaker has 308 words
[Rank 0] 2026-01-23 12:38:25,622 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:25,622 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:25,622 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:25,623 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:25,650 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:25,760 - podcast_processing.episode_processor - INFO -   Processing chunk 19/27 (210.0s)
[Rank 0] 2026-01-23 12:38:25,808 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16315/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:25,906 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:25,906 - podcast_processing.episode_processor - DEBUG - System speaker has 174 words
[Rank 0] 2026-01-23 12:38:25,953 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:25,953 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:25,953 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:25,953 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:25,981 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:26,080 - podcast_processing.episode_processor - INFO -   Processing chunk 20/27 (210.0s)
[Rank 0] 2026-01-23 12:38:26,130 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 31682/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:26,214 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:26,214 - podcast_processing.episode_processor - DEBUG - System speaker has 248 words
[Rank 0] 2026-01-23 12:38:26,261 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:26,261 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:26,261 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:26,262 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:26,289 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:26,383 - podcast_processing.episode_processor - INFO -   Processing chunk 21/27 (210.0s)
[Rank 0] 2026-01-23 12:38:26,430 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:26,524 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:26,524 - podcast_processing.episode_processor - DEBUG - System speaker has 351 words
[Rank 0] 2026-01-23 12:38:26,571 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:26,571 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:26,571 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:26,572 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:26,599 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:26,704 - podcast_processing.episode_processor - INFO -   Processing chunk 22/27 (210.0s)
[Rank 0] 2026-01-23 12:38:26,750 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 43431/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:26,832 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:26,832 - podcast_processing.episode_processor - DEBUG - System speaker has 225 words
[Rank 0] 2026-01-23 12:38:26,878 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:26,879 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:26,879 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:26,879 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:26,907 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:27,006 - podcast_processing.episode_processor - INFO -   Processing chunk 23/27 (210.0s)
[Rank 0] 2026-01-23 12:38:27,052 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:27,134 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:27,134 - podcast_processing.episode_processor - DEBUG - System speaker has 241 words
[Rank 0] 2026-01-23 12:38:27,181 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:27,181 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:27,181 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:27,182 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:27,209 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:27,303 - podcast_processing.episode_processor - INFO -   Processing chunk 24/27 (210.0s)
[Rank 0] 2026-01-23 12:38:27,349 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 19440/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:27,431 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:27,431 - podcast_processing.episode_processor - DEBUG - System speaker has 152 words
[Rank 0] 2026-01-23 12:38:27,478 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:27,952 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:27,952 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:27,953 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:27,980 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:28,074 - podcast_processing.episode_processor - INFO -   Processing chunk 25/27 (210.0s)
[Rank 0] 2026-01-23 12:38:28,123 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:28,212 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:28,238 - podcast_processing.episode_processor - DEBUG - System speaker has 260 words
[Rank 0] 2026-01-23 12:38:28,259 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:28,259 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:28,259 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:28,259 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:28,287 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:28,380 - podcast_processing.episode_processor - INFO -   Processing chunk 26/27 (210.0s)
[Rank 0] 2026-01-23 12:38:28,428 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 51594/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:28,668 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:28,668 - podcast_processing.episode_processor - DEBUG - System speaker has 122 words
[Rank 0] 2026-01-23 12:38:28,715 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:28,715 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:28,717 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:28,717 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:28,745 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:28,839 - podcast_processing.episode_processor - INFO -   Processing chunk 27/27 (22.1s)
[Rank 0] 2026-01-23 12:38:28,844 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/529240 samples zeroed
[Rank 0] 2026-01-23 12:38:28,891 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 276]), System codes shape: torch.Size([1, 8, 276])
[Rank 0] 2026-01-23 12:38:28,891 - podcast_processing.episode_processor - DEBUG - System speaker has 1 words
[Rank 0] 2026-01-23 12:38:28,891 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 276])
[Rank 0] 2026-01-23 12:38:28,891 - podcast_processing.episode_processor - DEBUG - Padded to max_t=276
[Rank 0] 2026-01-23 12:38:28,891 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 276]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:28,892 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 277])
[Rank 0] 2026-01-23 12:38:28,928 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 276, 4096])
[Rank 0] 2026-01-23 12:38:29,252 - podcast_processing.episode_processor - INFO - Combined 27 chunks into final output shape: torch.Size([68526, 4096])
[Rank 0] 2026-01-23 12:38:32,524 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/GeeklyBiWeekly_Geekly Bi-Weekly Episode 1 WandaVision, Disney+, Spiderman, HBO MAX/features_assignment_0.npy
[Rank 0] 2026-01-23 12:38:32,524 - podcast_processing.episode_processor - INFO -   Saved features: 68526 frames
[Rank 0] 2026-01-23 12:38:32,526 - podcast_processing.label_generator - DEBUG - Processing 42 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:38:32,532 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/GeeklyBiWeekly_Geekly Bi-Weekly Episode 1 WandaVision, Disney+, Spiderman, HBO MAX/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:38:32,532 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 191/68526 positive
[Rank 0] 2026-01-23 12:38:32,533 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:38:32,534 - podcast_processing.audio_masking - DEBUG - Creating mask from 42 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:38:32,614 - podcast_processing.audio_masking - DEBUG - Mask covers 359511/131569240 samples (0.27%)
[Rank 0] 2026-01-23 12:38:32,672 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 359511/131569240 samples masked
[Rank 0] 2026-01-23 12:38:34,119 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 359511/131569240 samples zeroed
[Rank 0] 2026-01-23 12:38:34,119 - podcast_processing.episode_processor - INFO - Audio is 5482.1s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:38:34,119 - podcast_processing.episode_processor - INFO - Processing 5482.1s audio in 27 chunks of 210s each
[Rank 0] 2026-01-23 12:38:34,125 - podcast_processing.episode_processor - INFO -   Processing chunk 1/27 (210.0s)
[Rank 0] 2026-01-23 12:38:34,160 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 45122/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:34,245 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:34,246 - podcast_processing.episode_processor - DEBUG - System speaker has 415 words
[Rank 0] 2026-01-23 12:38:34,291 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:34,292 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:34,292 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:34,292 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:34,320 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:34,414 - podcast_processing.episode_processor - INFO -   Processing chunk 2/27 (210.0s)
[Rank 0] 2026-01-23 12:38:34,450 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:34,533 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:34,533 - podcast_processing.episode_processor - DEBUG - System speaker has 346 words
[Rank 0] 2026-01-23 12:38:34,579 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:34,580 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:34,580 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:34,580 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:34,608 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:34,696 - podcast_processing.episode_processor - INFO -   Processing chunk 3/27 (210.0s)
[Rank 0] 2026-01-23 12:38:34,732 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:34,814 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:34,814 - podcast_processing.episode_processor - DEBUG - System speaker has 302 words
[Rank 0] 2026-01-23 12:38:34,860 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:34,861 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:34,861 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:34,861 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:34,889 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:34,972 - podcast_processing.episode_processor - INFO -   Processing chunk 4/27 (210.0s)
[Rank 0] 2026-01-23 12:38:35,007 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:35,089 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:35,089 - podcast_processing.episode_processor - DEBUG - System speaker has 242 words
[Rank 0] 2026-01-23 12:38:35,135 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:35,135 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:35,136 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:35,136 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:35,163 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:35,246 - podcast_processing.episode_processor - INFO -   Processing chunk 5/27 (210.0s)
[Rank 0] 2026-01-23 12:38:35,281 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5040/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:35,362 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:35,362 - podcast_processing.episode_processor - DEBUG - System speaker has 319 words
[Rank 0] 2026-01-23 12:38:35,409 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:35,409 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:35,410 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:35,410 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:35,437 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:35,520 - podcast_processing.episode_processor - INFO -   Processing chunk 6/27 (210.0s)
[Rank 0] 2026-01-23 12:38:35,556 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:35,636 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:35,637 - podcast_processing.episode_processor - DEBUG - System speaker has 322 words
[Rank 0] 2026-01-23 12:38:35,683 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:35,683 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:35,684 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:35,684 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:35,711 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:35,794 - podcast_processing.episode_processor - INFO -   Processing chunk 7/27 (210.0s)
[Rank 0] 2026-01-23 12:38:35,828 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5760/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:35,916 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:35,916 - podcast_processing.episode_processor - DEBUG - System speaker has 288 words
[Rank 0] 2026-01-23 12:38:35,962 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:35,963 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:35,963 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:35,963 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:35,990 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:36,079 - podcast_processing.episode_processor - INFO -   Processing chunk 8/27 (210.0s)
[Rank 0] 2026-01-23 12:38:36,114 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:36,199 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:36,199 - podcast_processing.episode_processor - DEBUG - System speaker has 243 words
[Rank 0] 2026-01-23 12:38:36,246 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:36,246 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:36,246 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:36,247 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:36,274 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:36,382 - podcast_processing.episode_processor - INFO -   Processing chunk 9/27 (210.0s)
[Rank 0] 2026-01-23 12:38:36,418 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6958/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:36,498 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:36,498 - podcast_processing.episode_processor - DEBUG - System speaker has 336 words
[Rank 0] 2026-01-23 12:38:36,545 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:36,545 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:36,545 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:36,546 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:36,573 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:36,665 - podcast_processing.episode_processor - INFO -   Processing chunk 10/27 (210.0s)
[Rank 0] 2026-01-23 12:38:36,700 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 41281/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:36,790 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:36,790 - podcast_processing.episode_processor - DEBUG - System speaker has 345 words
[Rank 0] 2026-01-23 12:38:36,836 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:36,837 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:36,837 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:36,837 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:36,865 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:36,963 - podcast_processing.episode_processor - INFO -   Processing chunk 11/27 (210.0s)
[Rank 0] 2026-01-23 12:38:36,998 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:37,078 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:37,079 - podcast_processing.episode_processor - DEBUG - System speaker has 458 words
[Rank 0] 2026-01-23 12:38:37,125 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:37,125 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:37,126 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:37,126 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:37,153 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:37,236 - podcast_processing.episode_processor - INFO -   Processing chunk 12/27 (210.0s)
[Rank 0] 2026-01-23 12:38:37,271 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 5280/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:37,352 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:37,352 - podcast_processing.episode_processor - DEBUG - System speaker has 300 words
[Rank 0] 2026-01-23 12:38:37,399 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:37,399 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:37,399 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:37,400 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:37,427 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:37,510 - podcast_processing.episode_processor - INFO -   Processing chunk 13/27 (210.0s)
[Rank 0] 2026-01-23 12:38:37,544 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 38403/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:37,625 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:37,625 - podcast_processing.episode_processor - DEBUG - System speaker has 321 words
[Rank 0] 2026-01-23 12:38:37,671 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:37,671 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:37,672 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:37,672 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:37,699 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:37,782 - podcast_processing.episode_processor - INFO -   Processing chunk 14/27 (210.0s)
[Rank 0] 2026-01-23 12:38:37,817 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 7440/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:37,898 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:37,898 - podcast_processing.episode_processor - DEBUG - System speaker has 251 words
[Rank 0] 2026-01-23 12:38:37,944 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:37,944 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:37,945 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:37,945 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:37,972 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:38,055 - podcast_processing.episode_processor - INFO -   Processing chunk 15/27 (210.0s)
[Rank 0] 2026-01-23 12:38:38,089 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:38,169 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:38,170 - podcast_processing.episode_processor - DEBUG - System speaker has 364 words
[Rank 0] 2026-01-23 12:38:38,216 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:38,216 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:38,217 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:38,217 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:38,244 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:38,327 - podcast_processing.episode_processor - INFO -   Processing chunk 16/27 (210.0s)
[Rank 0] 2026-01-23 12:38:38,363 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11519/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:38,445 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:38,445 - podcast_processing.episode_processor - DEBUG - System speaker has 377 words
[Rank 0] 2026-01-23 12:38:38,491 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:38,491 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:38,491 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:38,492 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:38,521 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:38,602 - podcast_processing.episode_processor - INFO -   Processing chunk 17/27 (210.0s)
[Rank 0] 2026-01-23 12:38:38,637 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 10086/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:38,719 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:38,719 - podcast_processing.episode_processor - DEBUG - System speaker has 319 words
[Rank 0] 2026-01-23 12:38:38,766 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:38,766 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:38,766 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:38,766 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:38,794 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:38,876 - podcast_processing.episode_processor - INFO -   Processing chunk 18/27 (210.0s)
[Rank 0] 2026-01-23 12:38:38,912 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 10083/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:38,993 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:38,993 - podcast_processing.episode_processor - DEBUG - System speaker has 260 words
[Rank 0] 2026-01-23 12:38:39,039 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:39,039 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:39,040 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:39,040 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:39,067 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:39,150 - podcast_processing.episode_processor - INFO -   Processing chunk 19/27 (210.0s)
[Rank 0] 2026-01-23 12:38:39,185 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:39,266 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:39,266 - podcast_processing.episode_processor - DEBUG - System speaker has 400 words
[Rank 0] 2026-01-23 12:38:39,312 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:39,312 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:39,312 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:39,313 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:39,340 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:39,422 - podcast_processing.episode_processor - INFO -   Processing chunk 20/27 (210.0s)
[Rank 0] 2026-01-23 12:38:39,678 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3600/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:39,759 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:39,759 - podcast_processing.episode_processor - DEBUG - System speaker has 340 words
[Rank 0] 2026-01-23 12:38:39,805 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:39,805 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:39,807 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:39,807 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:39,835 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:39,917 - podcast_processing.episode_processor - INFO -   Processing chunk 21/27 (210.0s)
[Rank 0] 2026-01-23 12:38:39,964 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 63117/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:40,046 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:40,046 - podcast_processing.episode_processor - DEBUG - System speaker has 233 words
[Rank 0] 2026-01-23 12:38:40,092 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:40,092 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:40,093 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:40,093 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:40,120 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:40,214 - podcast_processing.episode_processor - INFO -   Processing chunk 22/27 (210.0s)
[Rank 0] 2026-01-23 12:38:40,265 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16311/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:40,346 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:40,346 - podcast_processing.episode_processor - DEBUG - System speaker has 262 words
[Rank 0] 2026-01-23 12:38:40,393 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:40,393 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:40,393 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:40,394 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:40,421 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:40,515 - podcast_processing.episode_processor - INFO -   Processing chunk 23/27 (210.0s)
[Rank 0] 2026-01-23 12:38:40,563 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6720/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:40,644 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:40,644 - podcast_processing.episode_processor - DEBUG - System speaker has 304 words
[Rank 0] 2026-01-23 12:38:40,691 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:40,691 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:40,692 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:40,692 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:40,719 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:40,814 - podcast_processing.episode_processor - INFO -   Processing chunk 24/27 (210.0s)
[Rank 0] 2026-01-23 12:38:40,863 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11280/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:40,945 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:40,945 - podcast_processing.episode_processor - DEBUG - System speaker has 370 words
[Rank 0] 2026-01-23 12:38:40,991 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:40,991 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:40,992 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:40,992 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:41,019 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:41,112 - podcast_processing.episode_processor - INFO -   Processing chunk 25/27 (210.0s)
[Rank 0] 2026-01-23 12:38:41,161 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:41,244 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:41,244 - podcast_processing.episode_processor - DEBUG - System speaker has 304 words
[Rank 0] 2026-01-23 12:38:41,290 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:41,291 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:41,291 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:41,291 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:41,318 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:41,412 - podcast_processing.episode_processor - INFO -   Processing chunk 26/27 (210.0s)
[Rank 0] 2026-01-23 12:38:41,461 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 71511/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:41,549 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:41,549 - podcast_processing.episode_processor - DEBUG - System speaker has 500 words
[Rank 0] 2026-01-23 12:38:41,596 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:41,596 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:41,596 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:41,597 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:41,624 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:41,718 - podcast_processing.episode_processor - INFO -   Processing chunk 27/27 (22.1s)
[Rank 0] 2026-01-23 12:38:41,723 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/529240 samples zeroed
[Rank 0] 2026-01-23 12:38:41,745 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 276]), System codes shape: torch.Size([1, 8, 276])
[Rank 0] 2026-01-23 12:38:41,745 - podcast_processing.episode_processor - DEBUG - System speaker has 2 words
[Rank 0] 2026-01-23 12:38:41,745 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 276])
[Rank 0] 2026-01-23 12:38:41,745 - podcast_processing.episode_processor - DEBUG - Padded to max_t=276
[Rank 0] 2026-01-23 12:38:41,746 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 276]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:41,746 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 277])
[Rank 0] 2026-01-23 12:38:41,772 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 276, 4096])
[Rank 0] 2026-01-23 12:38:42,104 - podcast_processing.episode_processor - INFO - Combined 27 chunks into final output shape: torch.Size([68526, 4096])
[Rank 0] 2026-01-23 12:38:45,353 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/GeeklyBiWeekly_Geekly Bi-Weekly Episode 1 WandaVision, Disney+, Spiderman, HBO MAX/features_assignment_1.npy
[Rank 0] 2026-01-23 12:38:45,353 - podcast_processing.episode_processor - INFO -   Saved features: 68526 frames
[Rank 0] 2026-01-23 12:38:45,355 - podcast_processing.label_generator - DEBUG - Processing 45 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:38:45,361 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/GeeklyBiWeekly_Geekly Bi-Weekly Episode 1 WandaVision, Disney+, Spiderman, HBO MAX/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:38:45,361 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 197/68526 positive
[Rank 0] 2026-01-23 12:38:45,363 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/GeeklyBiWeekly_Geekly Bi-Weekly Episode 1 WandaVision, Disney+, Spiderman, HBO MAX/metadata_shift_1.json
[Rank 0] 2026-01-23 12:38:45,363 - podcast_processing.episode_processor - INFO - Completed episode: GeeklyBiWeekly_Geekly Bi-Weekly Episode 1 WandaVision, Disney+, Spiderman, HBO MAX
[Rank 0] 2026-01-23 12:38:45,426 - podcast_processing.distributed_orchestrator - INFO - âœ“ GeeklyBiWeekly_Geekly Bi-Weekly Episode 1 WandaVision, Disney+, Spiderman, HBO MAX
[Rank 0] 2026-01-23 12:38:45,427 - podcast_processing.episode_processor - INFO - Processing episode: Gin the Multimediator_The Upside VT Work It with Vermont Womenpreneurs, Mieko Ozeki and Bethany Andrews-Nichols
[Rank 0] 2026-01-23 12:38:45,430 - podcast_processing.label_generator - DEBUG - Loaded 19 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Gin the Multimediator_The Upside VT Work It with Vermont Womenpreneurs, Mieko Ozeki and Bethany Andrews-Nichols.json
[Rank 0] 2026-01-23 12:38:45,431 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_00 (longer), SPEAKER_01 (shorter)
[Rank 0] 2026-01-23 12:38:45,526 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [471.50, 471.80], using fallback
[Rank 0] 2026-01-23 12:38:45,633 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [964.59, 964.80], using fallback
[Rank 0] 2026-01-23 12:38:45,749 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1546.21, 1546.29], using fallback
[Rank 0] 2026-01-23 12:38:45,818 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1848.55, 1848.55], using fallback
[Rank 0] 2026-01-23 12:38:45,904 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2277.12, 2277.21], using fallback
[Rank 0] 2026-01-23 12:38:45,917 - podcast_processing.alignment_merger - INFO - Created 6766 word alignments
[Rank 0] 2026-01-23 12:38:46,461 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_00: torch.Size([1, 56487184]), SPEAKER_01: torch.Size([1, 56487184])
[Rank 0] 2026-01-23 12:38:46,461 - podcast_processing.episode_processor - INFO - Episode duration: 2353.63s
[Rank 0] 2026-01-23 12:38:46,461 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:38:46,466 - podcast_processing.audio_masking - DEBUG - Creating mask from 10 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:38:46,492 - podcast_processing.audio_masking - DEBUG - Mask covers 115683/56487184 samples (0.20%)
[Rank 0] 2026-01-23 12:38:46,517 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 115683/56487184 samples masked
[Rank 0] 2026-01-23 12:38:47,141 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 115683/56487184 samples zeroed
[Rank 0] 2026-01-23 12:38:47,141 - podcast_processing.episode_processor - INFO - Audio is 2353.6s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:38:47,142 - podcast_processing.episode_processor - INFO - Processing 2353.6s audio in 12 chunks of 210s each
[Rank 0] 2026-01-23 12:38:47,142 - podcast_processing.episode_processor - INFO -   Processing chunk 1/12 (210.0s)
[Rank 0] 2026-01-23 12:38:47,182 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:47,265 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:47,265 - podcast_processing.episode_processor - DEBUG - System speaker has 30 words
[Rank 0] 2026-01-23 12:38:47,311 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:47,311 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:47,312 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:47,312 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:47,340 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:47,427 - podcast_processing.episode_processor - INFO -   Processing chunk 2/12 (210.0s)
[Rank 0] 2026-01-23 12:38:47,462 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:47,555 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:47,555 - podcast_processing.episode_processor - DEBUG - System speaker has 299 words
[Rank 0] 2026-01-23 12:38:47,602 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:47,602 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:47,602 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:47,603 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:47,630 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:47,717 - podcast_processing.episode_processor - INFO -   Processing chunk 3/12 (210.0s)
[Rank 0] 2026-01-23 12:38:47,752 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:47,833 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:47,833 - podcast_processing.episode_processor - DEBUG - System speaker has 93 words
[Rank 0] 2026-01-23 12:38:47,880 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:47,880 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:47,880 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:47,881 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:47,908 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:47,999 - podcast_processing.episode_processor - INFO -   Processing chunk 4/12 (210.0s)
[Rank 0] 2026-01-23 12:38:48,033 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:48,114 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:48,114 - podcast_processing.episode_processor - DEBUG - System speaker has 136 words
[Rank 0] 2026-01-23 12:38:48,161 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:48,161 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:48,161 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:48,162 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:48,189 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:48,272 - podcast_processing.episode_processor - INFO -   Processing chunk 5/12 (210.0s)
[Rank 0] 2026-01-23 12:38:48,307 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11040/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:48,388 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:48,388 - podcast_processing.episode_processor - DEBUG - System speaker has 369 words
[Rank 0] 2026-01-23 12:38:48,434 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:48,434 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:48,435 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:48,435 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:48,462 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:48,545 - podcast_processing.episode_processor - INFO -   Processing chunk 6/12 (210.0s)
[Rank 0] 2026-01-23 12:38:48,579 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 52801/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:48,667 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:48,667 - podcast_processing.episode_processor - DEBUG - System speaker has 290 words
[Rank 0] 2026-01-23 12:38:48,714 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:48,714 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:48,715 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:48,715 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:48,742 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:48,823 - podcast_processing.episode_processor - INFO -   Processing chunk 7/12 (210.0s)
[Rank 0] 2026-01-23 12:38:48,865 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:48,958 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:48,959 - podcast_processing.episode_processor - DEBUG - System speaker has 5 words
[Rank 0] 2026-01-23 12:38:49,005 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:49,005 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:49,006 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:49,006 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:49,033 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:49,116 - podcast_processing.episode_processor - INFO -   Processing chunk 8/12 (210.0s)
[Rank 0] 2026-01-23 12:38:49,154 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16560/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:49,235 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:49,235 - podcast_processing.episode_processor - DEBUG - System speaker has 143 words
[Rank 0] 2026-01-23 12:38:49,281 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:49,281 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:49,282 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:49,282 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:49,309 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:49,392 - podcast_processing.episode_processor - INFO -   Processing chunk 9/12 (210.0s)
[Rank 0] 2026-01-23 12:38:49,437 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 18482/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:49,537 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:49,537 - podcast_processing.episode_processor - DEBUG - System speaker has 70 words
[Rank 0] 2026-01-23 12:38:49,584 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:49,584 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:49,584 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:49,585 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:49,612 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:49,696 - podcast_processing.episode_processor - INFO -   Processing chunk 10/12 (210.0s)
[Rank 0] 2026-01-23 12:38:49,741 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 16800/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:49,821 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:49,821 - podcast_processing.episode_processor - DEBUG - System speaker has 314 words
[Rank 0] 2026-01-23 12:38:49,868 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:49,868 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:49,869 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:49,869 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:49,896 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:49,987 - podcast_processing.episode_processor - INFO -   Processing chunk 11/12 (210.0s)
[Rank 0] 2026-01-23 12:38:50,022 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:50,103 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:50,103 - podcast_processing.episode_processor - DEBUG - System speaker has 58 words
[Rank 0] 2026-01-23 12:38:50,150 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:50,150 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:50,150 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:50,151 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:50,180 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:50,260 - podcast_processing.episode_processor - INFO -   Processing chunk 12/12 (43.6s)
[Rank 0] 2026-01-23 12:38:50,270 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/1047184 samples zeroed
[Rank 0] 2026-01-23 12:38:50,319 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 546]), System codes shape: torch.Size([1, 8, 546])
[Rank 0] 2026-01-23 12:38:50,319 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:38:50,321 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 546])
[Rank 0] 2026-01-23 12:38:50,321 - podcast_processing.episode_processor - DEBUG - Padded to max_t=546
[Rank 0] 2026-01-23 12:38:50,321 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 546]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:50,322 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 547])
[Rank 0] 2026-01-23 12:38:50,355 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 546, 4096])
[Rank 0] 2026-01-23 12:38:50,517 - podcast_processing.episode_processor - INFO - Combined 12 chunks into final output shape: torch.Size([29421, 4096])
[Rank 0] 2026-01-23 12:38:53,107 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Gin the Multimediator_The Upside VT Work It with Vermont Womenpreneurs, Mieko Ozeki and Bethany Andrews-Nichols/features_assignment_0.npy
[Rank 0] 2026-01-23 12:38:53,107 - podcast_processing.episode_processor - INFO -   Saved features: 29421 frames
[Rank 0] 2026-01-23 12:38:53,128 - podcast_processing.label_generator - DEBUG - Processing 9 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:38:53,204 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Gin the Multimediator_The Upside VT Work It with Vermont Womenpreneurs, Mieko Ozeki and Bethany Andrews-Nichols/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:38:53,204 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 51/29421 positive
[Rank 0] 2026-01-23 12:38:53,223 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:38:53,231 - podcast_processing.audio_masking - DEBUG - Creating mask from 9 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:38:53,311 - podcast_processing.audio_masking - DEBUG - Mask covers 98398/56487184 samples (0.17%)
[Rank 0] 2026-01-23 12:38:53,342 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 98398/56487184 samples masked
[Rank 0] 2026-01-23 12:38:53,949 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 98398/56487184 samples zeroed
[Rank 0] 2026-01-23 12:38:53,949 - podcast_processing.episode_processor - INFO - Audio is 2353.6s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:38:53,949 - podcast_processing.episode_processor - INFO - Processing 2353.6s audio in 12 chunks of 210s each
[Rank 0] 2026-01-23 12:38:53,950 - podcast_processing.episode_processor - INFO -   Processing chunk 1/12 (210.0s)
[Rank 0] 2026-01-23 12:38:53,990 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:54,073 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:54,073 - podcast_processing.episode_processor - DEBUG - System speaker has 207 words
[Rank 0] 2026-01-23 12:38:54,119 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:54,119 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:54,119 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:54,120 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:54,147 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:54,239 - podcast_processing.episode_processor - INFO -   Processing chunk 2/12 (210.0s)
[Rank 0] 2026-01-23 12:38:54,279 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:54,361 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:54,361 - podcast_processing.episode_processor - DEBUG - System speaker has 290 words
[Rank 0] 2026-01-23 12:38:54,408 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:54,408 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:54,408 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:54,409 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:54,436 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:54,525 - podcast_processing.episode_processor - INFO -   Processing chunk 3/12 (210.0s)
[Rank 0] 2026-01-23 12:38:54,565 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:54,646 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:54,646 - podcast_processing.episode_processor - DEBUG - System speaker has 419 words
[Rank 0] 2026-01-23 12:38:54,693 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:54,693 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:54,693 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:54,694 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:54,721 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:54,811 - podcast_processing.episode_processor - INFO -   Processing chunk 4/12 (210.0s)
[Rank 0] 2026-01-23 12:38:54,845 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 48241/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:54,926 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:54,926 - podcast_processing.episode_processor - DEBUG - System speaker has 489 words
[Rank 0] 2026-01-23 12:38:54,973 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:54,973 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:54,973 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:54,974 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:55,001 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:55,088 - podcast_processing.episode_processor - INFO -   Processing chunk 5/12 (210.0s)
[Rank 0] 2026-01-23 12:38:55,123 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:55,204 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:55,204 - podcast_processing.episode_processor - DEBUG - System speaker has 285 words
[Rank 0] 2026-01-23 12:38:55,251 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:55,251 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:55,251 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:55,252 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:55,279 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:55,362 - podcast_processing.episode_processor - INFO -   Processing chunk 6/12 (210.0s)
[Rank 0] 2026-01-23 12:38:55,397 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20159/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:55,478 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:55,478 - podcast_processing.episode_processor - DEBUG - System speaker has 82 words
[Rank 0] 2026-01-23 12:38:55,524 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:55,524 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:55,525 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:55,525 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:55,552 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:55,643 - podcast_processing.episode_processor - INFO -   Processing chunk 7/12 (210.0s)
[Rank 0] 2026-01-23 12:38:55,678 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:55,759 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:55,759 - podcast_processing.episode_processor - DEBUG - System speaker has 606 words
[Rank 0] 2026-01-23 12:38:55,805 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:55,805 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:55,806 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:55,806 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:55,834 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:55,917 - podcast_processing.episode_processor - INFO -   Processing chunk 8/12 (210.0s)
[Rank 0] 2026-01-23 12:38:55,957 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3838/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:56,038 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:56,038 - podcast_processing.episode_processor - DEBUG - System speaker has 429 words
[Rank 0] 2026-01-23 12:38:56,084 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:56,085 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:56,085 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:56,085 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:56,113 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:56,198 - podcast_processing.episode_processor - INFO -   Processing chunk 9/12 (210.0s)
[Rank 0] 2026-01-23 12:38:56,233 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:56,328 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:56,328 - podcast_processing.episode_processor - DEBUG - System speaker has 508 words
[Rank 0] 2026-01-23 12:38:56,375 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:56,375 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:56,375 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:56,376 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:56,403 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:56,512 - podcast_processing.episode_processor - INFO -   Processing chunk 10/12 (210.0s)
[Rank 0] 2026-01-23 12:38:56,547 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 20160/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:56,645 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:56,645 - podcast_processing.episode_processor - DEBUG - System speaker has 188 words
[Rank 0] 2026-01-23 12:38:56,691 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:56,691 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:56,692 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:56,692 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:56,719 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:56,817 - podcast_processing.episode_processor - INFO -   Processing chunk 11/12 (210.0s)
[Rank 0] 2026-01-23 12:38:56,852 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 6000/5040000 samples zeroed
[Rank 0] 2026-01-23 12:38:56,933 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:38:56,933 - podcast_processing.episode_processor - DEBUG - System speaker has 311 words
[Rank 0] 2026-01-23 12:38:56,980 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:38:56,980 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:38:56,980 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:56,981 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:38:57,008 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:38:57,090 - podcast_processing.episode_processor - INFO -   Processing chunk 12/12 (43.6s)
[Rank 0] 2026-01-23 12:38:57,098 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/1047184 samples zeroed
[Rank 0] 2026-01-23 12:38:57,125 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 546]), System codes shape: torch.Size([1, 8, 546])
[Rank 0] 2026-01-23 12:38:57,125 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:38:57,127 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 546])
[Rank 0] 2026-01-23 12:38:57,127 - podcast_processing.episode_processor - DEBUG - Padded to max_t=546
[Rank 0] 2026-01-23 12:38:57,127 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 546]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:38:57,128 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 547])
[Rank 0] 2026-01-23 12:38:57,154 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 546, 4096])
[Rank 0] 2026-01-23 12:38:57,319 - podcast_processing.episode_processor - INFO - Combined 12 chunks into final output shape: torch.Size([29421, 4096])
[Rank 0] 2026-01-23 12:38:58,849 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Gin the Multimediator_The Upside VT Work It with Vermont Womenpreneurs, Mieko Ozeki and Bethany Andrews-Nichols/features_assignment_1.npy
[Rank 0] 2026-01-23 12:38:58,849 - podcast_processing.episode_processor - INFO -   Saved features: 29421 frames
[Rank 0] 2026-01-23 12:38:58,849 - podcast_processing.label_generator - DEBUG - Processing 10 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:38:58,941 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Gin the Multimediator_The Upside VT Work It with Vermont Womenpreneurs, Mieko Ozeki and Bethany Andrews-Nichols/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:38:58,941 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 61/29421 positive
[Rank 0] 2026-01-23 12:38:58,968 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Gin the Multimediator_The Upside VT Work It with Vermont Womenpreneurs, Mieko Ozeki and Bethany Andrews-Nichols/metadata_shift_1.json
[Rank 0] 2026-01-23 12:38:58,968 - podcast_processing.episode_processor - INFO - Completed episode: Gin the Multimediator_The Upside VT Work It with Vermont Womenpreneurs, Mieko Ozeki and Bethany Andrews-Nichols
[Rank 0] 2026-01-23 12:38:59,042 - podcast_processing.distributed_orchestrator - INFO - âœ“ Gin the Multimediator_The Upside VT Work It with Vermont Womenpreneurs, Mieko Ozeki and Bethany Andrews-Nichols
[Rank 0] 2026-01-23 12:38:59,072 - podcast_processing.episode_processor - INFO - Processing episode: Happiness of Pursuit_HOP #64 How to beat burnout and defeat depression w. Victoria Klein
[Rank 0] 2026-01-23 12:38:59,099 - podcast_processing.label_generator - DEBUG - Loaded 9 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Happiness of Pursuit_HOP #64 How to beat burnout and defeat depression w. Victoria Klein.json
[Rank 0] 2026-01-23 12:38:59,100 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_00 (longer), SPEAKER_02 (shorter)
[Rank 0] 2026-01-23 12:38:59,200 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [336.34, 336.48], using fallback
[Rank 0] 2026-01-23 12:38:59,310 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1156.42, 1156.42], using fallback
[Rank 0] 2026-01-23 12:38:59,404 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1813.23, 1813.71], using fallback
[Rank 0] 2026-01-23 12:38:59,451 - podcast_processing.alignment_merger - INFO - Created 6477 word alignments
[Rank 0] 2026-01-23 12:38:59,992 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_00: torch.Size([1, 52657840]), SPEAKER_02: torch.Size([1, 52657840])
[Rank 0] 2026-01-23 12:38:59,992 - podcast_processing.episode_processor - INFO - Episode duration: 2194.08s
[Rank 0] 2026-01-23 12:38:59,992 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:39:00,007 - podcast_processing.audio_masking - DEBUG - No laughter events found for SPEAKER_02
[Rank 0] 2026-01-23 12:39:00,012 - podcast_processing.episode_processor - INFO - Audio is 2194.1s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:39:00,012 - podcast_processing.episode_processor - INFO - Processing 2194.1s audio in 11 chunks of 210s each
[Rank 0] 2026-01-23 12:39:00,012 - podcast_processing.episode_processor - INFO -   Processing chunk 1/11 (210.0s)
[Rank 0] 2026-01-23 12:39:00,095 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:00,095 - podcast_processing.episode_processor - DEBUG - System speaker has 321 words
[Rank 0] 2026-01-23 12:39:00,142 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:00,142 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:00,142 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:00,142 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:00,170 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:00,261 - podcast_processing.episode_processor - INFO -   Processing chunk 2/11 (210.0s)
[Rank 0] 2026-01-23 12:39:00,344 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:00,344 - podcast_processing.episode_processor - DEBUG - System speaker has 149 words
[Rank 0] 2026-01-23 12:39:00,391 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:00,391 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:00,391 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:00,391 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:00,419 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:00,502 - podcast_processing.episode_processor - INFO -   Processing chunk 3/11 (210.0s)
[Rank 0] 2026-01-23 12:39:00,584 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:00,584 - podcast_processing.episode_processor - DEBUG - System speaker has 116 words
[Rank 0] 2026-01-23 12:39:00,630 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:00,630 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:00,630 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:00,631 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:00,658 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:00,741 - podcast_processing.episode_processor - INFO -   Processing chunk 4/11 (210.0s)
[Rank 0] 2026-01-23 12:39:00,823 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:00,824 - podcast_processing.episode_processor - DEBUG - System speaker has 110 words
[Rank 0] 2026-01-23 12:39:00,870 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:00,870 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:00,870 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:00,871 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:00,898 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:00,980 - podcast_processing.episode_processor - INFO -   Processing chunk 5/11 (210.0s)
[Rank 0] 2026-01-23 12:39:01,063 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:01,063 - podcast_processing.episode_processor - DEBUG - System speaker has 144 words
[Rank 0] 2026-01-23 12:39:01,109 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:01,109 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:01,109 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:01,110 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:01,138 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:01,219 - podcast_processing.episode_processor - INFO -   Processing chunk 6/11 (210.0s)
[Rank 0] 2026-01-23 12:39:01,302 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:01,302 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:39:01,349 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:01,349 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:01,349 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:01,349 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:01,376 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:01,459 - podcast_processing.episode_processor - INFO -   Processing chunk 7/11 (210.0s)
[Rank 0] 2026-01-23 12:39:01,541 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:01,542 - podcast_processing.episode_processor - DEBUG - System speaker has 47 words
[Rank 0] 2026-01-23 12:39:01,588 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:01,953 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:01,953 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:01,954 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:01,998 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:02,079 - podcast_processing.episode_processor - INFO -   Processing chunk 8/11 (210.0s)
[Rank 0] 2026-01-23 12:39:02,162 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:02,162 - podcast_processing.episode_processor - DEBUG - System speaker has 50 words
[Rank 0] 2026-01-23 12:39:02,208 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:02,209 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:02,209 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:02,210 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:02,237 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:02,319 - podcast_processing.episode_processor - INFO -   Processing chunk 9/11 (210.0s)
[Rank 0] 2026-01-23 12:39:02,400 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:02,400 - podcast_processing.episode_processor - DEBUG - System speaker has 131 words
[Rank 0] 2026-01-23 12:39:02,447 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:02,447 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:02,447 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:02,448 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:02,475 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:02,558 - podcast_processing.episode_processor - INFO -   Processing chunk 10/11 (210.0s)
[Rank 0] 2026-01-23 12:39:02,639 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:02,639 - podcast_processing.episode_processor - DEBUG - System speaker has 164 words
[Rank 0] 2026-01-23 12:39:02,686 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:02,686 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:02,686 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:02,687 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:02,714 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:02,797 - podcast_processing.episode_processor - INFO -   Processing chunk 11/11 (94.1s)
[Rank 0] 2026-01-23 12:39:02,850 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1176]), System codes shape: torch.Size([1, 8, 1176])
[Rank 0] 2026-01-23 12:39:02,851 - podcast_processing.episode_processor - DEBUG - System speaker has 128 words
[Rank 0] 2026-01-23 12:39:02,863 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1176])
[Rank 0] 2026-01-23 12:39:02,863 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1176
[Rank 0] 2026-01-23 12:39:02,863 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1176]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:02,864 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1177])
[Rank 0] 2026-01-23 12:39:02,892 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1176, 4096])
[Rank 0] 2026-01-23 12:39:03,044 - podcast_processing.episode_processor - INFO - Combined 11 chunks into final output shape: torch.Size([27426, 4096])
[Rank 0] 2026-01-23 12:39:04,305 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Happiness of Pursuit_HOP #64 How to beat burnout and defeat depression w. Victoria Klein/features_assignment_0.npy
[Rank 0] 2026-01-23 12:39:04,305 - podcast_processing.episode_processor - INFO -   Saved features: 27426 frames
[Rank 0] 2026-01-23 12:39:04,311 - podcast_processing.label_generator - DEBUG - Processing 9 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:39:04,323 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Happiness of Pursuit_HOP #64 How to beat burnout and defeat depression w. Victoria Klein/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:39:04,323 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 41/27426 positive
[Rank 0] 2026-01-23 12:39:04,323 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:39:04,337 - podcast_processing.audio_masking - DEBUG - Creating mask from 9 laughter events for SPEAKER_00
[Rank 0] 2026-01-23 12:39:04,391 - podcast_processing.audio_masking - DEBUG - Mask covers 79438/52657840 samples (0.15%)
[Rank 0] 2026-01-23 12:39:04,419 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 79438/52657840 samples masked
[Rank 0] 2026-01-23 12:39:04,992 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 79438/52657840 samples zeroed
[Rank 0] 2026-01-23 12:39:04,992 - podcast_processing.episode_processor - INFO - Audio is 2194.1s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:39:04,992 - podcast_processing.episode_processor - INFO - Processing 2194.1s audio in 11 chunks of 210s each
[Rank 0] 2026-01-23 12:39:04,992 - podcast_processing.episode_processor - INFO -   Processing chunk 1/11 (210.0s)
[Rank 0] 2026-01-23 12:39:05,027 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:05,110 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:05,110 - podcast_processing.episode_processor - DEBUG - System speaker has 185 words
[Rank 0] 2026-01-23 12:39:05,156 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:05,156 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:05,157 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:05,157 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:05,185 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:05,270 - podcast_processing.episode_processor - INFO -   Processing chunk 2/11 (210.0s)
[Rank 0] 2026-01-23 12:39:05,306 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:05,387 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:05,387 - podcast_processing.episode_processor - DEBUG - System speaker has 466 words
[Rank 0] 2026-01-23 12:39:05,434 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:05,434 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:05,434 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:05,435 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:05,462 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:05,545 - podcast_processing.episode_processor - INFO -   Processing chunk 3/11 (210.0s)
[Rank 0] 2026-01-23 12:39:05,580 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:05,661 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:05,661 - podcast_processing.episode_processor - DEBUG - System speaker has 502 words
[Rank 0] 2026-01-23 12:39:05,708 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:05,708 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:05,709 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:05,709 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:05,736 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:05,819 - podcast_processing.episode_processor - INFO -   Processing chunk 4/11 (210.0s)
[Rank 0] 2026-01-23 12:39:05,853 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 15599/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:05,935 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:05,935 - podcast_processing.episode_processor - DEBUG - System speaker has 517 words
[Rank 0] 2026-01-23 12:39:05,981 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:05,981 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:05,982 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:05,982 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:06,009 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:06,092 - podcast_processing.episode_processor - INFO -   Processing chunk 5/11 (210.0s)
[Rank 0] 2026-01-23 12:39:06,131 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:06,212 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:06,213 - podcast_processing.episode_processor - DEBUG - System speaker has 482 words
[Rank 0] 2026-01-23 12:39:06,259 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:06,259 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:06,260 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:06,260 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:06,287 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:06,370 - podcast_processing.episode_processor - INFO -   Processing chunk 6/11 (210.0s)
[Rank 0] 2026-01-23 12:39:06,410 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 11759/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:06,490 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:06,491 - podcast_processing.episode_processor - DEBUG - System speaker has 647 words
[Rank 0] 2026-01-23 12:39:06,537 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:06,537 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:06,538 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:06,538 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:06,565 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:06,648 - podcast_processing.episode_processor - INFO -   Processing chunk 7/11 (210.0s)
[Rank 0] 2026-01-23 12:39:06,688 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:06,769 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:06,769 - podcast_processing.episode_processor - DEBUG - System speaker has 593 words
[Rank 0] 2026-01-23 12:39:06,815 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:06,815 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:06,816 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:06,816 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:06,843 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:06,937 - podcast_processing.episode_processor - INFO -   Processing chunk 8/11 (210.0s)
[Rank 0] 2026-01-23 12:39:06,972 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 15120/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:07,052 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:07,052 - podcast_processing.episode_processor - DEBUG - System speaker has 607 words
[Rank 0] 2026-01-23 12:39:07,099 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:07,099 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:07,100 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:07,100 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:07,127 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:07,210 - podcast_processing.episode_processor - INFO -   Processing chunk 9/11 (210.0s)
[Rank 0] 2026-01-23 12:39:07,245 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 8880/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:07,325 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:07,326 - podcast_processing.episode_processor - DEBUG - System speaker has 526 words
[Rank 0] 2026-01-23 12:39:07,372 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:07,372 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:07,373 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:07,373 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:07,400 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:07,483 - podcast_processing.episode_processor - INFO -   Processing chunk 10/11 (210.0s)
[Rank 0] 2026-01-23 12:39:07,518 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 25681/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:07,608 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:07,608 - podcast_processing.episode_processor - DEBUG - System speaker has 452 words
[Rank 0] 2026-01-23 12:39:07,654 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:07,655 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:07,655 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:07,655 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:07,683 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:07,778 - podcast_processing.episode_processor - INFO -   Processing chunk 11/11 (94.1s)
[Rank 0] 2026-01-23 12:39:07,794 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 2399/2257840 samples zeroed
[Rank 0] 2026-01-23 12:39:07,831 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 1176]), System codes shape: torch.Size([1, 8, 1176])
[Rank 0] 2026-01-23 12:39:07,832 - podcast_processing.episode_processor - DEBUG - System speaker has 16 words
[Rank 0] 2026-01-23 12:39:07,844 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 1176])
[Rank 0] 2026-01-23 12:39:07,844 - podcast_processing.episode_processor - DEBUG - Padded to max_t=1176
[Rank 0] 2026-01-23 12:39:07,844 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 1176]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:07,845 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 1177])
[Rank 0] 2026-01-23 12:39:07,871 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 1176, 4096])
[Rank 0] 2026-01-23 12:39:08,021 - podcast_processing.episode_processor - INFO - Combined 11 chunks into final output shape: torch.Size([27426, 4096])
[Rank 0] 2026-01-23 12:39:09,278 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Happiness of Pursuit_HOP #64 How to beat burnout and defeat depression w. Victoria Klein/features_assignment_1.npy
[Rank 0] 2026-01-23 12:39:09,278 - podcast_processing.episode_processor - INFO -   Saved features: 27426 frames
[Rank 0] 2026-01-23 12:39:09,278 - podcast_processing.label_generator - DEBUG - Processing 0 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:39:09,296 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Happiness of Pursuit_HOP #64 How to beat burnout and defeat depression w. Victoria Klein/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:39:09,296 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 0/27426 positive
[Rank 0] 2026-01-23 12:39:09,303 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Happiness of Pursuit_HOP #64 How to beat burnout and defeat depression w. Victoria Klein/metadata_shift_1.json
[Rank 0] 2026-01-23 12:39:09,305 - podcast_processing.episode_processor - INFO - Completed episode: Happiness of Pursuit_HOP #64 How to beat burnout and defeat depression w. Victoria Klein
[Rank 0] 2026-01-23 12:39:09,358 - podcast_processing.distributed_orchestrator - INFO - âœ“ Happiness of Pursuit_HOP #64 How to beat burnout and defeat depression w. Victoria Klein
[Rank 0] 2026-01-23 12:39:09,361 - podcast_processing.episode_processor - INFO - Processing episode: Indivisible Chicago Podcast_196 COVID-19 One Year In with Dr. Rachel Rubin and Dr. Ellen Mason
[Rank 0] 2026-01-23 12:39:09,363 - podcast_processing.label_generator - DEBUG - Loaded 5 laughter events from data/PodcastFillers/metadata/episode_event_speaker_mapping/train/Indivisible Chicago Podcast_196 COVID-19 One Year In with Dr. Rachel Rubin and Dr. Ellen Mason.json
[Rank 0] 2026-01-23 12:39:09,364 - podcast_processing.episode_processor - INFO - Top speakers: SPEAKER_01 (longer), SPEAKER_02 (shorter)
[Rank 0] 2026-01-23 12:39:09,487 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [356.20, 356.20], using fallback
[Rank 0] 2026-01-23 12:39:09,487 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [363.41, 363.48], using fallback
[Rank 0] 2026-01-23 12:39:09,809 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1286.01, 1286.06], using fallback
[Rank 0] 2026-01-23 12:39:10,003 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1874.31, 1874.61], using fallback
[Rank 0] 2026-01-23 12:39:10,026 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [1939.60, 1939.60], using fallback
[Rank 0] 2026-01-23 12:39:10,062 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2054.91, 2055.01], using fallback
[Rank 0] 2026-01-23 12:39:10,126 - podcast_processing.alignment_merger - WARNING - No speaker found for interval [2239.20, 2239.20], using fallback
[Rank 0] 2026-01-23 12:39:10,286 - podcast_processing.alignment_merger - INFO - Created 8019 word alignments
[Rank 0] 2026-01-23 12:39:10,927 - podcast_processing.episode_processor - DEBUG - Loaded SPEAKER_01: torch.Size([1, 65861800]), SPEAKER_02: torch.Size([1, 65861800])
[Rank 0] 2026-01-23 12:39:10,927 - podcast_processing.episode_processor - INFO - Episode duration: 2744.24s
[Rank 0] 2026-01-23 12:39:10,927 - podcast_processing.episode_processor - INFO - Processing Assignment 0
[Rank 0] 2026-01-23 12:39:10,933 - podcast_processing.audio_masking - DEBUG - Creating mask from 3 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:39:10,964 - podcast_processing.audio_masking - DEBUG - Mask covers 31201/65861800 samples (0.05%)
[Rank 0] 2026-01-23 12:39:10,996 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 31201/65861800 samples masked
[Rank 0] 2026-01-23 12:39:11,697 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 31201/65861800 samples zeroed
[Rank 0] 2026-01-23 12:39:11,697 - podcast_processing.episode_processor - INFO - Audio is 2744.2s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:39:11,697 - podcast_processing.episode_processor - INFO - Processing 2744.2s audio in 14 chunks of 210s each
[Rank 0] 2026-01-23 12:39:11,697 - podcast_processing.episode_processor - INFO -   Processing chunk 1/14 (210.0s)
[Rank 0] 2026-01-23 12:39:11,732 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:11,815 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:11,815 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:39:11,861 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:11,861 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:11,863 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:11,863 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:11,892 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:11,976 - podcast_processing.episode_processor - INFO -   Processing chunk 2/14 (210.0s)
[Rank 0] 2026-01-23 12:39:12,012 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:12,094 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:12,094 - podcast_processing.episode_processor - DEBUG - System speaker has 2 words
[Rank 0] 2026-01-23 12:39:12,141 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:12,141 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:12,141 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:12,142 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:12,169 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:12,252 - podcast_processing.episode_processor - INFO -   Processing chunk 3/14 (210.0s)
[Rank 0] 2026-01-23 12:39:12,287 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:12,369 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:12,369 - podcast_processing.episode_processor - DEBUG - System speaker has 461 words
[Rank 0] 2026-01-23 12:39:12,415 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:12,415 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:12,416 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:12,416 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:12,443 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:12,526 - podcast_processing.episode_processor - INFO -   Processing chunk 4/14 (210.0s)
[Rank 0] 2026-01-23 12:39:12,561 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 27361/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:12,645 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:12,645 - podcast_processing.episode_processor - DEBUG - System speaker has 265 words
[Rank 0] 2026-01-23 12:39:12,691 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:12,691 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:12,692 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:12,692 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:12,720 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:12,801 - podcast_processing.episode_processor - INFO -   Processing chunk 5/14 (210.0s)
[Rank 0] 2026-01-23 12:39:12,836 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:12,918 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:12,918 - podcast_processing.episode_processor - DEBUG - System speaker has 303 words
[Rank 0] 2026-01-23 12:39:12,964 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:12,964 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:12,965 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:12,965 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:12,992 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:13,074 - podcast_processing.episode_processor - INFO -   Processing chunk 6/14 (210.0s)
[Rank 0] 2026-01-23 12:39:13,109 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 3840/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:13,191 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:13,191 - podcast_processing.episode_processor - DEBUG - System speaker has 274 words
[Rank 0] 2026-01-23 12:39:13,237 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:13,238 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:13,238 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:13,238 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:13,266 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:13,347 - podcast_processing.episode_processor - INFO -   Processing chunk 7/14 (210.0s)
[Rank 0] 2026-01-23 12:39:13,382 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:13,463 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:13,464 - podcast_processing.episode_processor - DEBUG - System speaker has 148 words
[Rank 0] 2026-01-23 12:39:13,510 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:13,510 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:13,511 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:13,511 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:13,539 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:13,620 - podcast_processing.episode_processor - INFO -   Processing chunk 8/14 (210.0s)
[Rank 0] 2026-01-23 12:39:13,655 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:13,736 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:13,736 - podcast_processing.episode_processor - DEBUG - System speaker has 165 words
[Rank 0] 2026-01-23 12:39:13,783 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:13,783 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:13,783 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:13,784 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:13,811 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:13,893 - podcast_processing.episode_processor - INFO -   Processing chunk 9/14 (210.0s)
[Rank 0] 2026-01-23 12:39:13,927 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:14,009 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:14,009 - podcast_processing.episode_processor - DEBUG - System speaker has 211 words
[Rank 0] 2026-01-23 12:39:14,055 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:14,055 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:14,055 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:14,056 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:14,083 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:14,165 - podcast_processing.episode_processor - INFO -   Processing chunk 10/14 (210.0s)
[Rank 0] 2026-01-23 12:39:14,201 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:14,284 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:14,284 - podcast_processing.episode_processor - DEBUG - System speaker has 202 words
[Rank 0] 2026-01-23 12:39:14,330 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:14,330 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:14,331 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:14,331 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:14,359 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:14,441 - podcast_processing.episode_processor - INFO -   Processing chunk 11/14 (210.0s)
[Rank 0] 2026-01-23 12:39:14,477 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:14,559 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:14,559 - podcast_processing.episode_processor - DEBUG - System speaker has 283 words
[Rank 0] 2026-01-23 12:39:14,605 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:14,605 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:14,605 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:14,606 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:14,633 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:14,715 - podcast_processing.episode_processor - INFO -   Processing chunk 12/14 (210.0s)
[Rank 0] 2026-01-23 12:39:14,751 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:14,833 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:14,833 - podcast_processing.episode_processor - DEBUG - System speaker has 199 words
[Rank 0] 2026-01-23 12:39:14,879 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:14,879 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:14,879 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:14,880 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:14,907 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:14,990 - podcast_processing.episode_processor - INFO -   Processing chunk 13/14 (210.0s)
[Rank 0] 2026-01-23 12:39:15,025 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:15,107 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:15,107 - podcast_processing.episode_processor - DEBUG - System speaker has 325 words
[Rank 0] 2026-01-23 12:39:15,153 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:15,154 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:15,154 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:15,154 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:15,181 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:15,264 - podcast_processing.episode_processor - INFO -   Processing chunk 14/14 (14.2s)
[Rank 0] 2026-01-23 12:39:15,267 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/341800 samples zeroed
[Rank 0] 2026-01-23 12:39:15,314 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 179]), System codes shape: torch.Size([1, 8, 179])
[Rank 0] 2026-01-23 12:39:15,315 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:39:15,315 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 179])
[Rank 0] 2026-01-23 12:39:15,315 - podcast_processing.episode_processor - DEBUG - Padded to max_t=179
[Rank 0] 2026-01-23 12:39:15,315 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 179]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:15,315 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 180])
[Rank 0] 2026-01-23 12:39:15,353 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 179, 4096])
[Rank 0] 2026-01-23 12:39:15,517 - podcast_processing.episode_processor - INFO - Combined 14 chunks into final output shape: torch.Size([34304, 4096])
[Rank 0] 2026-01-23 12:39:16,839 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Indivisible Chicago Podcast_196 COVID-19 One Year In with Dr. Rachel Rubin and Dr. Ellen Mason/features_assignment_0.npy
[Rank 0] 2026-01-23 12:39:16,839 - podcast_processing.episode_processor - INFO -   Saved features: 34304 frames
[Rank 0] 2026-01-23 12:39:16,839 - podcast_processing.label_generator - DEBUG - Processing 2 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:39:16,847 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Indivisible Chicago Podcast_196 COVID-19 One Year In with Dr. Rachel Rubin and Dr. Ellen Mason/labels_assignment_0_shift_1.npy
[Rank 0] 2026-01-23 12:39:16,847 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 16/34304 positive
[Rank 0] 2026-01-23 12:39:16,847 - podcast_processing.episode_processor - INFO - Processing Assignment 1
[Rank 0] 2026-01-23 12:39:16,852 - podcast_processing.audio_masking - DEBUG - Creating mask from 2 laughter events for SPEAKER_01
[Rank 0] 2026-01-23 12:39:16,891 - podcast_processing.audio_masking - DEBUG - Mask covers 30480/65861800 samples (0.05%)
[Rank 0] 2026-01-23 12:39:16,922 - podcast_processing.episode_processor - INFO -   Generated system audio mask: 30480/65861800 samples masked
[Rank 0] 2026-01-23 12:39:17,621 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 30480/65861800 samples zeroed
[Rank 0] 2026-01-23 12:39:17,622 - podcast_processing.episode_processor - INFO - Audio is 2744.2s, splitting into chunks for processing
[Rank 0] 2026-01-23 12:39:17,622 - podcast_processing.episode_processor - INFO - Processing 2744.2s audio in 14 chunks of 210s each
[Rank 0] 2026-01-23 12:39:17,622 - podcast_processing.episode_processor - INFO -   Processing chunk 1/14 (210.0s)
[Rank 0] 2026-01-23 12:39:17,656 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:17,740 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:17,740 - podcast_processing.episode_processor - DEBUG - System speaker has 569 words
[Rank 0] 2026-01-23 12:39:17,786 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:17,786 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:17,786 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:17,787 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:17,817 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:17,900 - podcast_processing.episode_processor - INFO -   Processing chunk 2/14 (210.0s)
[Rank 0] 2026-01-23 12:39:17,936 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:18,018 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:18,018 - podcast_processing.episode_processor - DEBUG - System speaker has 494 words
[Rank 0] 2026-01-23 12:39:18,064 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:18,064 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:18,065 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:18,065 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:18,093 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:18,176 - podcast_processing.episode_processor - INFO -   Processing chunk 3/14 (210.0s)
[Rank 0] 2026-01-23 12:39:18,211 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:18,293 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:18,387 - podcast_processing.episode_processor - DEBUG - System speaker has 132 words
[Rank 0] 2026-01-23 12:39:18,389 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:18,389 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:18,389 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:18,390 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:18,417 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:18,500 - podcast_processing.episode_processor - INFO -   Processing chunk 4/14 (210.0s)
[Rank 0] 2026-01-23 12:39:18,535 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:18,616 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:18,616 - podcast_processing.episode_processor - DEBUG - System speaker has 186 words
[Rank 0] 2026-01-23 12:39:18,663 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:18,663 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:18,664 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:18,664 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:18,691 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:18,773 - podcast_processing.episode_processor - INFO -   Processing chunk 5/14 (210.0s)
[Rank 0] 2026-01-23 12:39:18,808 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:18,889 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:18,889 - podcast_processing.episode_processor - DEBUG - System speaker has 154 words
[Rank 0] 2026-01-23 12:39:18,936 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:18,936 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:18,936 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:18,937 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:18,964 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:19,045 - podcast_processing.episode_processor - INFO -   Processing chunk 6/14 (210.0s)
[Rank 0] 2026-01-23 12:39:19,080 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:19,171 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:19,172 - podcast_processing.episode_processor - DEBUG - System speaker has 56 words
[Rank 0] 2026-01-23 12:39:19,218 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:19,218 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:19,218 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:19,219 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:19,247 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:19,327 - podcast_processing.episode_processor - INFO -   Processing chunk 7/14 (210.0s)
[Rank 0] 2026-01-23 12:39:19,362 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:19,461 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:19,461 - podcast_processing.episode_processor - DEBUG - System speaker has 207 words
[Rank 0] 2026-01-23 12:39:19,507 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:19,508 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:19,508 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:19,508 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:19,536 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:19,617 - podcast_processing.episode_processor - INFO -   Processing chunk 8/14 (210.0s)
[Rank 0] 2026-01-23 12:39:19,653 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:19,737 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:19,737 - podcast_processing.episode_processor - DEBUG - System speaker has 79 words
[Rank 0] 2026-01-23 12:39:19,784 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:19,784 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:19,784 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:19,785 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:19,812 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:19,893 - podcast_processing.episode_processor - INFO -   Processing chunk 9/14 (210.0s)
[Rank 0] 2026-01-23 12:39:19,928 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:20,009 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:20,009 - podcast_processing.episode_processor - DEBUG - System speaker has 45 words
[Rank 0] 2026-01-23 12:39:20,056 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:20,056 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:20,056 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:20,057 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:20,084 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:20,165 - podcast_processing.episode_processor - INFO -   Processing chunk 10/14 (210.0s)
[Rank 0] 2026-01-23 12:39:20,201 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:20,282 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:20,282 - podcast_processing.episode_processor - DEBUG - System speaker has 306 words
[Rank 0] 2026-01-23 12:39:20,328 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:20,328 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:20,329 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:20,329 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:20,356 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:20,439 - podcast_processing.episode_processor - INFO -   Processing chunk 11/14 (210.0s)
[Rank 0] 2026-01-23 12:39:20,473 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 30480/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:20,554 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:20,554 - podcast_processing.episode_processor - DEBUG - System speaker has 247 words
[Rank 0] 2026-01-23 12:39:20,601 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:20,601 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:20,601 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:20,602 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:20,629 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:20,711 - podcast_processing.episode_processor - INFO -   Processing chunk 12/14 (210.0s)
[Rank 0] 2026-01-23 12:39:20,747 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:20,828 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:20,828 - podcast_processing.episode_processor - DEBUG - System speaker has 197 words
[Rank 0] 2026-01-23 12:39:20,875 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:20,875 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:20,875 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:20,876 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:20,903 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:20,985 - podcast_processing.episode_processor - INFO -   Processing chunk 13/14 (210.0s)
[Rank 0] 2026-01-23 12:39:21,020 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/5040000 samples zeroed
[Rank 0] 2026-01-23 12:39:21,101 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 2625]), System codes shape: torch.Size([1, 8, 2625])
[Rank 0] 2026-01-23 12:39:21,101 - podcast_processing.episode_processor - DEBUG - System speaker has 169 words
[Rank 0] 2026-01-23 12:39:21,147 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 2625])
[Rank 0] 2026-01-23 12:39:21,148 - podcast_processing.episode_processor - DEBUG - Padded to max_t=2625
[Rank 0] 2026-01-23 12:39:21,148 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 2625]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:21,148 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 2626])
[Rank 0] 2026-01-23 12:39:21,175 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 2625, 4096])
[Rank 0] 2026-01-23 12:39:21,258 - podcast_processing.episode_processor - INFO -   Processing chunk 14/14 (14.2s)
[Rank 0] 2026-01-23 12:39:21,261 - podcast_processing.episode_processor - DEBUG - Applied audio mask: 0/341800 samples zeroed
[Rank 0] 2026-01-23 12:39:21,283 - podcast_processing.episode_processor - DEBUG - User codes shape: torch.Size([1, 8, 179]), System codes shape: torch.Size([1, 8, 179])
[Rank 0] 2026-01-23 12:39:21,283 - podcast_processing.episode_processor - DEBUG - System speaker has 0 words
[Rank 0] 2026-01-23 12:39:21,283 - podcast_processing.episode_processor - DEBUG - Text tokens shape: torch.Size([1, 1, 179])
[Rank 0] 2026-01-23 12:39:21,284 - podcast_processing.episode_processor - DEBUG - Padded to max_t=179
[Rank 0] 2026-01-23 12:39:21,284 - podcast_processing.episode_processor - DEBUG - Combined codes shape: torch.Size([1, 17, 179]) (1 text + 8 user + 8 system = 17)
[Rank 0] 2026-01-23 12:39:21,284 - podcast_processing.episode_processor - DEBUG - Delayed codes shape: torch.Size([1, 17, 180])
[Rank 0] 2026-01-23 12:39:21,311 - podcast_processing.episode_processor - DEBUG - Transformer output shape: torch.Size([1, 179, 4096])
[Rank 0] 2026-01-23 12:39:21,478 - podcast_processing.episode_processor - INFO - Combined 14 chunks into final output shape: torch.Size([34304, 4096])
[Rank 0] 2026-01-23 12:39:23,281 - podcast_processing.episode_output_writer - DEBUG - Saved features to outputs/features_masked/train/Indivisible Chicago Podcast_196 COVID-19 One Year In with Dr. Rachel Rubin and Dr. Ellen Mason/features_assignment_1.npy
[Rank 0] 2026-01-23 12:39:23,281 - podcast_processing.episode_processor - INFO -   Saved features: 34304 frames
[Rank 0] 2026-01-23 12:39:23,281 - podcast_processing.label_generator - DEBUG - Processing 3 laughter events for SPEAKER_02
[Rank 0] 2026-01-23 12:39:23,445 - podcast_processing.episode_output_writer - DEBUG - Saved labels to outputs/features_masked/train/Indivisible Chicago Podcast_196 COVID-19 One Year In with Dr. Rachel Rubin and Dr. Ellen Mason/labels_assignment_1_shift_1.npy
[Rank 0] 2026-01-23 12:39:23,445 - podcast_processing.episode_processor - INFO -   Saved labels (shift=1): 17/34304 positive
[Rank 0] 2026-01-23 12:39:23,460 - podcast_processing.episode_output_writer - DEBUG - Saved metadata to outputs/features_masked/train/Indivisible Chicago Podcast_196 COVID-19 One Year In with Dr. Rachel Rubin and Dr. Ellen Mason/metadata_shift_1.json
[Rank 0] 2026-01-23 12:39:23,460 - podcast_processing.episode_processor - INFO - Completed episode: Indivisible Chicago Podcast_196 COVID-19 One Year In with Dr. Rachel Rubin and Dr. Ellen Mason
[Rank 0] 2026-01-23 12:39:23,534 - podcast_processing.distributed_orchestrator - INFO - âœ“ Indivisible Chicago Podcast_196 COVID-19 One Year In with Dr. Rachel Rubin and Dr. Ellen Mason
[Rank 0] 2026-01-23 12:39:23,535 - podcast_processing.distributed_orchestrator - INFO - Rank 0 finished: 24 success, 0 errors
